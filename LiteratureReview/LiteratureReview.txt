# The need for digital preservation

With an exponential growth in data being produced digitally (SINTEF, 2013), comes a growth in the volume of data worth preserving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional preservation paradigms; where we can consider that for paper and physical artifacts, “benign neglect may be the best treatment” (Harvey, 2012, p. 10; derived from Bastian, Cloonan and Harvey, 1993; 2011), the rapid changes in technology and the fragility of digital media make this rule dangerous for the survival of data.

First, we should define what are archives, and what they are useful for. As Cook eloquently puts it:

> “Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)

It is certainly difficult to understand which data was already lost, and what is at stake now. Harvey emitted some criticism of pessimistic views for archiving:

> “It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
While it is difficult to argue that preserving digital objects is necessary, there is certainly a need to make a selection of what deserves to be protected, and to what level. It is clear that the long term preservation of legal and governmental records, scientific publications (Harvey, 2012, p. 26) and business records (Ross and Gow, 1999, p. iii) on digital form is crucial; but the archival of the wider Internet, cultural artifacts and our personal heritage is subject to discussion.

UNESCO note that those who value a more comprehensive collection argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything” (UNESCO, 2003, p. 73). Additionally, digital storage media degrade so rapidly that the content might disappear before a decision about its value has been made (UNESCO, 2003, p. 71; Harvey, 2012, p. 57). Proponents of a more selective collection argue that we could obtain a higher content quality, settle the preservation rights with content producers, and that we do not have the physical resources to store everything anyway (UNESCO, 2003, pp. 70-73; Harvey, 2012, pp. 26, 58).
Both UNESCO (2003) and Cook (2000) recognise that a middle ground must be found, and that both approaches are valid depending on the goal of the preservation intent. For example, the Internet Archive (Kahle, 1996) stores copies of as many websites as possible, but discards all images, stylesheets and multimedia objects in the process due to technical limitations; evidently this is not appropriate for valuable websites. The British Library’s Web Archive [footnote: http://www.webarchive.org.uk/ukwa/] curates collections of websites by topic and by events (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks, General Elections …) to reflect the state and opinion of the Web at these given points in history; because fewer sites are archived and their content is deemed important, they have archived full quality versions of these sites. See Masanès (2006, p.83) for a methodology for this type of selection. Cook reminds us however that archivists have a duty of impartiality and objectivity during the selection and must ensure all points of view are being kept, to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination” (Cook, 2000).

Hiroyuki Kawano also proposes to use reputation models to let crawling robots consider the “importance, fairness, trustiness, uniqueness and valuation” of a Web page (Kawano, 2008) based on numerous parameters, to decide whether a page is worth archiving. The automated nature of this selection can, by nature, be inaccurate and inadvertently subjective, therefore a manual selection is still sometimes required.


## Threats to digital continuity 

UNESCO (2003, pp. 30–31) has compiled a list of threats to what they call *digital continuity*. The two principal ones are the short lifetime of digital materials carriers (i.e. storage media), and the obsolescence of the means to access these digital materials (i.e. the software to read files and the hardware to read discontinued storage media).

The Digital Preservation Coalition (2008, p. 154) show that the reliability of storage material varies highly depending on the type of material and the storage conditions; for example D3 cartridges tapes start to deteriorate after 50 years in optimal conditions (low temperature and humidity) but only a year in warm and humid atmospheres. The range is even greater with optical media like DVDs, going from 3 months to a theoretical 200 years.

But the media are only part of the equation; because these media become obsolete, we will not necessarily be able to read them again even if they are not deteriorated. Weathley (2003, cited by Harvey, 2012, p. 37) denounced that myth of long-lived media: “[an IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” And as Pearson adds, not only is the CD-ROM drive needed, but also the type of cable to plug that drive to the computer, a computer motherboard that has a connector for this cable, an operating system with drivers for these types of connectors, and a program able to open the file itself (Pearson, 2009, slide 11). All of these elements become rapidly obsolete themselves, which mean that media may not be easily accessible on current technology after just one or two decades, even if the storage media last longer than that. Therefore it is needed to periodically migrate (a process also called “refreshing”) the bitstreams from a media type to a more contemporary one in order to ensure that this bitstream will remain easily accessible (Harvey, 2012). As the bitstream is preserved, only the question of software is left.

# Who must preserve, and what we should keep

Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era. But as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterise the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and for many publishers the task of preservation is new to them (Harvey, 2012, p. 32); they might not have the awareness, knowledge or resources to do so themselves it is therefore essential that they collaborate with preservation organisations, such as libraries and archives (Ayre and Muir, 2004). See Harvey (2012, chapter 9), Ayre and Muir (2004) and UNESCO (2003, chapter 11) for more resources and case studies. Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Ebrary) or publishers directly (ACM, Elsevier Science, Springer).

# How to preserve

There are multiple methods for preservation. Each has advantages and issues, although one parameter is particularly influential: **authenticity**. This refers to the faithfulness of the rendition of the preserved object in the future, compared to when it was created; while the content should not be altered, its presentation may change (Cook, 2000). What is considered appropriately authentic is subject to debate (del Pozo et al., 2012, p. 7; Cook, 2000) and may vary depending on the preservation intent; del Pozo et al. (2012, p. 8) give, as example, the normalisation of a spreadsheet to formats that may accurately retain either the formatting, or the formulae used in each cell.
Retaining integrity, that is ensuring the object is “what it purports to be” and is “complete and has not been altered or corrupted” (Ross, 2002, p. 7, cited in Harvey, 2012, p. 54), can also be crucially important, particularly for proving that a business or legal document has not been tampered with (Harvey, 2012, p. 54). But as Lynch (2000), UNESCO (2003, p. 22) and Harvey (2012, p. 54) argue, integrity is mostly a matter of trust and can only be ensured with a thorough documentation of the archiving process.


## Methods for software preservation

*NB: due to the length limit of this literature review, I only give a simplified overview of the main archiving techniques. See Granger (2000), Thibodeau (2002) and Harvey (2012) for a comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.*

* **Hard copies**: print documents to archive them. Rarely considered a viable option for large data sets and interactive documents (Granger, 2000; Rothenberg, 1999).
* **Computer Museums**: Swade (1993) proposed to preserve hardware and software centralised places. Considered short-term and prohibitely expensive by Granger (2000) but can be useful to recover old media or testing emulators (Rothenberg, 1999).
* **Migration**: the most popular option, consisting of periodically saving files to a current file type (newer version of a format, different format, or a standardised format) (Granger, 2000; Thibodeau, 2002) to avoid technological obsolescence. It is labour intensive and risky, as it compromises authenticity (Rothenberg, 1999).
* Universal Virtual Computer (UVC): proposed by Lorie (2000, in Thibodeau, 2002, p. 22). It consists of implementing a format viewer in a portable programming language like Java [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine (itself low-level, different for every platform) which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.] which could then theoretically run on any future platform supporting that programming language. It is however slow and functionally limited (Lorie 2000), and runs the risk of the portable language itself becoming obsolete.
* **Emulation** is the most conservative model; it simulates a legacy architecture on current platforms, allowing to run the original software used to create a file, therefore not modifying them. It “keeps the look and feel as well as the interactivity” (Granger, 2000) therefore is highly relevant for video games (Guttenbrunner et al., 2010) and interactive systems, and it guarantees authenticity.
It is however highly complex to implement (Granger, 2000; byuu, 2011) and need renewal, since emulators themselves become obsolete (Thibodeau, 2002), as exemplified by emulators provided by Apple for their architecture switches (Mesa, A. F., 1997; AppleInsider, 2011) that were later discontinued, effectively removing the ability to run pre-2005 applications on their current models.

## Choosing a method

Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method. It must be:
* technically feasible
* sustainable and resistant to technological obsolescence
* practical (the preserving organisation must have the resources to do it)
* appropriate to the type of material being preserved, and the objectives of the preservation (see del Pozo et al., 2012, p. 7 and Granger, 2000 for examples).

# Personal archiving

It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal corespondance and sentimental artifacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will be able to understand our modern life without these exchanges. While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.

Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.

However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. Fortunately, digital objects have fundamental properties that physical artifacts don’t have, which actually provide numerous advantages in terms of preservation: the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost-free (Banks, 2011).

The cataloguing advantage allows us to process it using computer science. Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable information.
Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
> “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.” (Hangal et al., 2011)

The copying advantage, while useful for sharing, has issues for backing up. Banks (2011) notes the process is still troublesome, and still *feels* insecure because of cheap looking media, and nowadays, the abstraction with cloud storage (about Flickr: “I have no idea what kind of hardware my files are now stored on or even where they are geographically. I just expect to have access to them as long as I pay my bills” Banks, 2011, p. 27).

Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining we could also digitally augment physical objects or places. Banks (2011) gives as example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos. A similar technique is used in bigger preservation projects to make high quality 3D models of culturally important places and objects in China (Zhou et al., 2012).