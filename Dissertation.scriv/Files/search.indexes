<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="53">
            <Title>Need for preservation</Title>
            <Synopsis>Get the FULL context and relationship — why is there a shift to digital in storing stuff that’s emotionally important, precisely what in the nature of social networks prove that they will disappear and that their content needs to be preserved. </Synopsis>
            <Notes>Reference The Archive Team, and Jason Scott’s arguments/talks for cultural preservation of data

Use divergent technique &gt; keep asking WHAT IS… WHAT IS… WHAT IS to define memories, statuses, social networks, communities, internet etc

Correct data to singular</Notes>
        </Document>
        <Document ID="29">
            <Title>LiteratureReview</Title>
        </Document>
        <Document ID="54">
            <Title>Guru's Day Questions</Title>
            <Text>Title of your project: Social media backups
Question for the gurus (40 words): How could I design an interface that would allow users to go through a lifetime of digital memories in a meaningful and organised way?
Description of your project (50 words): A time capsule for the contents that you post on social networks, to keep your digital memories safe and organised over decades, just like diaries or photo albums. The project aims to use open design to be sustainable.</Text>
        </Document>
        <Document ID="80">
            <Title>Open design</Title>
            <Synopsis>Talk about need for openly designed hardware and software and documentation (+ preservation of that documentation)</Synopsis>
            <Text>[Talk about need for openly designed hardware and software and documentation (+ preservation of that documentation)]
</Text>
        </Document>
        <Document ID="55">
            <Title>Lecture: structure</Title>
            <Text>10/10/14 - towards a first draft

draft: 12 noon, 27th October, hard copy, bind if needed
NOT about trying to write sth coherent, well argued &amp; well written
it’s about finding a *structure*
organising thoughts &amp; planning wht you want to write
block in ideas, supporting material
organise material using “containers”
	literally (moving paper notes) or metaphorically
	label (headings)
	macro/micro headings
think of it as a design problem, not a writing assignment
words = things, can be manipulated, altered, changed, swapped or thrown away
			= thing that can be shaped
organise into §s and headings
	ok to use empty ones &amp; them as placeholders
	if copying-pasting chunks of other own material, highlight it to be reminded to edit/rewrite
	&lt;Notes to self&gt;

# contains
- title
- ToC
- ToFigures
- Intro = summary of what is to follow, maybe do it first, 1-2pages
- Chapters / body
- Conclusions
- References - further reading / separate bibliography + reference list
- Appendices &gt; from primary research
	- transcript interviews or only sections of it

@todo test Scrivener
</Text>
        </Document>
        <Document ID="81">
            <Title>Choosing a method</Title>
        </Document>
        <Document ID="56">
            <Title>Timelines podcast</Title>
        </Document>
        <Document ID="82">
            <Title>New contexts for personal archiving</Title>
            <Synopsis>It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal correspondence and sentimental ar- tefacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will be able to understand our modern life without these exchanges.
</Synopsis>
        </Document>
        <Document ID="57">
            <Title>Desire to visualise differently</Title>
            <Text>
&gt;&gt; in time representation</Text>
        </Document>
        <Document ID="83">
            <Title>Introduction copy</Title>
        </Document>
        <Document ID="58">
            <Title>Transcript </Title>
            <Text>
Ben Hammersley {Haynes:2014aa} @ 13:00 on the irrelevance of timelines
It’s artificial and it comes from the constraints that the timeline gives in describing your life. […] As human beings we all do multiple things at the same time. And so to try [to avoid that] instead of being a timeline it would be multiple timelines, and some interests would fade away and some parts of our lives would [shine?]. It’s not a single line but because the format forces you into a single line there’s a natural convergence within the crowd to specific measurable things. So if you see that everyone else puts their GCSE results on there, then even if you were 16 and the thing that was most important to you was your ballet class rather than your maths GCSE, then you wouldn’t put your ballet class there, you would put the GCSEs. There is a sort of crowd following thing, of “that’s the appropriate thing to post at that point in the timeline on Facebook”, but that’s not necessarily indicative of your own personal values, it’s just something that’s brought about by the architecture of [Facebook]. 
Aleks K disagrees
The only difference is that they’re there for the record. If you think about playgrounds dynamics, you would have seen exactly the same thing. Everybody would be sitting around talking about their GCSE results, not throwing out that they’re absolutely in love with ballet. What the web does, which is extraordinary — and especially for a psychologist like myself, is that there’s all these unspoken things that happen, there’s all these dynamics that happen, socially. Whether it’s to do with indicators of trust in another person, or indicators of belonging to a particular group, that, historically, throughout our social and psychological lives, we have expressed. That is literally what the study of social psychology is, it’s trying to identify and map, and unfortunately in many ways predict, what people will do and how people will behave and how people will think and act based on the dynamics of what’s going on, the dynamics that often appear quite subjective, because you’re experiencing them in your head. However, what the web does, in a really exciting way, is that it makes that visible. So suddenly you’re seeing these influence pathways, those influence patterns in the playground, which, if you were a teacher, you’d be able to describe. Now everybody can see it, and now we can see how we can form in everyday lives, based on the signals of our social groups. So I completely disagree that it’s forcing us into conformity; there’s lots and lots of different influences. The only area where I fear for is enforcing conformity. It’s the inability for people to make mistakes, because these mistakes, given how it is that we’re interacting with this information online now, those mistakes are therefore the record, which means that people will go back and they’ll look at the mistakes and they’ll define you by the mistakes that you’ve made in the past that you may have learned from, but you haven’t been able to leave them behind you because they’re there.</Text>
        </Document>
        <Document ID="84">
            <Title>Storage media</Title>
            <Synopsis>Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612–613)), this cannot be applied to digital storage media because their lifetime is much shorter. This varies highly with the type of medium used and with the storage conditions; for example, samples by the Digital Preservation Coalition (2008, p. 154) show that D3 cartridge tapes deteriorates after 50 years in optimal conditions (25% RH at 10o) but only one year in high humidity and temperatures (50%RH at 28o). Similar results happen for the more commercially available optical media (down to three months and up to 200 years), which are more sensitive to moisture (Harvey, 2012, p.47).</Synopsis>
            <Text>The most important threat to digital data as identified by UNESCO (2003, pp. 30–31) are the carriers used to store these materials. Most of them “are usually unstable and deteriorate within a few years or decades at most”. </Text>
        </Document>
        <Document ID="59">
            <Title>Untitled</Title>
        </Document>
        <Document ID="85">
            <Title>Access of media</Title>
            <Synopsis>ven if storage media could survive decades or even centuries, technological change means we will not necessarily have the means to access the data later. In other words, “to retain appropriate access to a digital object, we must maintain a mechanism to derive meaning from that object” (del Pozo et al., 2012, p6): for optical media, this includes not only the drives to read the disc, but also a cable to connect the drive to the computer’s motherboard, a motherboard that has a connector for this type of cable, and an operating system that has drivers for this connectivity (Pearson 2009, slide 11). Once we have access to the bitstream from the computer we need to be able to represent it, which means we also need to keep the software in a version that can open the preserved file. There is a myth, kept by both customers and vendors, that media is long-lived: “[An IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” (Weathley, 2003, cited by Harvey, 2012, p. 37)</Synopsis>
            <Text>“Use of digital materials depends on means of access that work in particular ways: often complex combinations of tools including hardware and software, which typically become obsolete within a few years and are replaced with new tools that work differently” (UNESCO, 2003). Even if storage media could survive decades or even centuries, technological change means we will not necessarily have the means to access the data later. In other words, “to retain appropriate access to a digital object, we must maintain a mechanism to derive meaning from that object” (del Pozo et al., 2012, p6): for optical media, this includes not only the drives to read the disc, but also a cable to connect the drive to the computer’s motherboard, a motherboard that has a connector for this type of cable, and an operating system that has drivers for this connectivity (Pearson 2009, slide 11). Once we have access to the bitstream from the computer we need to be able to represent it, which means we also need to keep the software in a version that can open the preserved file. There is a myth, kept by both customers and vendors, that media is long-lived: “[An IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” (Weathley, 2003, cited by Harvey, 2012, p. 37)
</Text>
        </Document>
        <Document ID="86">
            <Title>Software</Title>
            <Synopsis>“Access barriers such as password protection, encryption, security devices, or hard-coded access paths may prevent ongoing access beyond the very limited circumstances for which they were designed”

need to keep crawlers up to date if archiving functions are not provided
</Synopsis>
        </Document>
        <Document ID="87">
            <Title>Patents</Title>
        </Document>
        <Document ID="88">
            <Title>First draft</Title>
            <Text>
# Introduction

As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts. This literature revim
ew aims to get an overview of the current problems, techniques and practices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the various methods used to do so. It also encompasses legal and ethical issues arising from it,  and how the paradigms and methods change when applied to different types of archiving (e.g. for researchers, for businesses, and for personal businesses).

# Why digital preservation
[Stats of numbers on digital vs physical]

## Why digital degrades faster
### 	UNESCO’s Threats to digital continuity
UNESCO (2003, pp. 30-31) has identified a list of threats to what they call *digital continuity*. These are:
+ “The carriers used to store these digital materials are usually unstable and deteriorate within a few years or decades at most”. Where, in the traditional preservation paradigms for paper-based artifacts, the main rule is that “benign neglect may be the best treatment” (derived from Cloonan (1993, p.596), Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612-613)),  this cannot be applied to digital storage media because their lifetime is much shorter. This varies highly with the type of medium used and with the storage conditions; for example, samples by the Digital Preservation Coalition (2008, p. 154) show that D3 cartridge tapes deteriorates after 50 years in optimal conditions (25% RH at 10º) but only one year in high humidity and temperatures (50%RH at 28º). Similar results happen for the more commercially available optical media (down to three months and up to 200 years), which are more sensitive to moisture (Harvey, 2012, p.47).

+ “Use of digital materials depends on means of access that work in particular ways: often complex combinations of tools including hardware and software, which typically become obsolete within a few years and are replaced with new tools that work diﬀerently” (UNESCO, 2003). Even if storage media could survive decades or even centuries, technological change means we will not necessarily have the means to access the data later. In other words, “to retain appropriate access to a digital object, we must maintain a mechanism to derive meaning from that object” (del Pozo et al., 2012, p6): for optical media, this includes not only the drives to read the disc, but also a cable to connect the drive to the computer’s motherboard, a motherboard that has a connector for this type of cable, and an operating system that has drivers for this connectivity (Pearson 2009, slide 11). Once we have access to the bitstream from the computer we need to be able to represent it, which means we also need to keep the software in a version that can open the preserved file.
There is a myth, kept by both customers and vendors, that media is long-lived: “[An IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” (Weathley, 2003, cited by Harvey, 2012, p. 37)

+ Poor preservation documentation and metadata means it could be hard for potential users to find the data (UNESCO 2003)
+ + poor preservation (“Critical aspects of functionality, such as formatting of documents or the rules by which databases operate, may not be recognised and may be discarded or damaged in preservation processing.”, UNESCO 2003) + “So much contextual information may be lost that the materials themselves are un- intelligible or not trusted even when they can be accessed” -&gt; poor integrity

+ “Materials may be lost in the event of disasters such as fire, flood, equipment failure, or virus or direct attack that disables stored data and operating systems”
+ “Access barriers such as password protection, encryption, security devices, or hard-coded access paths may prevent ongoing access beyond the very limited circumstances for which they were designed”. [This argument is particularly true for web archiving, where crawlers of national libraries retrieve all sort of files to preserve them but do not necessarily have the permission or know the rights owner] [back that up maybe yo]

## Importance of data

### Library material: for society

&gt; “if we librarians do not rise to the occasion, successive generations will know less and have access to less for the first time in human history. This is not a challenge from which we can shrink or a mission in which we can fail” (Gorman, 1997, cited in Harvey, 2012, p. 27)

### For businesses (records)
### Personal archiving / domestic archiving
### Preserving interactive material inc. video games

In addition to the preservation of “static” documents and images, there is a significant desire to preserve video games, which are getting recognised as a form of art similarly to movies and music. The Library of Congress (2007) gave awards for the preservation of video games; there is a growing interest in being able to play “retro” games, but the consoles are obsolete. A large community of hobbyists reverse engineered consoles and produced emulators of these platforms for PC and other platforms different from their intended one. Because no documentation is available, this is a Herculean task; byuu (2011), the developer of an emulator for Super Nintendo games, recalls this for reengineering certain cartridges:

&gt; [Low-level emulation] is also a very expensive operation, monetarily speaking: to obtain the DSP program code requires melting the integrated circuit with nitric acid, scanning in the surface of a chip with an electron microscope, and then either staining and manually reading out or physically altering and monitoring the traces to extract the program and data ROMs. This kind of work can cost up to millions of dollars to have done professionally, depending upon the chip's complexity, due to the extremely specialized knowledge and equipment involved.  (byuu, 2011)

Obviously this is not necessarily a route many institutions would like to take for preserving digital objects. Because this also causes intellectual property issues, Nintendo and Sony have launched their own preservation programs, allowing players to play “classic” games on the newer generations of consoles; this is a far more accurate emulation (as they do have the internal documentation to create these emulators) and respects their monetary interests (players have to buy the games, whereas in hobbyist emulation, you would have to download the game file).

### Useful for researchers in the future

Beyond the governmental and cultural needs for preservation, there is also great need for preserving scientific data. “Data are the foundation on which scientific, engineering, and medical knowledge is built” (Committee on Ensuring the Utility and Integrity of Research Data in a Digital Age, 2009, p. ix, cited in Harvey, 2012, p. 26); therefore it is crucial in a digital era, with enormous data sets and research papers becoming widely public, to ensure this doesn’t disappear.

#### Understanding our history

There is a need to define what is the purpose of archives. As a tool to learn from the past, or to keep records, but as Cook (2000) eloquently puts it:
&gt; “Archives […] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)

Preservation should, therefore, be considered very important. There is some skepticism to this:

&gt; “It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002).
&gt; Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole… truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. 
&gt;[…]
&gt; It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33-34)

While it’s difficult to argue that preserving digital objects is necessary, there is certainly a need to define what deserves to be protected, and to what level.

#### Understanding the beginnings of the Internet, as we have shifted in an information society
##### Preserving an accurate + [integrity] image of our society at a given point

###### Twitter &amp; Usenet

Camille Paloque-Bergès (2011; 2013) proposes that we can already find historical and sociological evidence of a given period in Internet time when browsing archives of Usenet [footnote: An Internet discussion system established in the 1980s and that is widely regarded as the predecessor of the Web and online fora]. She analysed how the way of speaking has evolved [footnote: See also http://wwwtxt.org (or @wwwtxt on Twitter), a project collecting short phrases of the Usenet to demonstrate this] and how an self-organised community had built itself, noting that we can “feel [the community’s] informational generativity” and understand that one of the biggest qualities of the early users of the Internet was their “recursivity as a public” (Paloque-Bergès, 2013); that is, how they welcomed newcomers — notably through the use of FAQs [footnote: Frequently Asked Questions], which weren’t a common concept back then. There are also large elements of nostalgia coming back (Paloque-Bergès, 2011).

It is also interesting to come back on the archival of Usenet. The messages were not systematically archived, and obviously not available on the Web as it did not exist and is separate. Today’s collections have mainly been recreated from donations of people who did archived Usenet newsgroup, originally to DejaVu News in 1995, and Google Groups in 2001.
A number of privacy concerns were raised with the publication of these searchable archives; messages who were, 15 to 20 years earlier, thought to be confidential are now considered as digital heritage. There was also a large backlash against the archiving made by for-profit companies, and the credit taken later by Google for its donors, with other critiques like Brad Templeton’s (an Internet veteran and important figure; cited in Paloque-Berges, 2013)  remark that the archive was lacking in integrity. However, the searchability of these archives did bring welcomed technical possibilities for an Internet historiography, including a timeline where “the announcement of the Chernobyl disaster on Usenet stands alongside the first message of Linus Torvalds calling for help on what would become the Linux operating system” (Paloque-Bergès, 2013). 

Similar concerns appeared at the announcement of the archival of Twitter by the Library of Congress in 2010. The two are not really comparable, mostly because the archive is not public and is made by a not-for-profit body. On the mailing list of the Association of Internet Researchers, the idea was met with interest: “The public twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important” (Baym, 2010) [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021125.html]”. However, the privacy concerns (notably with public and private feeds) were discussed, and as Michael Zimmer remarked:
&gt; “This is the classic “but the information is already public” argument that, while technically true, presumes a false dichotomy that information is either strictly public or private, ignoring any contextual norms that might have guided the initial release of information or how a person expects that information to flow.” (Zimmer, M. [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021136.html]; see also his paper (2010) on Facebook privacy, going further in that argument) 

Paloque-Bergès (2010) theorises this argument, suggesting that “information is not an object, but a statement; it goes through socio-technical processes; it doesn’t have an objective nature”. A message in a tweet can have a very different context when taken apart of the moment it was posted. It also emphasises that privacy could change (the user could, later, switch their account to Private, delete the tweet or their account altogether, but this wouldn’t be reflected in the archive. We cannot know what is the user’s original intent when they posted their message, and, as Paloque-Bergès (2010) noted, we aren’t sure the user themselves know.
&gt; “More often than not, in a technical ecosystem in which making content private is more difficult than sharing broadly, teens choose to share, even if doing so creates the impression that they have given up on privacy. It’s not that every teen is desperate for widespread attention; plenty simply see no reason to take the effort to minimize the visibility of their photos and conversations.” (Boyd, 2014).

## Advantages over physical preservation
### Mass preservation, easier access and organisation

### Recording digitally material that’s not born-digital
## Cost of restoration; case studies of lost data

A number of institutions have already experienced loss of data, or data being corrupted. This can have disastrous consequences for businesses, for example, as noted by McAteer (1996, cited by Ross and Gow, 1999, p. iii): “of the 350 companies unexpectedly relocated by the [1993] World Trade Centre (NYC) bombing 150 [43%] ceased trading,
many because they lost access to key business records held in electronic form”. 

Data can, obviously, be sometimes restored. Ross and Gow (1999, pp. 39-42, referenced in Harvey, 2012, p. 34) provide a number of case studies. Harvey (2012, p. 34) also gives the ironic example of the website for the “Functional Requirements for Evidence in Recordkeeping” project, directed by the University of Pittsburgh which was accidentally deleted; but thankfully was automatically saved by the Internet Archive.

There is still the possibility of restoring data by specialised carriers; however Pearson (2009, slide 15) notes that while this was generally effective, this did not work on some items. He also regrets that the restoration loses all metadata in the process; this can be an issue for sensitive or classified information (for business or governmental archives) as the carrier would be able to see it; finally, it is a prohibitely expensive operation, and so a carefully planned preservation could be much cheaper (and obviously more reliable) than neglect.
However, these services are always useful in certain cases. Harvey (2012, p. 41) cites the statistics by the data recovery giant Kroll Ontrack (2011): “hardware and system problems cause most customers to approach them (29 per cent), followed by human error (27 per cent). Software corruption or program problems, computer viruses and natural disasters are the other reasons listed.”

# Defining paradigms for digital preservation
### Pre-digital paradigms
### Inability to preserve the medium, only the bitstream
### Importance of metadata, relationship &amp; context
### Definition of terms		
		
# What to preserve / Selectivity
## Harvey 5 pillars for selectivity (Harvey 2012, p. 26)
* If **unique information** objects that are vulnerable and sensitive and therefore subject to risks can be preserved and protected
* If preservation ensures long-term accessibility for researchers and the public;
* If preservation fosters the accountability of governments and organisations
* If there is an economic or societal advantage in re-using information
* If there is a legal requirement to keep it (NSF-DELOS Working Group on Digital Archiving and Preservation, 2003, p.3).

### Banks reasons for domestic archiving
In *The Future of Looking Back*, Richard Banks (2011) analyses the reasons that lead us to keep or discard physical objects at home. He argues that while making a selection is a positive thing because it forces us to filter our belongings and focus on what is really meaningful, we also run the risk of ridding ourselves of things that we wish we would have kept in retrospect. He points out that the organisation of digital files make this trickier: because we we can keep pretty much everything on virtual space, it is easier to accidentally delete meaningful things alongside the less important. (Banks, 2011 p. 22).

In the context of personal archiving, Banks notes that in the past, the legacy we leave behind us was a highly selective one. Because our possessions are limited by physical space, our ancestors until now “have implicitly indicated that an item is significant through the simple act of keeping it. Although thousands of objects likely crossed their path over their lifetime, the constraints of money and space meant that only a few were retained, often the most significant.” (Banks, 2011, p. 78). He does however argue that this is no longer true in a digital world, because new possibilities mean we simply accumulate digital objects without necessarily ordering them by importance.

### Technical possibility of archiving

### Pros/cons of archiving the entire internet

There are various controversies around whether we should automate the archiving of the Internet, or if we should operate a manual selection. UNESCO (2003, p. 73) notes that those who value a more comprehensive collection (i.e. archiving “all” the Internet) argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything”. This argument is particularly true because of the digital media: “unlike non-digital material such as paper-based artifacts, where there is a period of time in which to make selection decisions before deterioration of materials becomes an issue, the time frame for deciding whether or not to preserve digital materials is very short” (Harvey, 2012, p. 57). UNESCO (2003, p.71) backs that claim: “it may not be possible to wait for evidence of enduring value to emerge before making selection decisions”.

Other people [Cook?] think that it would be preferable to keep a curated collection because of a higher technical quality, and this also allow us to settle [negotiate?] preservation rights with the content producers. Harvey adds that we also do not have the technical capabilities to find all the pages on the Internet, and even if we had we would not have the technical possibility to store the whole of the Internet (Harvey 2012, p. 58); again, this is also something recognised by UNESCO: “‘there are usually more things – more information, more records, more publications, more data – than we have the means to keep” (2003, p.70).

The UNESCO (2003) and Cook (2000) both however recognise that a middle ground should be found and that both approaches are valid depending on the goal of the preservation. For instance, the Internet Archive[IA] is going through an automated process (archive as many pages as possible) but, because of technical limitation, only preserves the text and dismisses all other images, stylesheets and external media, which could be critical in some instances. It seems evident that for valued documents these should be retained. The British Library’s Web Archive[ukwa] [http://www.webarchive.org.uk/ukwa/] 

###	Dangers of selection (Cook)
However, Cook (2000) points out the dangers of manual selection for what is worth archiving: “With memory comes the inevitable privileging of certain records and records creators, and the marginalizing or silencing of others” (Cook, 2000, cited in Harvey p. 58). He asserts that the archivists must be impartial and objective, and ensure all points of view are kept to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination”. This is something that is clear with manual archiving, but could also be a problem, maybe unintentionally, with the automated discovery of content when archiving Web pages.
		
### Automatic selection (Reputation model)
In order to keep the most valuable content, algorithms could be used. Kawano (2008) proposes to use reputation models, that attempts to determine the relative value of a Web page by considering its “importance, fairness, trustiness, uniqueness and valuation”. This is done using a variety of ways; the algorithm suggested by Kawano relies on the consistency of a web page, that is the amount of time it existed, the number of links it contains and the number of external links to this page  (Kawano, 2008, p. 291).

#### Crawling
#### Manual curating
	
### Special Collections for events (eg before elections, see webarchive.org.uk for other ideas)
Another interesting selection process that has emerged is the one of *specific archiving* when certain events are happening. For instance, the UK Web Archive[ukwa] has, on top of their topical-based collections (Energy, Health and Social Care…), a few event-based collections (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks…) which reflect the state of the Web at that given moment in history. Masanès (2006, p.83) notes that this type of archiving must be manually curated and thoroughly preparated. He gives a methodology for this, using presidential elections as an example: a time frame for the collection must be defined (“3 months before the election + 1 month after”), what type of sites will be archived and when (“the political parties’ blogs and websites, every week; analysis, commentary and humourous/satire websites, every month; online newspaper articles, once”).

[Opposing to automated archiving]: Masanès (2006) also describes the technique used for crawling a set of websites automatically. For example, when attempting to save all sites located in France for the French National Library, the robots were instructed to start navigating from 12 existing directories of websites, and restrict what they save to sites with a .fr domain name, or, for more generic top-level domain names (.com, .net, .org…), check if the phone number used for DNS[footnote explanation] registration is a French number (starting with +33). (Masanès 2006, p. 83)

### Selection: by genre [web]
There are different genres of websites: institutional website, blogs, personal pages, forums. [[Genre have been studied in the context of the Web to see how they replicate or diverge from the genre in the print- ing world (see Crowston and Williams 1997) - in Masanès p88]]. An interesting point about this is that often, robots (crawlers, or later data analysis) can automatically identify their type [Rehm 2002 -&gt; check reference, Masanès:88] which permits the automatic generation of metadata, or simply to restrict a collection of web pages to certain Web genres.

# Web archiving: what stands as heritage on the web

# Who should preserve

Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era; but as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterize the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and this is also true for businesses and personal data.
The Task Force on Archiving of Digital Information (1996, pp. 19-20) suggests that when, in general, “stakeholders disseminate, use, reuse, recreate and re-disseminate various kinds of digital information, they can easily, even inadvertently, destroy valuable information, corrupt the cultural record, [and ultimately thwart the pursuit of knowledge that is their common end]. Against such a danger, a safety net is needed to ensure that digital information objects with long-term cultural and intellectual value survive the expressions of stakeholder interest with their integrity intact.

[&gt; Society has always created objects and records describing its activities, and it has consciously preserved them in a permanent way… Cultural institutions are recognised custodians of this collective memory: archives, librar[ies] and museums play a vital role in organizing, preserving and providing access to the cultural, intellectual and historical resources of society. They have established formal preservation programs for traditional materials and they understand how to safeguard both the contextual circumstances and the authenticity and integrity of the objects and information placed in their care… It is now evident that the computer has changed forever the way information is created, managed, archives and accessed, and that digital information is now an integral part of our cultural and intellectual heritage. However the institutions that have traditionally been responsible for preserving information now face major technical, organisational, resource, and legal challenges in taking on the preservation of digital holdings (B. Smith, 2002, pp.133-134) [cited in Harvey p. 29].]

A variety of new stakeholders are now required to collaborate more for a good preservation practice to take place. Lavoie and Dempsey (2004, cited in Harvey, 2012, p. 30) argues that cooperation “can enhance the productive capacity of a limited supply of digital preservation funds, by building shared resources, eliminating redundancies, and exploiting economies of scale”. Chapter 11 of the UNESCO guidelines (2003) give more pratical details on how this can take place, giving structural models and tips on what to share (information, standards, division of labour…). [CLOCKSS cooperation to preserve journals (see Harvey p32 + chapter 9); + Harvey p32 National Library of Netherlands &amp; Elsevier Science + most uni libraries access with publishers, even UoD with eg Dawsonera/ACM]

## Legal issues
### (see later) special case for emulation

In certain cases, the archiving process is not made in accordance with the original publisher. This is often the case for the automated archiving of the Internet (e.g. Wayback Machine), which automatically crawl pages, but as a website publisher, it is easily possible to opt out of these schemes [see http://archive.org/about/exclude.php [Accessed 17th Apr 2014]].
In the case of emulation, this is what happens with *reverse engineering*, that is, disassembling the original program to understand how it works and recreate a similar version which can operate from a different hardware or software architecture. This is a common process for proprietary software or hardware, whose source code is not available to the general public and no documentation is provided for developers. Often, this is developed by amateurs and hobbyists, but is illegal as it breaks the intellectual property of the original creator; Nintendo, for example, attacks reverse engineered emulators[http://www.nintendo.com/corp/legal.jsp [Accessed 17th Apr 2014]] and the sharing of ROMs [Read Only Memory; the bitstream of cartridges or discs containing the games]. There is however popular demand for playing these, and Nintendo has developed their own emulators to play legacy games on their new consoles (see the Virtual Console [http://en.wikipedia.org/wiki/Virtual_Console]), while still retaining their property rights (you need to buy the games again on an e-commerce platform). This however causes issue for the longer term preservation: there is no certainty that Nintendo will continue to provide this service on their future generations of consoles, or if they ever cease operations.



A similar issue happened with Apple Computer. In 2005, Apple changed the architecture (that is, the “language” of instructions needed for the processor) of their personal computers from PowerPC to Intel x86. This means that applications needed to be rewritten, sometimes from the ground up, to work natively on the newer Apple computers. To ease the transition, Apple created **Rosetta**, a software that dynamically translates PowerPC instructions to x86 instructions, so that buyers of the new Apple computers were still able to open legacy applications that were not yet rewritten for x86 — although this came with a significant performance hit. In 2009 however, support for PowerPC was entirely discontinued […]

## Libraries

Good curating and preservation starts early. Smith (2003, pp. 2-3, cited in Harvey, 2012, p. 32) suggests that “the critical dependency of preservation on good stewardship begins with the act of creation, and the creator has a decisive role in the longevity of the digital object”. Harvey (2012, p. 32) notes that “for most creators of information in any form this is a new role”; therefore publishers of digital content are not necessarily well prepared for preservation, and this is why collaboration with librarians and archivists can be helpful (Ayre and Muir, 2004). 

Ayre and Muir (2004) note that if the publisher worries about preservation themselves then they generally already own the rights for preservation, but there are negotiations to be done if an external body helps with preservation. 

## National libraries

Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Elsevier Science) or publishers directly (ACM).
A report by Hedstrom and Montgomery (1998, cited by Ayre and Muir, 2004) found that most research librarians in the UK thought that a legal deposit to national archives was the best option, but this was not a clear consensus. The report also highlighted that these librarians thought that “other libraries and publishers would need to, and should, have some involvement in preservation”.

Because all preservation methods involve copying of the original object, it might be illegal to make such a copy without the necessary rights, even if it is for preservation purposes. Certain countries have laws to overcome this and allow national libraries to preserve all materials; Ayre and Muir (2004) list a few of them and their specificities, but the situation has since evolved, as a lot of legislations have enacted changes to specifically include digital materials.

## Archivists
## New stakeholders
## Profits vs nonprofits

Harvey (2012) points out doubts in the real interests of for-profit companies to achieve long-term preservation;
&gt; Even given the prevailing market-driven political ethos, it is difficult to envisage a situation where market forces will be sufficient to ensure the preservation of this digital material. The opposite is more likely to apply: ‘in some cases market forces work against long-term preservation by locking customers into proprietary formats and systems’ (Workshop on Research Challenges in Digital Archiving and Long-term Preservation, 2003, pp.x-xi). (Harvey, 2012, p. 32). [link with Google concerns]

# How to preserve
## Software methods
### Making hard copies
What appears to be the simplest solution is to make physical copies (i.e. print) of the digital documents. Although this certainly solves some problems in regards to technological obsolescence, Rothenberg (1999) and Granger (2000) pointed out that this cannot be done for more interactive material besides text and images. There is also, obviously, an issue with the amount of content that can be stored in this way — this would not work for archiving websites. Granger (2000) recognises that “if one’s sole concern is with the intellectual content of a document and the document is of a fairly simple nature […] this at least provides some form of security”.

### Standardisation

Standardisation is the transformation of a document’s content to a format that is standardised, open and well documented, ensuring that we will be able to open it with a variety of applications on a variety of platforms and that we can rebuild a program for visualising that document — as opposed to vendor-specific, closed source program that could be discontinued at any point in the future. Rothenberg (1999, p. 10) claims that this is a bad solution because “standardisation sows the seeds of its own destruction by encouraging vendors to implement non-standard features in order to secure market share” (therefore these non-standard features will be lost if opened in a different application). Granger (2000) argues that the blame is not to be put on the method, but on vendors.
Standardisation is a type of migration and therefore share some of it cons (notably, this absence of vendor-specific features could imply a loss in the presentation and other characteristics). Standards eventually become obsolete so it is also paramount to preserve the specifications of the format, or to define formats that are unambiguous, such as CSV or XML.

A slightly different approach to this method is rebuilding viewers. In this scenario, the bitstream is not migrated to a standardised format, but kept as is; we simply re-build a viewer that is able to read that format. This is not as straightforward as it sounds, because most of the time, formats for proprietary software are not documented and decrypting them would require reverse engineering. If they are documented, then it is likely that this format is already a standard. There exists cases where reverse engineering is possible, or where a non-standard format is documented; for example, Microsoft Word files are not a standard, but there is plenty of documentation available online to produce code able to read them. An experiment by the VERS project (Thibodeau 2002, p. 22) has shown that it is possible to reengineer a viewer for the PDF file format from the specification available; as long as we also preserve these specifications, we will be able to read PDF files in the future.

#### UVC

Lorie (2000, in Thibodeau, 2002, p. 22) has also proposed that the use of a portable programming language, such as Java [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine, which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.]. Lorie developed a software called Universal Virtual Computer (UVC), able to decrypt a variety of file formats, which can run on any platform supporting Java; because Java could be implemented on virtually any architecture, this means that a reader could be run on any platform without any effort. However, Lorie points out, this approach is limited in terms of functionality, and comes at the price of performance (because portable programming languages are platform-agnostic, this means the code is not optimised for any of the platforms). I am also wondering if this would really work on the long term, as we cannot be sure that future implementations of Java will be backward compatible with code written for a previous version.

### Migration

Migration is the transformation of a document’s content to a format that is not necessarily standardised, but at least current; or, the newer version of same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed (although this can be overcome by migrating to more flexible formats like PDF or LaTeX).
Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.

### Computer museums

Another approach to preservation, proposed by Swade (1993), would be to preserve a variety of hardware, software and devices to access obsolete media in “computer museums”. This is generally not considered a good solution; Granger (2000) notes that it would be unreasonably expensive to keep old machines running for an extended period of time, that computers chips will eventually decay anyway (and repair or replacement will be impossible), and that storage media not stand the test of time. There are still two possible use cases, identified by Rothenberg (1999): ensuring that emulators work as expected (by comparing them to original platforms), and helping with the recovery of lost data on obsolete media

### Emulation

Emulation is the dynamic transformation of instruction sets to allow software and/or operating system designed for an obsolete architecture or platform to run on current systems. It is a highly complex method that offers certain benefits; notably, this is the most conservative method, as it is not destructive of the content or presentation. It allows us to run the original program used to create a digital object without altering that bitstream ; it “keeps the look and feel as well as the interactivity” (Granger, 2000) and as such, it is particularly interesting for objects rich in interaction, such as video games, data visualisations, or formats that are particularly complex (for example, medical imagery, 3D modelisations), for which methods like migration would be hard. It also ensures complete integrity and authenticity, which could be crucial for some data types.

There are numerous criticisms against emulation. A number of legal and intellectual property problems are raised, if the emulation strategy is not supported by the original author [see Nintendo &amp; Apple]. The complexity involved in creating emulators might be not worth it and requires a coherent organisation to reduce overhead (Granger 2000). Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to the delivery of the preserved content; “most users in the future will never have encountered—not to mention learned how to use—most of the products they will need to access the preserved information objects”, and “it would cut users off from the possibility of using more advanced technologies for discovery, delivery, and analysis”.

&gt; “Emulators themselves become obsolete; therefore, it becomes necessary either to replace the old em- ulator with a new one or to create a new emulator that allows the old emulator to work on new platforms. In fact, if you get into an emula- tion strategy, you have bought into a migration strategy. Either strategy adds complexity over time.” (thibodeau 2002 p.20)

[NB: due to the length limit of this literature review, I have only explained the most popular archiving techniques. See Thibodeau (2002) and Harvey (2012) for a more comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.]

## Choosing one

Thibodeau (2002, pp. 15-16) suggests four criteria to choose a preservation method: *feasibility*, *sustainability*, *practicality* and *appropriateness*. 

Feasability means that the hardware and the software for implementing a given method must be existing and developed. 
Sustainability is ensuring that this method can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable”. This means that the method must be resistant to technological obsolescence, both for storing the data (medium will change) and accessing it (means to access the media ane decode the bitstream will change).

Practicality is establishing that this method will be reasonably difficult and affordable. [This can generally change depending on the resources of the preserving organisation, the available technology at that time and the valuation of the digital objects.]

Finally, appropriateness is using a method that is relevant to the type of material being preserved, and the objectives of the preservation. For example, del Pozo et al. (2012, p. 7) suggests that if the integrity and authenticity of the documents are not paramount, then a migration that keeps the contents but discards the presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).

### Authenticity/integrity and issues with each method

Different preservation methods yield different results in what is called **authenticity**, that is how faithful the rendition [its presentation] of the preserved object will be. Authenticity is subjective and therefore there is debate around this issue (Del Pozo et al., 2012, p. 7; Cook, 2000); however most agree that while as little difference in the presentation is desirable, it is rarely (if ever) possible to keep a truthful rendition. As an example, del Pozo et al. (2012, p. 8) use a spreadsheet within the migration method:
&gt; “For instance, one institution may decide to normalise a spreadsheet into a PDF, which would retain the cell values but destroy any formula used to calculate them. This would favour a particular presentation of that digital object over the information form of the original. On the other hand, another institution might decide to normalise spreadsheets into ODF, which may lose some formatting but retain the formula used to derive each cell. In this case, being able to retain the information form of the file would be seen as more important.”

Thibodeau (2002, p. 28) however points out that “people will want to use the best available technology—or at least technologies they know how to use—for discovery, retrieval, processing, and delivery of preserved information. There is a danger that to the degree that preservation solutions keep things unaltered they will create barriers to satisfying this basic user requirement.” An overly faithful preservation would therefore not be desirable. Again, this is subject to a high number of parameters.

Another important issue is *integrity*, i.e. “ensuring the object is complete and has not been altered or corrupted” (Harvey, 2012, p. 54; Ross [CITED], 2002, p. 7); that is, the object “is what it purports to be”, and no parts are missing from it. This is particularly important, Harvey (2012, p. 54) notes, for business archiving, where the legal value of a digital object could be lost if we cannot demonstrate that this object hasn’t been tampered with, or that a migration processes have not incurred data losses.
However, as Lynch (2000) has argued, the integrity of objects is only a matter of trust. The guidelines of UNESCO (2003, p. 22) recommend that the best protection for authenticity is proper documentation of the archival process; Harvey (2012, p. 54) expands on this idea: “for instance, if it can be established that a digital object has always been kept in the custody of an archive in which every change to it has been recorded (such as changes resulting from migration of the bit-stream – the dates at which migration occurred, to which media, and so on), then we can be more secure about its integrity.” 

### Emulation / legal rights with videogames



## Use of standards

Some standards such as OAIS (Open Archival Information System), originally developed for space science, could be used. Sadly [no implementation] [source??]

# Personal archiving

On a more personal level, Harvey (2012) and Lukesh (1999) note that personal correspondance might be lost if we do not take steps to preserve them:

&gt; “The widespread shift from writing letters to the use of email has diminished the likelihood that personal correspondence will remain accessible to future historians. Lukesh asked in 1999, ‘Where will our understandings of today and, more critically, the next century be, if this rich source of information is no longer available?’, as scientists, scholars, historians and almost everyone increasingly use email” (Lukesh, 1999) (in Harvey, 2012 p. 32)

While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.

Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.
However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited; second, storing photos and data on online services mean we may forget about them in a few years (Banks, 2011).

## What happens after our death
### [Digital heritage]
## Shifts in usages (more photos)
## Advantages (sharing, organisation etc.); record part of our lives we never did before

Digital artifacts have certain fundamental advantages over physical objects: the main two being the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost-free (Banks, 2011). This actually provides numerous advantages in terms of preservation. 

[[+ tie with “In the past ancestors have signified something is important simply by keeping it” part ]]

The first one, ease of organisation, can be significantly helpful in tackling the abundance of digital data. Banks (2011) suggests that the technologies lying behind the ranking in the result of Web search engines could, eventually, help us in understanding and finding what is our most important data. An attempt has been made by the MUSE (Memories USing Email) project (Hangal et al., 2011), which aims to find patterns in our emails archives to help us make sense of this large data set. As the authors note in the introduction:

&gt; “Email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later, and thereby use their email account as an informal backup device. Therefore, email archives contain or reflect memories that are extremely valuable for the purposes of reminiscence.” (Hangal et al., 2011)

Early users reported that they have been using it to: make a summary of their work progress over the year; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; renewing with old relationships; and serendipitous discovery. The authors note in the conclusion that the different uses of their program went beyond their original expectations of simply reminiscing: “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.”

The second advantage, the ability to accurately and easily make copies and backups, is fairly obviously an advantage for personal preservation. However, Banks (2011) notes, the process of backing up is troublesome and storage media do not make our data immune. Additionally, the use of online services to store our data creates an abstraction between the storage material and us; about Flickr: “I have no idea what kind of hardware my files are now stored or even where they are geographically. I just expect to have access to them as long as I pay my bills” (Banks, 2011, p. 27).

## Keeping memories attached to digital objects

Banks (2011) also suggests that we could blend in the physical and the digital to allow recording of things we never had the opportunity to before. He gives as example the Weather Camera, an experimental object by Kjen Wilkens (2011) that records wind and temperature along with commentary, instead of an image, as an alternative to recall a place; or 3D backups by Héctor Serrano (2009), another experimental project that allows us to make backups of sentimentally important objects through 3D scanning and 3D printing. 
Similarly, Banks notes tools by Microsoft Research to recreate places in a 3D environment based on photos, allowing to recreate a sentimentally important place at any given point in time provided enough photos are available. A similar technique is used in bigger preservation projects, as described by Zhou et al. (2012), to make high quality 3D models of culturally important places and objects in China.

Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining that we could augment physical objects with RFID tags (and I would add, virtual reality technologies) to pass down stories attached to these objects.

Conclusion</Text>
        </Document>
        <Document ID="89">
            <Title>Long draft</Title>
            <Text>Introduction
As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts. This literature review aims to get an overview of the current problems, techniques and practices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the various methods used to do so. It also encompasses legal and ethical issues arising from it, and how the paradigms and methods change when applied to different types of archiving (e.g. for researchers, for businesses, and for personal businesses).
Why digital preservation
[Stats of numbers on digital vs physical]
Why digital degrades faster UNESCO’s Threats to digital continuity
UNESCO (2003, pp. 30–31) has identified a list of threats to what they call digital continuity. These are: + “The carriers used to store these digital materials are usually unstable and deteriorate within a few years or decades at most”. Where, in the traditional preservation paradigms for paper-based artifacts, the main rule is that “benign neglect may be the best treatment” (derived from Cloonan (1993, p.596), Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612–613)), this cannot be applied to digital storage media because their lifetime is much shorter. This varies highly with the type of medium used and with the storage conditions; for example, samples by the Digital Preservation Coalition (2008, p. 154) show that D3 cartridge tapes deteriorates after 50 years in optimal conditions (25% RH at 10o) but only one year in high humidity and temperatures (50%RH at 28o). Similar results happen for the more commercially available optical media (down to three months and up to 200 years), which are more sensitive to moisture (Harvey, 2012, p.47).
“Use of digital materials depends on means of access that work in
￼￼
particular ways: often complex combinations of tools including hardware and software, which typically become obsolete within a few years and are replaced with new tools that work differently” (UNESCO, 2003). Even if storage media could survive decades or even centuries, technological change means we will not necessarily have the means to access the data later. In other words, “to retain appropriate access to a digital object, we must maintain a mechanism to derive meaning from that object” (del Pozo et al., 2012, p6): for optical media, this includes not only the drives to read the disc, but also a cable to connect the drive to the computer’s motherboard, a motherboard that has a connector for this type of cable, and an operating system that has drivers for this connectivity (Pearson 2009, slide 11). Once we have access to the bitstream from the computer we need to be able to represent it, which means we also need to keep the software in a version that can open the preserved file. There is a myth, kept by both customers and vendors, that media is long-lived: “[An IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” (Weathley, 2003, cited by Harvey, 2012, p. 37)
Poor preservation documentation and metadata means it could be hard for potential users to find the data (UNESCO 2003)
poor preservation (“Critical aspects of functionality, such as formatting of documents or the rules by which databases operate, may not be recognised and may be discarded or damaged in preservation processing.”, UNESCO 2003) + “So much contextual information may be lost that the materials themselves are un- intelligible or not trusted even when they can be accessed” -&gt; poor integrity
“Materials may be lost in the event of disasters such as fire, flood, equipment failure, or virus or direct attack that disables stored data and operating systems”
“Access barriers such as password protection, encryption, security devices, or hard-coded access paths may prevent ongoing access beyond the very limited circumstances for which they were designed”. [This argument is particularly true for web archiving, where crawlers of national libraries retrieve all sort of files to preserve them but do not
￼￼￼￼￼￼
necessarily have the permission or know the rights owner][back that up maybe yo]
Importance of data Library material: for society
“if we librarians do not rise to the occasion, successive generations will know less and have access to less for the first time in human history. This is not a challenge from which we can shrink or a mission in which we can fail” (Gorman, 1997, cited in Harvey, 2012, p. 27)
For businesses (records)
Personal archiving / domestic archiving
Preserving interactive material inc. video games
In addition to the preservation of “static” documents and images, there is a significant desire to preserve video games, which are getting recognised as a form of art similarly to movies and music. The Library of Congress (2007) gave awards for the preservation of video games; there is a growing interest in being able to play “retro” games, but the consoles are obsolete. A large community of hobbyists reverse engineered consoles and produced emulators of these platforms for PC and other platforms different from their intended one. Because no documentation is available, this is a Herculean task; byuu (2011), the developer of an emulator for Super Nintendo games, recalls this for reengineering certain cartridges:
[Low-level emulation] is also a very expensive operation, monetarily speaking: to obtain the DSP program code requires melting the integrated circuit with nitric acid, scanning in the surface of a chip with an electron microscope, and then either staining and manually reading out or physically altering and monitoring the traces to extract the program and data ROMs. This kind of work can cost up to millions of dollars to have done professionally, depending upon the chip’s complexity, due to the extremely specialized knowledge and equipment involved. (byuu, 2011)
Obviously this is not necessarily a route many institutions would like to take for preserving digital objects. Because this also causes intellectual
￼￼￼
property issues, Nintendo and Sony have launched their own preservation programs, allowing players to play “classic” games on the newer generations of consoles; this is a far more accurate emulation (as they do have the internal documentation to create these emulators) and respects their monetary interests (players have to buy the games, whereas in hobbyist emulation, you would have to download the game file).
Useful for researchers in the future
Beyond the governmental and cultural needs for preservation, there is also great need for preserving scientific data. “Data are the foundation on which scientific, engineering, and medical knowledge is built” (Committee on Ensuring the Utility and Integrity of Research Data in a Digital Age, 2009, p. ix, cited in Harvey, 2012, p. 26); therefore it is crucial in a digital era, with enormous data sets and research papers becoming widely public, to ensure this doesn’t disappear.
Understanding our history
There is a need to define what is the purpose of archives. As a tool to learn from the past, or to keep records, but as Cook (2000) eloquently puts it:
“Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)
Preservation should, therefore, be considered very important. There is some skepticism to this:
￼￼
“It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
While it’s difficult to argue that preserving digital objects is necessary, there is certainly a need to define what deserves to be protected, and to what level.
Understanding the beginnings of the Internet, as we have shifted in an information society
Preserving an accurate + [integrity] image of our society at a given point Twitter &amp; Usenet
Camille Paloque-Bergès (2011; 2013) proposes that we can already find historical and sociological evidence of a given period in Internet time when browsing archives of Usenet [footnote: An Internet discussion system established in the 1980s and that is widely regarded as the predecessor of the Web and online fora]. She analysed how the way of speaking has evolved [footnote: See also http://wwwtxt.org (or @wwwtxt on Twitter), a project collecting short phrases of the Usenet to demonstrate this] and how an self-organised community had built itself, noting that we can “feel [the community’s] informational generativity” and understand that one of the biggest qualities of the early users of the Internet was their “recursivity as a public” (Paloque-Bergès, 2013); that is, how they welcomed newcomers — notably through the use of FAQs [footnote: Frequently Asked Questions], which weren’t a common concept back then. There are also large elements of nostalgia coming back (Paloque-Bergès, 2011).
It is also interesting to come back on the archival of Usenet. The messages were not systematically archived, and obviously not available on the Web as
￼￼
it did not exist and is separate. Today’s collections have mainly been recreated from donations of people who did archived Usenet newsgroup, originally to DejaVu News in 1995, and Google Groups in 2001. A number of privacy concerns were raised with the publication of these searchable archives; messages who were, 15 to 20 years earlier, thought to be confidential are now considered as digital heritage. There was also a large backlash against the archiving made by for-profit companies, and the credit taken later by Google for its donors, with other critiques like Brad Templeton’s (an Internet veteran and important figure; cited in Paloque- Berges, 2013) remark that the archive was lacking in integrity. However, the searchability of these archives did bring welcomed technical possibilities for an Internet historiography, including a timeline where “the announcement of the Chernobyl disaster on Usenet stands alongside the first message of Linus Torvalds calling for help on what would become the Linux operating system” (Paloque-Bergès, 2013).
Similar concerns appeared at the announcement of the archival of Twitter by the Library of Congress in 2010. The two are not really comparable, mostly because the archive is not public and is made by a not-for-profit body. On the mailing list of the Association of Internet Researchers, the idea was met with interest: “The public twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important. [Nancy Baym on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010- April/021125.html]”. However, the privacy concerns (notably with public and private feeds) were discussed, and as Michael Zimmer remarked:
“This is the classic “but the information is already public” argument that, while technically true, presumes a false dichotomy that information is either strictly public or private, ignoring any contextual norms that might have guided the initial release of information or how a person expects that information to flow.” (Zimmer, M. [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021136.html]; see also his paper (2010) on Facebook privacy, going further in that argument)
Paloque-Bergès (2010) theorises this argument, suggesting that “information is not an object, but a statement; it goes through socio-technical processes; it doesn’t have an objective nature”. A message in a tweet can have a very
￼￼
different context when taken apart of the moment it was posted. It also emphasises that the user could, later, switch their account to Private or delete it altogether, but this wouldn’t be reflected in the archive. We cannot know what is the user’s original intent when they posted their message, and, as Paloque-Bergès (2010) noted, we aren’t sure the user themselves know.
“More often than not, in a technical ecosystem in which making content private is more difficult than sharing broadly, teens choose to share, even if doing so creates the impression that they have given up on privacy. It’s not that every teen is desperate for widespread attention; plenty simply see no reason to take the effort to minimize the visibility of their photos and conversations.” (Boyd, 2014).
Advantages over physical preservation Mass preservation, easier access and organisation Recording digitally material that’s not born-digital
Cost of restoration; case studies of lost data
A number of institutions have already experienced loss of data, or data being corrupted. This can have disastrous consequences for businesses, for example, as noted by McAteer (1996, cited by Ross and Gow, 1999, p. iii): “of the 350 companies unexpectedly relocated by the [1993] World Trade Centre (NYC) bombing 150 [43%] ceased trading, many because they lost access to key business records held in electronic form”.
Data can, obviously, be sometimes restored. Ross and Gow (1999, pp. 39–42, referenced in Harvey, 2012, p. 34) provide a number of case studies. Harvey (2012, p. 34) also gives the ironic example of the website for the “Functional Requirements for Evidence in Recordkeeping” project, directed by the University of Pittsburgh which was accidentally deleted; but thankfully was automatically saved by the Internet Archive.
There is still the possibility of restoring data by specialised carriers; however Pearson (2009, slide 15) notes that while this was generally effective, this did not work on some items. He also regrets that the
￼￼
restoration loses all metadata in the process; this can be an issue for sensitive or classified information (for business or governmental archives) as the carrier would be able to see it; finally, it is a prohibitely expensive operation, and so a carefully planned preservation could be much cheaper (and obviously more reliable) than neglect. However, these services are always useful in certain cases. Harvey (2012, p. 41) cites the statistics by the data recovery giant Kroll Ontrack (2011): “hardware and system problems cause most customers to approach them (29 per cent), followed by human error (27 per cent). Software corruption or program problems, computer viruses and natural disasters are the other reasons listed.”
Defining paradigms for digital
preservation
Pre-digital paradigms
Inability to preserve the medium, only the bitstream Importance of metadata, relationship &amp; context Definition of terms
What to preserve / Selectivity
Harvey 5 pillars for selectivity (Harvey 2012, p. 26)
￼
￼￼     + If **unique information** objects that are vulnerable
 and sensitive and therefore subject to risks can be preserved
 and protected
     + If preservation ensures long-term accessibility for
 researchers and the public;
     + If preservation fosters the accountability of
 governments and organisations
     + If there is an economic or societal advantage in re-
 using information
     + If there is a legal requirement to keep it (NSF-DELOS
 Working Group on Digital Archiving and Preservation, 2003,
 p.3).
Banks reasons for domestic archiving
In The Future of Looking Back, Richard Banks (2011) analyses the reasons that lead us to keep or discard physical objects at home. He argues that while making a selection is a positive thing because it forces us to filter our belongings and focus on what is really meaningful, we also run the risk of ridding ourselves of things that we wish we would have kept in retrospect. He points out that the organisation of digital files make this trickier: because we we can keep pretty much everything on virtual space, it is easier to accidentally delete meaningful things alongside the less important. (Banks, 2011 p. 22).
In the context of personal archiving, Banks notes that in the past, the legacy we leave behind us was a highly selective one. Because our possessions are limited by physical space, our ancestors until now “have implicitly indicated that an item is significant through the simple act of keeping it. Although thousands of objects likely crossed their path over their lifetime, the constraints of money and space meant that only a few were retained, often the most significant.” (Banks, 2011, p. 78). He does however argue that this is no longer true in a digital world, because new possibilities mean we simply accumulate digital objects without necessarily ordering them by importance.
Technical possibility of archiving Pros/cons of archiving the entire internet
There are various controversies around whether we should automate the archiving of the Internet, or if we should operate a manual selection. UNESCO (2003, p. 73) notes that those who value a more comprehensive collection (i.e. archiving “all” the Internet) argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything”. This argument is particularly true because of the digital media: “unlike non-digital material such as paper-based artifacts, where there is a period of time in which to make selection decisions before deterioration of materials becomes an issue, the time frame for deciding whether or not to preserve digital materials is very short” (Harvey, 2012, p. 57). UNESCO (2003, p.71) backs that claim: “it may not be possible to wait for evidence of enduring value to emerge before making selection decisions”.
Other people [Cook?] think that it would be preferable to keep a curated collection because of a higher technical quality, and this also allow us to settle [negotiate?] preservation rights with the content producers. Harvey adds that we also do not have the technical capabilities to find all the pages on the Internet, and even if we had we would not have the technical possibility to store the whole of the Internet (Harvey 2012, p. 58); again, this is also something recognised by UNESCO: “‘there are usually more things – more information, more records, more publications, more data – than we have the means to keep” (2003, p.70).
The UNESCO (2003) and Cook (2000) both however recognise that a middle ground should be found and that both approaches are valid depending on the goal of the preservation. For instance, the Internet Archive[IA] is going through an automated process (archive as many pages as possible) but, because of technical limitation, only preserves the text and dismisses all other images, stylesheets and external media, which could be critical in some instances. It seems evident that for valued documents these should be retained. The British Library’s Web Archive[ukwa] [http://www.webarchive.org.uk/ukwa/]
Dangers of selection (Cook)
However, Cook (2000) points out the dangers of manual selection for what is worth archiving: “With memory comes the inevitable privileging of certain records and records creators, and the marginalizing or silencing of others” (Cook, 2000, cited in Harvey p. 58). He asserts that the archivists
￼
must be impartial and objective, and ensure all points of view are kept to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination”. This is something that is clear with manual archiving, but could also be a problem, maybe unintentionally, with the automated discovery of content when archiving Web pages.
Automatic selection (Reputation model)
In order to keep the most valuable content, algorithms could be used. Kawano (2008) proposes to use reputation models, that attempts to determine the relative value of a Web page by considering its “importance, fairness, trustiness, uniqueness and valuation”. This is done using a variety of ways; the algorithm suggested by Kawano relies on the consistency of a web page, that is the amount of time it existed, the number of links it contains and the number of external links to this page (Kawano, 2008, p. 291).
Crawling
Manual curating
Special Collections for events (eg before elections, see webarchive.org.uk for other ideas)
Another interesting selection process that has emerged is the one of specific archiving when certain events are happening. For instance, the UK Web Archive[ukwa] has, on top of their topical-based collections (Energy, Health and Social Care...), a few event-based collections (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks...) which reflect the state of the Web at that given moment in history. Masanès (2006, p.83) notes that this type of archiving must be manually curated and thoroughly preparated. He gives a methodology for this, using presidential elections as an example: a time frame for the collection must be defined (“3 months before the election + 1 month after”), what type of sites will be archived and when (“the political parties’ blogs and websites, every week; analysis, commentary and humourous/satire websites, every month; online newspaper articles, once”).
Selection: by genre
There are different genres of websites: institutional website, blogs, personal
￼
pages, forums. [[Genre have been studied in the context of the Web to see how they replicate or diverge from the genre in the print- ing world (see Crowston and Williams 1997) - in Masanès p88]]. An interesting point about this is that often, robots (crawlers, or later data analysis) can automatically identify their type [Rehm 2002 -&gt; check reference, Masanès:88] which permits the automatic generation of metadata, or simply to restrict a collection of web pages to certain Web genres.
Web archiving: what stands as heritage on the web
Who should preserve
Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era; but as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterize the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and this is also true for businesses and personal data. The Task Force on Archiving of Digital Information (1996, pp. 19–20) suggests that when, in general, “stakeholders disseminate, use, reuse, recreate and re-disseminate various kinds of digital information, they can easily, even inadvertently, destroy valuable information, corrupt the cultural record, [and ultimately thwart the pursuit of knowledge that is their common end]. Against such a danger, a safety net is needed to ensure that digital information objects with long-term cultural and intellectual value survive the expressions of stakeholder interest with their integrity intact.
[&gt; Society has always created objects and records describing its activities, and it has consciously preserved them in a permanent way... Cultural institutions are recognised custodians of this collective memory: archives, librar[ies] and museums play a vital role in organizing, preserving and providing access to the cultural, intellectual and historical resources of society. They have established formal preservation programs for traditional
￼
materials and they understand how to safeguard both the contextual circumstances and the authenticity and integrity of the objects and information placed in their care... It is now evident that the computer has changed forever the way information is created, managed, archives and accessed, and that digital information is now an integral part of our cultural and intellectual heritage. However the institutions that have traditionally been responsible for preserving information now face major technical, organisational, resource, and legal challenges in taking on the preservation of digital holdings (B. Smith, 2002, pp.133–134) [cited in Harvey p. 29].]
A variety of new stakeholders are now required to collaborate more for a good preservation practice to take place. Lavoie and Dempsey (2004, cited in Harvey, 2012, p. 30) argues that cooperation “can enhance the productive capacity of a limited supply of digital preservation funds, by building shared resources, eliminating redundancies, and exploiting economies of scale”. Chapter 11 of the UNESCO guidelines (2003) give more pratical details on how this can take place, giving structural models and tips on what to share (information, standards, division of labour...). [CLOCKSS cooperation to preserve journals (see Harvey p32 + chapter 9); + Harvey p32 National Library of Netherlands &amp; Elsevier Science + most uni libraries access with publishers, even UoD with eg Dawsonera/ACM]
Legal issues
(see later) special case for emulation
In certain cases, the archiving process is not made in accordance with the original publisher. This is often the case for the automated archiving of the Internet (e.g. Wayback Machine), which automatically crawl pages, but as a website publisher, it is easily possible to opt out of these schemes [see http://archive.org/about/exclude.php [Accessed 17th Apr 2014]]. In the case of emulation, this is what happens with reverse engineering, that is, disassembling the original program to understand how it works and recreate a similar version which can operate from a different hardware or software architecture. This is a common process for proprietary software or hardware, whose source code is not available to the general public and no documentation is provided for developers. Often, this is developed by amateurs and hobbyists, but is illegal as it breaks the intellectual property of the original creator; Nintendo, for example, attacks reverse engineered
￼
emulators[http://www.nintendo.com/corp/legal.jsp [Accessed 17th Apr 2014]] and the sharing of ROMs [Read Only Memory; the bitstream of cartridges or discs containing the games]. There is however popular demand for playing these, and Nintendo has developed their own emulators to play legacy games on their new consoles (see the Virtual Console [http://en.wikipedia.org/wiki/Virtual_Console]), while still retaining their property rights (you need to buy the games again on an e-commerce platform). This however causes issue for the longer term preservation: there is no certainty that Nintendo will continue to provide this service on their future generations of consoles, or if they ever cease operations.
A similar issue happened with Apple Computer. In 2005, Apple changed the architecture (that is, the “language” of instructions needed for the processor) of their personal computers from PowerPC to Intel x86. This means that applications needed to be rewritten, sometimes from the ground up, to work natively on the newer Apple computers. To ease the transition, Apple created Rosetta, a software that dynamically translates PowerPC instructions to x86 instructions, so that buyers of the new Apple computers were still able to open legacy applications that were not yet rewritten for x86 — although this came with a significant performance hit. In 2009 however, support for PowerPC was entirely discontinued [...]
Depends on the type of content Libraries
Good curating and preservation starts early. Smith (2003, pp. 2–3, cited in Harvey, 2012, p. 32) suggests that “the critical dependency of preservation on good stewardship begins with the act of creation, and the creator has a decisive role in the longevity of the digital object”. Harvey (2012, p. 32) notes that “for most creators of information in any form this is a new role”; therefore publishers of digital content are not necessarily well prepared for preservation, and this is why collaboration with librarians and archivists can be helpful (Ayre and Muir, 2004).
Ayre and Muir (2004) note that if the publisher worries about preservation themselves then they generally already own the rights for preservation, but there are negotiations to be done if an external body helps with
￼
preservation.
National libraries
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Elsevier Science) or publishers directly (ACM). A report by Hedstrom and Montgomery (1998, cited by Ayre and Muir, 2004) found that most research librarians in the UK thought that a legal deposit to national archives was the best option, but this was not a clear consensus. The report also highlighted that these librarians thought that “other libraries and publishers would need to, and should, have some involvement in preservation”.
Archivists
New stakeholders
Profits vs nonprofits
Harvey (2012) points out doubts in the real interests of for-profit companies to achieve long-term preservation;
Even given the prevailing market-driven political ethos, it is difficult to envisage a situation where market forces will be sufficient to ensure the preservation of this digital material. The opposite is more likely to apply: ‘in some cases market forces work against long-term preservation by locking customers into proprietary formats and systems’ (Workshop on Research Challenges in Digital Archiving and Long-term Preservation, 2003, pp.x-xi). (Harvey, 2012, p. 32)
Personal archiving
￼￼
Yourself? Online services
How to preserve
Preparation
Software methods Making hard copies
What appears to be the simplest solution is to make physical copies (i.e. print) of the digital documents. Although this certainly solves some problems in regards to technological obsolescence, Rothenberg (1999) and Granger (2000) pointed out that this cannot be done for more interactive material besides text and images. There is also, obviously, an issue with the amount of content that can be stored in this way — this would not work for archiving websites. Granger (2000) recognises that “if one’s sole concern is with the intellectual content of a document and the document is of a fairly simple nature [...] this at least provides some form of security”.
Standardisation
Standardisation is the transformation of a document’s content to a format that is standardised, open and well documented, ensuring that we will be able to open it with a variety of applications on a variety of platforms and that we can rebuild a program for visualising that document — as opposed to vendor-specific, closed source program that could be discontinued at any point in the future. Rothenberg (1999, p. 10) claims that this is a bad solution because “standardisation sows the seeds of its own destruction by encouraging vendors to implement non-standard features in order to secure market share” (therefore these non-standard features will be lost if opened in a different application). Granger (2000) argues that the blame is not to be put on the method, but on vendors. Standardisation is a type of migration and therefore share some of it cons (notably, this absence of vendor-specific features could imply a loss in the presentation and other characteristics). Standards eventually become obsolete so it is also paramount to preserve the specifications of the format, or to define formats
￼
that are unambiguous, such as CSV or XML.
A slightly different approach to this method is rebuilding viewers. In this scenario, the bitstream is not migrated to a standardised format, but kept as is; we simply re-build a viewer that is able to read that format. This is not as straightforward as it sounds, because most of the time, formats for proprietary software are not documented and decrypting them would require reverse engineering. If they are documented, then it is likely that this format is already a standard. There exists cases where reverse engineering is possible, or where a non-standard format is documented; for example, Microsoft Word files are not a standard, but there is plenty of documentation available online to produce code able to read them. An experiment by the VERS project (Thibodeau 2002, p. 22) has shown that it is possible to reengineer a viewer for the PDF file format from the specification available; as long as we also preserve these specifications, we will be able to read PDF files in the future.
UVC
Lorie (2000, in Thibodeau, 2002, p. 22) has also proposed that the use of a portable programming language, such as Java [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine, which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.]. Lorie developed a software called Universal Virtual Computer (UVC), able to decrypt a variety of file formats, which can run on any platform supporting Java; because Java could be implemented on virtually any architecture, this means that a reader could be run on any platform without any effort. However, Lorie points out, this approach is limited in terms of functionality, and comes at the price of performance (because portable programming languages are platform-agnostic, this means the code is not optimised for any of the platforms). I am also wondering if this would really work on the long term, as we cannot be sure that future implementations of Java will be backward compatible with code written for a previous version.
Migration
￼
Migration is the transformation of a document’s content to a format that is not necessarily standardised, but at least current; or, the newer version of same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed (although this can be overcome by migrating to more flexible formats like PDF or LaTeX). Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.
Computer museums
Another approach to preservation, proposed by Swade (1993), would be to preserve a variety of hardware, software and devices to access obsolete media in “computer museums”. This is generally not considered a good solution; Granger (2000) notes that it would be unreasonably expensive to keep old machines running for an extended period of time, that computers chips will eventually decay anyway (and repair or replacement will be impossible), and that storage media not stand the test of time. There are still two possible use cases, identified by Rothenberg (1999): ensuring that emulators work as expected (by comparing them to original platforms), and helping with the recovery of lost data on obsolete media
Emulation
Emulation is the dynamic transformation of instruction sets to allow software and/or operating system designed for an obsolete architecture or platform to run on current systems. It is a highly complex method that offers certain benefits; notably, this is the most conservative method, as it is not destructive of the content or presentation. It allows us to run the original program used to create a digital object without altering that
￼
bitstream ; it “keeps the look and feel as well as the interactivity” (Granger, 2000) and as such, it is particularly interesting for objects rich in interaction, such as video games, data visualisations, or formats that are particularly complex (for example, medical imagery, 3D modelisations), for which methods like migration would be hard. It also ensures complete integrity and authenticity, which could be crucial for some data types.
There are numerous criticisms against emulation. A number of legal and intellectual property problems are raised, if the emulation strategy is not supported by the original author [see Nintendo &amp; Apple]. The complexity involved in creating emulators might be not worth it and requires a coherent organisation to reduce overhead (Granger 2000). Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to the delivery of the preserved content; “most users in the future will never have encountered—not to mention learned how to use—most of the products they will need to access the preserved information objects”, and “it would cut users off from the possibility of using more advanced technologies for discovery, delivery, and analysis”.
“Emulators themselves become obsolete; therefore, it becomes necessary either to replace the old em- ulator with a new one or to create a new emulator that allows the old emulator to work on new platforms. In fact, if you get into an emula- tion strategy, you have bought into a migration strategy. Either strategy adds complexity over time.” (thibodeau 2002 p.20)
[NB: due to the length limit of this literature review, I have only explained the most popular archiving techniques. See Thibodeau (2002) and Harvey (2012) for a more comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.]
Choosing one
Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method: feasibility, sustainability, practicality and appropriateness.
Feasability means that the hardware and the software for implementing a given method must be existing and developed. Sustainability is ensuring
￼￼
that this method can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable”. This means that the method must be resistant to technological obsolescence, both for storing the data (medium will change) and accessing it (means to access the media ane decode the bitstream will change).
Practicality is establishing that this method will be reasonably difficult and affordable. [This can generally change depending on the resources of the preserving organisation, the available technology at that time and the valuation of the digital objects.]
Finally, appropriateness is using a method that is relevant to the type of material being preserved, and the objectives of the preservation. For example, del Pozo et al. (2012, p. 7) suggests that if the integrity and authenticity of the documents are not paramount, then a migration that keeps the contents but discards the presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).
Authenticity/integrity and issues with each method
Different preservation methods yield different results in what is called authenticity, that is how faithful the rendition [its presentation] of the preserved object will be. Authenticity is subjective and therefore there is debate around this issue (Del Pozo et al., 2012, p. 7; Cook, 2000); however most agree that while as little difference in the presentation is desirable, it is rarely (if ever) possible to keep a truthful rendition. As an example, del Pozo et al. (2012, p. 8) use a spreadsheet within the migration method:
“For instance, one institution may decide to normalise a spreadsheet into a PDF, which would retain the cell values but destroy any formula used to calculate them. This would favour a particular presentation of that digital object over the information form of the original. On the other hand, another institution might decide to normalise spreadsheets into ODF, which may lose some formatting but retain the formula used to derive each cell. In this case, being able to retain the information form of the file would be seen as more important.”
￼￼
￼Thibodeau (2002, p. 28) however points out that “people will want to use the best available technology—or at least technologies they know how to use— for discovery, retrieval, processing, and delivery of preserved information. There is a danger that to the degree that preservation solutions keep things unaltered they will create barriers to satisfying this basic user requirement.” An overly faithful preservation would therefore not be desirable. Again, this is subject to a high number of parameters.
Another important issue is integrity, i.e. “ensuring the object is complete and has not been altered or corrupted” (Harvey, 2012, p. 54; Ross [CITED], 2002, p. 7); that is, the object “is what it purports to be”, and no parts are missing from it. This is particularly important, Harvey (2012, p. 54) notes, for business archiving, where the legal value of a digital object could be lost if we cannot demonstrate that this object hasn’t been tampered with, or that a migration processes have not incurred data losses. However, as Lynch (2000) has argued, the integrity of objects is only a matter of trust. The guidelines of UNESCO (2003, p. 22) recommend that the best protection for authenticity is proper documentation of the archival process; Harvey (2012, p. 54) expands on this idea: “for instance, if it can be established that a digital object has always been kept in the custody of an archive in which every change to it has been recorded (such as changes resulting from migration of the bit-stream – the dates at which migration occurred, to which media, and so on), then we can be more secure about its integrity.”
Emulation / legal rights with videogames Use of standards
Some standards such as OAIS (Open Archival Information System), originally developed for space science, could be used. Sadly [no implementation][source??]
Domestic archiving Archiving photos
What we store online
Personal media &amp; teenagers; privacy options Data already public
What happens after our
### [Digital heritage]
Shifts in usages (more photos)
Advantages (sharing, organisation etc.); record part of our lives we never did before
Keeping memories attached to digital objects
or storing physical objects digitally
-&gt; (larger scale? China book)
Conclusion
￼</Text>
        </Document>
        <Document ID="30">
            <Title>3D-backups-serrano</Title>
        </Document>
        <Document ID="31">
            <Title>draft-annotated</Title>
            <Text>Introduction
As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts. This literature review aims to get an overview of the current problems, techniques and practices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the various methods used to do so. It also encompasses legal and ethical issues arising from it, and how the paradigms and methods change when applied to different types of archiving (e.g. for researchers, for businesses, and for personal businesses).
Why digital preservation
[Stats of numbers on digital vs physical]
Why digital degrades faster UNESCO’s Threats to digital continuity
UNESCO (2003, pp. 30–31) has identified a list of threats to what they call digital continuity. These are: + “The carriers used to store these digital materials are usually unstable and deteriorate within a few years or decades at most”. Where, in the traditional preservation paradigms for paper-based artifacts, the main rule is that “benign neglect may be the best treatment” (derived from Cloonan (1993, p.596), Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612–613)), this cannot be applied to digital storage media because their lifetime is much shorter. This varies highly with the type of medium used and with the storage conditions; for example, samples by the Digital Preservation Coalition (2008, p. 154) show that D3 cartridge tapes deteriorates after 50 years in optimal conditions (25% RH at 10o) but only one year in high humidity and temperatures (50%RH at 28o). Similar results happen for the more commercially available optical media (down to three months and up to 200 years), which are more sensitive to moisture (Harvey, 2012, p.47).
“Use of digital materials depends on means of access that work in
￼￼
￼particular ways: often complex combinations of tools including hardware and software, which typically become obsolete within a few years and are replaced with new tools that work differently” (UNESCO, 2003). Even if storage media could survive decades or even centuries, technological change means we will not necessarily have the means to access the data later. In other words, “to retain appropriate access to a digital object, we must maintain a mechanism to derive meaning from that object” (del Pozo et al., 2012, p6): for optical media, this includes not only the drives to read the disc, but also a cable to connect the drive to the computer’s motherboard, a motherboard that has a connector for this type of cable, and an operating system that has drivers for this connectivity (Pearson 2009, slide 11). Once we have access to the bitstream from the computer we need to be able to represent it, which means we also need to keep the software in a version that can open the preserved file. There is a myth, kept by both customers and vendors, that media is long-lived: “[An IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” (Weathley, 2003, cited by Harvey, 2012, p. 37)
Poor preservation documentation and metadata means it could be hard for potential users to find the data (UNESCO 2003)
poor preservation (“Critical aspects of functionality, such as formatting of documents or the rules by which databases operate, may not be recognised and may be discarded or damaged in preservation processing.”, UNESCO 2003) + “So much contextual information may be lost that the materials themselves are un- intelligible or not trusted even when they can be accessed” -&gt; poor integrity
“Materials may be lost in the event of disasters such as fire, flood, equipment failure, or virus or direct attack that disables stored data and operating systems”
“Access barriers such as password protection, encryption, security devices, or hard-coded access paths may prevent ongoing access beyond the very limited circumstances for which they were designed”. [This argument is particularly true for web archiving, where crawlers of national libraries retrieve all sort of files to preserve them but do not
￼￼￼￼￼
￼necessarily have the permission or know the rights owner][back that up maybe yo]
Importance of data Library material: for society
“if we librarians do not rise to the occasion, successive generations will know less and have access to less for the first time in human history. This is not a challenge from which we can shrink or a mission in which we can fail” (Gorman, 1997, cited in Harvey, 2012, p. 27)
For businesses (records)
Personal archiving / domestic archiving
Preserving interactive material inc. video games
In addition to the preservation of “static” documents and images, there is a significant desire to preserve video games, which are getting recognised as a form of art similarly to movies and music. The Library of Congress (2007) gave awards for the preservation of video games; there is a growing interest in being able to play “retro” games, but the consoles are obsolete. A large community of hobbyists reverse engineered consoles and produced emulators of these platforms for PC and other platforms different from their intended one. Because no documentation is available, this is a Herculean task; byuu (2011), the developer of an emulator for Super Nintendo games, recalls this for reengineering certain cartridges:
[Low-level emulation] is also a very expensive operation, monetarily speaking: to obtain the DSP program code requires melting the integrated circuit with nitric acid, scanning in the surface of a chip with an electron microscope, and then either staining and manually reading out or physically altering and monitoring the traces to extract the program and data ROMs. This kind of work can cost up to millions of dollars to have done professionally, depending upon the chip’s complexity, due to the extremely specialized knowledge and equipment involved. (byuu, 2011)
Obviously this is not necessarily a route many institutions would like to take for preserving digital objects. Because this also causes intellectual
￼￼
￼property issues, Nintendo and Sony have launched their own preservation programs, allowing players to play “classic” games on the newer generations of consoles; this is a far more accurate emulation (as they do have the internal documentation to create these emulators) and respects their monetary interests (players have to buy the games, whereas in hobbyist emulation, you would have to download the game file).
Useful for researchers in the future
Beyond the governmental and cultural needs for preservation, there is also great need for preserving scientific data. “Data are the foundation on which scientific, engineering, and medical knowledge is built” (Committee on Ensuring the Utility and Integrity of Research Data in a Digital Age, 2009, p. ix, cited in Harvey, 2012, p. 26); therefore it is crucial in a digital era, with enormous data sets and research papers becoming widely public, to ensure this doesn’t disappear.
Understanding our history
There is a need to define what is the purpose of archives. As a tool to learn from the past, or to keep records, but as Cook (2000) eloquently puts it:
“Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)
Preservation should, therefore, be considered very important. There is some skepticism to this:
￼
￼￼“It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
While it’s difficult to argue that preserving digital objects is necessary, there is certainly a need to define what deserves to be protected, and to what level.
Understanding the beginnings of the Internet, as we have shifted in an information society
Preserving an accurate + [integrity] image of our society at a given point Twitter &amp; Usenet
Camille Paloque-Bergès (2011; 2013) proposes that we can already find historical and sociological evidence of a given period in Internet time when browsing archives of Usenet [footnote: An Internet discussion system established in the 1980s and that is widely regarded as the predecessor of the Web and online fora]. She analysed how the way of speaking has evolved [footnote: See also http://wwwtxt.org (or @wwwtxt on Twitter), a project collecting short phrases of the Usenet to demonstrate this] and how an self-organised community had built itself, noting that we can “feel [the community’s] informational generativity” and understand that one of the biggest qualities of the early users of the Internet was their “recursivity as a public” (Paloque-Bergès, 2013); that is, how they welcomed newcomers — notably through the use of FAQs [footnote: Frequently Asked Questions], which weren’t a common concept back then. There are also large elements of nostalgia coming back (Paloque-Bergès, 2011).
It is also interesting to come back on the archival of Usenet. The messages were not systematically archived, and obviously not available on the Web as
￼it did not exist and is separate. Today’s collections have mainly been recreated from donations of people who did archived Usenet newsgroup, originally to DejaVu News in 1995, and Google Groups in 2001. A number of privacy concerns were raised with the publication of these searchable archives; messages who were, 15 to 20 years earlier, thought to be confidential are now considered as digital heritage. There was also a large backlash against the archiving made by for-profit companies, and the credit taken later by Google for its donors, with other critiques like Brad Templeton’s (an Internet veteran and important figure; cited in Paloque- Berges, 2013) remark that the archive was lacking in integrity. However, the searchability of these archives did bring welcomed technical possibilities for an Internet historiography, including a timeline where “the announcement of the Chernobyl disaster on Usenet stands alongside the first message of Linus Torvalds calling for help on what would become the Linux operating system” (Paloque-Bergès, 2013).
Similar concerns appeared at the announcement of the archival of Twitter by the Library of Congress in 2010. The two are not really comparable, mostly because the archive is not public and is made by a not-for-profit body. On the mailing list of the Association of Internet Researchers, the idea was met with interest: “The public twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important” (Baym, 2010) [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010- April/021125.html]”. However, the privacy concerns (notably with public and private feeds) were discussed, and as Michael Zimmer remarked:
“This is the classic “but the information is already public” argument that, while technically true, presumes a false dichotomy that information is either strictly public or private, ignoring any contextual norms that might have guided the initial release of information or how a person expects that information to flow.” (Zimmer, M. [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021136.html]; see also his paper (2010) on Facebook privacy, going further in that argument)
Paloque-Bergès (2010) theorises this argument, suggesting that “information is not an object, but a statement; it goes through socio-technical processes; it doesn’t have an objective nature”. A message in a tweet can have a very
￼
￼different context when taken apart of the moment it was posted. It also emphasises that privacy could change (the user could, later, switch their account to Private, delete the tweet or their account altogether, but this wouldn’t be reflected in the archive. We cannot know what is the user’s original intent when they posted their message, and, as Paloque-Bergès (2010) noted, we aren’t sure the user themselves know.
“More often than not, in a technical ecosystem in which making content private is more difficult than sharing broadly, teens choose to share, even if doing so creates the impression that they have given up on privacy. It’s not that every teen is desperate for widespread attention; plenty simply see no reason to take the effort to minimize the visibility of their photos and conversations.” (Boyd, 2014).
Advantages over physical preservation Mass preservation, easier access and organisation Recording digitally material that’s not born-digital
Cost of restoration; case studies of lost data
A number of institutions have already experienced loss of data, or data being corrupted. This can have disastrous consequences for businesses, for example, as noted by McAteer (1996, cited by Ross and Gow, 1999, p. iii): “of the 350 companies unexpectedly relocated by the [1993] World Trade Centre (NYC) bombing 150 [43%] ceased trading, many because they lost access to key business records held in electronic form”.
Data can, obviously, be sometimes restored. Ross and Gow (1999, pp. 39–42, referenced in Harvey, 2012, p. 34) provide a number of case studies. Harvey (2012, p. 34) also gives the ironic example of the website for the “Functional Requirements for Evidence in Recordkeeping” project, directed by the University of Pittsburgh which was accidentally deleted; but thankfully was automatically saved by the Internet Archive.
There is still the possibility of restoring data by specialised carriers; however Pearson (2009, slide 15) notes that while this was generally effective, this did not work on some items. He also regrets that the
￼
￼restoration loses all metadata in the process; this can be an issue for sensitive or classified information (for business or governmental archives) as the carrier would be able to see it; finally, it is a prohibitely expensive operation, and so a carefully planned preservation could be much cheaper (and obviously more reliable) than neglect. However, these services are always useful in certain cases. Harvey (2012, p. 41) cites the statistics by the data recovery giant Kroll Ontrack (2011): “hardware and system problems cause most customers to approach them (29 per cent), followed by human error (27 per cent). Software corruption or program problems, computer viruses and natural disasters are the other reasons listed.”
Defining paradigms for digital
preservation
Pre-digital paradigms
Inability to preserve the medium, only the bitstream Importance of metadata, relationship &amp; context Definition of terms
What to preserve / Selectivity
Harvey 5 pillars for selectivity (Harvey 2012, p. 26)
If unique information objects that are vulnerable and sensitive and therefore subject to risks can be preserved and protected
If preservation ensures long-term accessibility for researchers and the public;
If preservation fosters the accountability of governments and organisations
If there is an economic or societal advantage in re-using information
￼￼￼￼
￼If there is a legal requirement to keep it (NSF-DELOS Working Group on Digital Archiving and Preservation, 2003, p.3).
Banks reasons for domestic archiving
In The Future of Looking Back, Richard Banks (2011) analyses the reasons that lead us to keep or discard physical objects at home. He argues that while making a selection is a positive thing because it forces us to filter our belongings and focus on what is really meaningful, we also run the risk of ridding ourselves of things that we wish we would have kept in retrospect. He points out that the organisation of digital files make this trickier: because we we can keep pretty much everything on virtual space, it is easier to accidentally delete meaningful things alongside the less important. (Banks, 2011 p. 22).
In the context of personal archiving, Banks notes that in the past, the legacy we leave behind us was a highly selective one. Because our possessions are limited by physical space, our ancestors until now “have implicitly indicated that an item is significant through the simple act of keeping it. Although thousands of objects likely crossed their path over their lifetime, the constraints of money and space meant that only a few were retained, often the most significant.” (Banks, 2011, p. 78). He does however argue that this is no longer true in a digital world, because new possibilities mean we simply accumulate digital objects without necessarily ordering them by importance.
Technical possibility of archiving Pros/cons of archiving the entire internet
There are various controversies around whether we should automate the archiving of the Internet, or if we should operate a manual selection. UNESCO (2003, p. 73) notes that those who value a more comprehensive collection (i.e. archiving “all” the Internet) argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything”. This argument is particularly true because of the digital media: “unlike non-digital material such as paper-based artifacts, where there is a period of time in which to make selection decisions before deterioration of materials becomes an issue, the time frame for deciding whether or not to preserve digital materials is very short” (Harvey, 2012, p. 57). UNESCO (2003, p.71)
￼
￼backs that claim: “it may not be possible to wait for evidence of enduring value to emerge before making selection decisions”.
Other people [Cook?] think that it would be preferable to keep a curated collection because of a higher technical quality, and this also allow us to settle [negotiate?] preservation rights with the content producers. Harvey adds that we also do not have the technical capabilities to find all the pages on the Internet, and even if we had we would not have the technical possibility to store the whole of the Internet (Harvey 2012, p. 58); again, this is also something recognised by UNESCO: “‘there are usually more things – more information, more records, more publications, more data – than we have the means to keep” (2003, p.70).
The UNESCO (2003) and Cook (2000) both however recognise that a middle ground should be found and that both approaches are valid depending on the goal of the preservation. For instance, the Internet Archive[IA] is going through an automated process (archive as many pages as possible) but, because of technical limitation, only preserves the text and dismisses all other images, stylesheets and external media, which could be critical in some instances. It seems evident that for valued documents these should be retained. The British Library’s Web Archive[ukwa] [http://www.webarchive.org.uk/ukwa/]
Dangers of selection (Cook)
However, Cook (2000) points out the dangers of manual selection for what is worth archiving: “With memory comes the inevitable privileging of certain records and records creators, and the marginalizing or silencing of others” (Cook, 2000, cited in Harvey p. 58). He asserts that the archivists must be impartial and objective, and ensure all points of view are kept to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination”. This is something that is clear with manual archiving, but could also be a problem, maybe unintentionally, with the automated discovery of content when archiving Web pages.
Automatic selection (Reputation model)
In order to keep the most valuable content, algorithms could be used. Kawano (2008) proposes to use reputation models, that attempts to
￼determine the relative value of a Web page by considering its “importance, fairness, trustiness, uniqueness and valuation”. This is done using a variety of ways; the algorithm suggested by Kawano relies on the consistency of a web page, that is the amount of time it existed, the number of links it contains and the number of external links to this page (Kawano, 2008, p. 291).
Crawling
Manual curating
Special Collections for events (eg before elections, see webarchive.org.uk for other ideas)
Another interesting selection process that has emerged is the one of specific archiving when certain events are happening. For instance, the UK Web Archive[ukwa] has, on top of their topical-based collections (Energy, Health and Social Care...), a few event-based collections (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks...) which reflect the state of the Web at that given moment in history. Masanès (2006, p.83) notes that this type of archiving must be manually curated and thoroughly preparated. He gives a methodology for this, using presidential elections as an example: a time frame for the collection must be defined (“3 months before the election + 1 month after”), what type of sites will be archived and when (“the political parties’ blogs and websites, every week; analysis, commentary and humourous/satire websites, every month; online newspaper articles, once”).
Selection: by genre
There are different genres of websites: institutional website, blogs, personal pages, forums. [[Genre have been studied in the context of the Web to see how they replicate or diverge from the genre in the print- ing world (see Crowston and Williams 1997) - in Masanès p88]]. An interesting point about this is that often, robots (crawlers, or later data analysis) can automatically identify their type [Rehm 2002 -&gt; check reference, Masanès:88] which permits the automatic generation of metadata, or simply to restrict a collection of web pages to certain Web genres.
Web archiving: what stands as
heritage on the web Who should preserve
Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era; but as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterize the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and this is also true for businesses and personal data. The Task Force on Archiving of Digital Information (1996, pp. 19–20) suggests that when, in general, “stakeholders disseminate, use, reuse, recreate and re-disseminate various kinds of digital information, they can easily, even inadvertently, destroy valuable information, corrupt the cultural record, [and ultimately thwart the pursuit of knowledge that is their common end]. Against such a danger, a safety net is needed to ensure that digital information objects with long-term cultural and intellectual value survive the expressions of stakeholder interest with their integrity intact.
[&gt; Society has always created objects and records describing its activities, and it has consciously preserved them in a permanent way... Cultural institutions are recognised custodians of this collective memory: archives, librar[ies] and museums play a vital role in organizing, preserving and providing access to the cultural, intellectual and historical resources of society. They have established formal preservation programs for traditional materials and they understand how to safeguard both the contextual circumstances and the authenticity and integrity of the objects and information placed in their care... It is now evident that the computer has changed forever the way information is created, managed, archives and accessed, and that digital information is now an integral part of our cultural and intellectual heritage. However the institutions that have traditionally been responsible for preserving information now face major technical, organisational, resource, and legal challenges in taking on the preservation of digital holdings (B. Smith, 2002, pp.133–134) [cited in Harvey p. 29].]
￼
￼A variety of new stakeholders are now required to collaborate more for a good preservation practice to take place. Lavoie and Dempsey (2004, cited in Harvey, 2012, p. 30) argues that cooperation “can enhance the productive capacity of a limited supply of digital preservation funds, by building shared resources, eliminating redundancies, and exploiting economies of scale”. Chapter 11 of the UNESCO guidelines (2003) give more pratical details on how this can take place, giving structural models and tips on what to share (information, standards, division of labour...). [CLOCKSS cooperation to preserve journals (see Harvey p32 + chapter 9); + Harvey p32 National Library of Netherlands &amp; Elsevier Science + most uni libraries access with publishers, even UoD with eg Dawsonera/ACM]
Legal issues
(see later) special case for emulation
In certain cases, the archiving process is not made in accordance with the original publisher. This is often the case for the automated archiving of the Internet (e.g. Wayback Machine), which automatically crawl pages, but as a website publisher, it is easily possible to opt out of these schemes [see http://archive.org/about/exclude.php [Accessed 17th Apr 2014]]. In the case of emulation, this is what happens with reverse engineering, that is, disassembling the original program to understand how it works and recreate a similar version which can operate from a different hardware or software architecture. This is a common process for proprietary software or hardware, whose source code is not available to the general public and no documentation is provided for developers. Often, this is developed by amateurs and hobbyists, but is illegal as it breaks the intellectual property of the original creator; Nintendo, for example, attacks reverse engineered emulators[http://www.nintendo.com/corp/legal.jsp [Accessed 17th Apr 2014]] and the sharing of ROMs [Read Only Memory; the bitstream of cartridges or discs containing the games]. There is however popular demand for playing these, and Nintendo has developed their own emulators to play legacy games on their new consoles (see the Virtual Console [http://en.wikipedia.org/wiki/Virtual_Console]), while still retaining their property rights (you need to buy the games again on an e-commerce platform). This however causes issue for the longer term preservation: there is no certainty that Nintendo will continue to provide this service on their future generations of consoles, or if they ever cease operations.
￼A similar issue happened with Apple Computer. In 2005, Apple changed the architecture (that is, the “language” of instructions needed for the processor) of their personal computers from PowerPC to Intel x86. This means that applications needed to be rewritten, sometimes from the ground up, to work natively on the newer Apple computers. To ease the transition, Apple created Rosetta, a software that dynamically translates PowerPC instructions to x86 instructions, so that buyers of the new Apple computers were still able to open legacy applications that were not yet rewritten for x86 — although this came with a significant performance hit. In 2009 however, support for PowerPC was entirely discontinued [...]
Libraries
Good curating and preservation starts early. Smith (2003, pp. 2–3, cited in Harvey, 2012, p. 32) suggests that “the critical dependency of preservation on good stewardship begins with the act of creation, and the creator has a decisive role in the longevity of the digital object”. Harvey (2012, p. 32) notes that “for most creators of information in any form this is a new role”; therefore publishers of digital content are not necessarily well prepared for preservation, and this is why collaboration with librarians and archivists can be helpful (Ayre and Muir, 2004).
Ayre and Muir (2004) note that if the publisher worries about preservation themselves then they generally already own the rights for preservation, but there are negotiations to be done if an external body helps with preservation.
National libraries
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Elsevier Science) or publishers directly (ACM). A report by Hedstrom and Montgomery (1998, cited by Ayre and Muir, 2004) found that most research librarians in the UK thought that a legal deposit to national archives was the best option, but this was not a
￼clear consensus. The report also highlighted that these librarians thought that “other libraries and publishers would need to, and should, have some involvement in preservation”.
Because all preservation methods involve copying of the original object, it might be illegal to make such a copy without the necessary rights, even if it is for preservation purposes. Certain countries have laws to overcome this and allow national libraries to preserve all materials; Ayre and Muir (2004) list a few of them and their specificities, but the situation has since evolved, as a lot of legislations have enacted changes to specifically include digital materials.
Archivists
New stakeholders
Profits vs nonprofits
Harvey (2012) points out doubts in the real interests of for-profit companies to achieve long-term preservation;
Even given the prevailing market-driven political ethos, it is difficult to envisage a situation where market forces will be sufficient to ensure the preservation of this digital material. The opposite is more likely to apply: ‘in some cases market forces work against long-term preservation by locking customers into proprietary formats and systems’ (Workshop on Research Challenges in Digital Archiving and Long-term Preservation, 2003, pp.x-xi). (Harvey, 2012, p. 32). [link with Google concerns]
How to preserve
Software methods Making hard copies
What appears to be the simplest solution is to make physical copies (i.e. print) of the digital documents. Although this certainly solves some
￼
￼problems in regards to technological obsolescence, Rothenberg (1999) and Granger (2000) pointed out that this cannot be done for more interactive material besides text and images. There is also, obviously, an issue with the amount of content that can be stored in this way — this would not work for archiving websites. Granger (2000) recognises that “if one’s sole concern is with the intellectual content of a document and the document is of a fairly simple nature [...] this at least provides some form of security”.
Standardisation
Standardisation is the transformation of a document’s content to a format that is standardised, open and well documented, ensuring that we will be able to open it with a variety of applications on a variety of platforms and that we can rebuild a program for visualising that document — as opposed to vendor-specific, closed source program that could be discontinued at any point in the future. Rothenberg (1999, p. 10) claims that this is a bad solution because “standardisation sows the seeds of its own destruction by encouraging vendors to implement non-standard features in order to secure market share” (therefore these non-standard features will be lost if opened in a different application). Granger (2000) argues that the blame is not to be put on the method, but on vendors. Standardisation is a type of migration and therefore share some of it cons (notably, this absence of vendor-specific features could imply a loss in the presentation and other characteristics). Standards eventually become obsolete so it is also paramount to preserve the specifications of the format, or to define formats that are unambiguous, such as CSV or XML.
A slightly different approach to this method is rebuilding viewers. In this scenario, the bitstream is not migrated to a standardised format, but kept as is; we simply re-build a viewer that is able to read that format. This is not as straightforward as it sounds, because most of the time, formats for proprietary software are not documented and decrypting them would require reverse engineering. If they are documented, then it is likely that this format is already a standard. There exists cases where reverse engineering is possible, or where a non-standard format is documented; for example, Microsoft Word files are not a standard, but there is plenty of documentation available online to produce code able to read them. An experiment by the VERS project (Thibodeau 2002, p. 22) has shown that it is possible to reengineer a viewer for the PDF file format from the specification available; as long as we also preserve these specifications, we
￼will be able to read PDF files in the future.
UVC
Lorie (2000, in Thibodeau, 2002, p. 22) has also proposed that the use of a portable programming language, such as Java [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine, which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.]. Lorie developed a software called Universal Virtual Computer (UVC), able to decrypt a variety of file formats, which can run on any platform supporting Java; because Java could be implemented on virtually any architecture, this means that a reader could be run on any platform without any effort. However, Lorie points out, this approach is limited in terms of functionality, and comes at the price of performance (because portable programming languages are platform-agnostic, this means the code is not optimised for any of the platforms). I am also wondering if this would really work on the long term, as we cannot be sure that future implementations of Java will be backward compatible with code written for a previous version.
Migration
Migration is the transformation of a document’s content to a format that is not necessarily standardised, but at least current; or, the newer version of same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed (although this can be overcome by migrating to more flexible formats like PDF or LaTeX). Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that
￼comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.
Computer museums
Another approach to preservation, proposed by Swade (1993), would be to preserve a variety of hardware, software and devices to access obsolete media in “computer museums”. This is generally not considered a good solution; Granger (2000) notes that it would be unreasonably expensive to keep old machines running for an extended period of time, that computers chips will eventually decay anyway (and repair or replacement will be impossible), and that storage media not stand the test of time. There are still two possible use cases, identified by Rothenberg (1999): ensuring that emulators work as expected (by comparing them to original platforms), and helping with the recovery of lost data on obsolete media
Emulation
Emulation is the dynamic transformation of instruction sets to allow software and/or operating system designed for an obsolete architecture or platform to run on current systems. It is a highly complex method that offers certain benefits; notably, this is the most conservative method, as it is not destructive of the content or presentation. It allows us to run the original program used to create a digital object without altering that bitstream ; it “keeps the look and feel as well as the interactivity” (Granger, 2000) and as such, it is particularly interesting for objects rich in interaction, such as video games, data visualisations, or formats that are particularly complex (for example, medical imagery, 3D modelisations), for which methods like migration would be hard. It also ensures complete integrity and authenticity, which could be crucial for some data types.
There are numerous criticisms against emulation. A number of legal and intellectual property problems are raised, if the emulation strategy is not supported by the original author [see Nintendo &amp; Apple]. The complexity involved in creating emulators might be not worth it and requires a coherent organisation to reduce overhead (Granger 2000). Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to the delivery of the preserved content; “most users in the future will never have encountered—not to
￼mention learned how to use—most of the products they will need to access the preserved information objects”, and “it would cut users off from the possibility of using more advanced technologies for discovery, delivery, and analysis”.
“Emulators themselves become obsolete; therefore, it becomes necessary either to replace the old em- ulator with a new one or to create a new emulator that allows the old emulator to work on new platforms. In fact, if you get into an emula- tion strategy, you have bought into a migration strategy. Either strategy adds complexity over time.” (thibodeau 2002 p.20)
[NB: due to the length limit of this literature review, I have only explained the most popular archiving techniques. See Thibodeau (2002) and Harvey (2012) for a more comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.]
Choosing one
Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method: feasibility, sustainability, practicality and appropriateness.
Feasability means that the hardware and the software for implementing a given method must be existing and developed. Sustainability is ensuring that this method can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable”. This means that the method must be resistant to technological obsolescence, both for storing the data (medium will change) and accessing it (means to access the media ane decode the bitstream will change).
Practicality is establishing that this method will be reasonably difficult and affordable. [This can generally change depending on the resources of the preserving organisation, the available technology at that time and the valuation of the digital objects.]
Finally, appropriateness is using a method that is relevant to the type of material being preserved, and the objectives of the preservation. For example, del Pozo et al. (2012, p. 7) suggests that if the integrity and
￼
￼authenticity of the documents are not paramount, then a migration that keeps the contents but discards the presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).
Authenticity/integrity and issues with each method
Different preservation methods yield different results in what is called authenticity, that is how faithful the rendition [its presentation] of the preserved object will be. Authenticity is subjective and therefore there is debate around this issue (Del Pozo et al., 2012, p. 7; Cook, 2000); however most agree that while as little difference in the presentation is desirable, it is rarely (if ever) possible to keep a truthful rendition. As an example, del Pozo et al. (2012, p. 8) use a spreadsheet within the migration method:
“For instance, one institution may decide to normalise a spreadsheet into a PDF, which would retain the cell values but destroy any formula used to calculate them. This would favour a particular presentation of that digital object over the information form of the original. On the other hand, another institution might decide to normalise spreadsheets into ODF, which may lose some formatting but retain the formula used to derive each cell. In this case, being able to retain the information form of the file would be seen as more important.”
Thibodeau (2002, p. 28) however points out that “people will want to use the best available technology—or at least technologies they know how to use— for discovery, retrieval, processing, and delivery of preserved information. There is a danger that to the degree that preservation solutions keep things unaltered they will create barriers to satisfying this basic user requirement.” An overly faithful preservation would therefore not be desirable. Again, this is subject to a high number of parameters.
Another important issue is integrity, i.e. “ensuring the object is complete and has not been altered or corrupted” (Harvey, 2012, p. 54; Ross [CITED], 2002, p. 7); that is, the object “is what it purports to be”, and no parts are missing from it. This is particularly important, Harvey (2012, p. 54) notes, for business archiving, where the legal value of a digital object could be lost if we cannot demonstrate that this object hasn’t been tampered with, or that a
￼
￼migration processes have not incurred data losses. However, as Lynch (2000) has argued, the integrity of objects is only a matter of trust. The guidelines of UNESCO (2003, p. 22) recommend that the best protection for authenticity is proper documentation of the archival process; Harvey (2012, p. 54) expands on this idea: “for instance, if it can be established that a digital object has always been kept in the custody of an archive in which every change to it has been recorded (such as changes resulting from migration of the bit-stream – the dates at which migration occurred, to which media, and so on), then we can be more secure about its integrity.”
Emulation / legal rights with videogames Use of standards
Some standards such as OAIS (Open Archival Information System), originally developed for space science, could be used. Sadly [no implementation][source??]
Personal archiving
On a more personal level, Harvey (2012) and Lukesh (1999) note that personal correspondance might be lost if we do not take steps to preserve them:
“The widespread shift from writing letters to the use of email has diminished the likelihood that personal correspondence will remain accessible to future historians. Lukesh asked in 1999, ‘Where will our understandings of today and, more critically, the next century be, if this rich source of information is no longer available?’, as scientists, scholars, historians and almost everyone increasingly use email” (Lukesh, 1999) (in Harvey, 2012 p. 32)
While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.
￼
￼Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths. However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited; second, storing photos and data on online services mean we may forget about them in a few years (Banks, 2011).
What happens after our death
### [Digital heritage]
Shifts in usages (more photos)
Advantages (sharing, organisation etc.); record part of our lives we never did before
Digital artifacts have certain fundamental advantages over physical objects: the main two being the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost- free (Banks, 2011). This actually provides numerous advantages in terms of preservation.
[[+ tie with “In the past ancestors have signified something is important simply by keeping it” part ]]
The first one, ease of organisation, can be significantly helpful in tackling the abundance of digital data. Banks (2011) suggests that the technologies lying behind the ranking in the result of Web search engines could, eventually, help us in understanding and finding what is our most important data. An attempt has been made by the MUSE (Memories USing
￼Email) project (Hangal et al., 2011), which aims to find patterns in our emails archives to help us make sense of this large data set. As the authors note in the introduction:
“Email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later, and thereby use their email account as an informal backup device. Therefore, email archives contain or reflect memories that are extremely valuable for the purposes of reminiscence.” (Hangal et al., 2011)
Early users reported that they have been using it to: make a summary of their work progress over the year; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; renewing with old relationships; and serendipitous discovery. The authors note in the conclusion that the different uses of their program went beyond their original expectations of simply reminiscing: “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.”
The second advantage, the ability to accurately and easily make copies and backups, is fairly obviously an advantage for personal preservation. However, Banks (2011) notes, the process of backing up is troublesome and storage media do not make our data immune. Additionally, the use of online services to store our data creates an abstraction between the storage material and us; about Flickr: “I have no idea what kind of hardware my files are now stored or even where they are geographically. I just expect to have access to them as long as I pay my bills” (Banks, 2011, p. 27).
Keeping memories attached to digital objects
Banks (2011) also suggests that we could blend in the physical and the digital to allow recording of things we never had the opportunity to before. He gives as example the Weather Camera, an experimental object by Kjen Wilkens (2011) that records wind and temperature along with commentary,
￼
￼instead of an image, as an alternative to recall a place; or 3D backups by Héctor Serrano (2009), another experimental project that allows us to make backups of sentimentally important objects through 3D scanning and 3D printing. Similarly, Banks notes tools by Microsoft Research to recreate places in a 3D environment based on photos, allowing to recreate a sentimentally important place at any given point in time provided enough photos are available. A similar technique is used in bigger preservation projects, as described by Zhou et al. (2012), to make high quality 3D models of culturally important places and objects in China.
Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining that we could augment physical objects with RFID tags (and I would add, virtual reality technologies) to pass down stories attached to these objects.
Conclusion
</Text>
        </Document>
        <Document ID="32">
            <Title>Draft</Title>
            <Text>Harvey, D. R. 2012. *Preserving digital materials*. Berlin: De Gruyter Saur.

Preserving Digital Materials by Douglas Ross Harvey is a great introduction to the field of digital preservation. Although it does not seek to get into details, it references a lot of other publications that I have used throughout this literature review, and is considered a great reference by archivists, librarians and other recordkeepers. The first chapter is concerned with the definition of digital preservation itself, which is central to the theme of my dissertation. Harvey argues that the most important challenge we are faced now with digital preservation is the changement of paradigm; he says the volume of information, the nature of the data that is deemed valuable for preservation, the means of accessing the data, the abundance of metadata, and the physical supports to hold digital data mean we must completely redefine our paradigms for the preservation of digital data, as traditional approaches from paper-based archiving become irrelevant.

&gt; “In library and recordkeeping practice we are moving rapidly from collection-based models, whose principles and practices have been developed over many centuries, to models where collections are not of paramount importance and where what matters is the extent of access provided to information resources”

## Previous paradigm

(copied p. 10). Called pre-digital preservation paradigm

- When materials are treated, the treatments should, when possible, be re- versible
– Whenever possible or appropriate, the originals should be preserved; only materials that are untreatable should be reformatted
– Library materials should be preserved for as long as possible
– Efforts should be put into preventive conservation, and aimed at providing
appropriate storage and handling of artifacts
– Benign neglect may be the best treatment (derived from Cloonan (1993,
p.596), Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612-613)).

more defs pp 10-11
+ Bastian, Cloonan and Harvey, 2011, p.611

&gt; Change is also apparent in the ways that information professionals define preservation. In a 2002 survey of records managers and archivists who deal with electronic records, Cloonan and Sanett (2002, p.73) posed the questions: ‘What is the meaning of preservation? Does the meaning change when it is applied to electronic rather than paper-based records?’. They noted that:
&gt;&gt; It is clear that professionals are revising their definitions of preservation from a once- and-forever approach for paper-based materials to an all-the-time approach for digital materials. Preservation must now accommodate both media and access systems ... while we once tended to think about preserving materials for a particular period of time – for example, permanent/durable paper was expected to last for five hundred years – we now think about retaining digital media for a period of continuing value (Cloonan and Sanett, 2002, p.93).

&gt; Interviewees expressed dissatisfaction with the term digital preservation, sug- gesting that other terms such as long-term retention are more suitable (Cloonan and Sanett, 2002, p.74). Definitions of preservation provided by survey re- spondents, Cloonan and Sanett (2002, p.85) concluded, ‘demonstrate a shift taking place from defining preservation as a once-and-forever approach for paper-based materials, to an all-the-time approach for digital materials’. This shift implies an acceptance that preservation may even begin before a record has been created.
&gt; Debate has continued about whether digital preservation sufficiently describes what needs to occur for digital materials to be accessible over time, on the grounds that more than just aspects of preservation need to be encompassed by whatever term is used. The terms digital curation and digital stewardship have been proposed and are gaining acceptance because they describe more than just preservation, referring also to ‘the creation, collection, organization [and] dissemination’ of digital objects (Bastian, Cloonan and Harvey 2011, p.609).

# Change of the nature of the data stored

Not only books or journals but also data sets:
&gt; Librarians manage hybrid libraries, consisting of both physical collections and distributed digital information resources, and digital libraries. Other stakeholders with a keen inter- est in digital preservation manage digital information in specific subject areas, such as geospatial data or social science data. In the past this material, where it existed, was maintained as collections of paper and other physical objects. The practices developed and applied in libraries and archives are still largely based on managing physical collections and cannot be applied automatically to managing digital collections.

Use of datasets: visualisation, aggregating, calculation

# Change of structure in physical media.
Benign neglect cannot be applied anymore:
&gt; The phrase benign neglect provides an example of a concept that is helpful in the pre-digital preservation paradigm but is harmful in the new. It refers to the concept that many informa- tion carriers made of organic materials (most notably paper-based artifacts) will not deteriorate rapidly if they are left undisturbed. For digital materials this concept is positively harmful.

&gt; The old paradigm does not, however, engender an understanding of the complexity of copying – which is more than simply preserving a bit-stream, but must take account of a wide range of other attributes of the digital object that also need to be preserved. (p. 12)

pp. 17-18

&gt; Other concepts need to be accommodated by the new definitions. For digital materials ‘their preservation must be an integral element of the initial design of systems and projects’ (Ross, 2000, p.13), but this is not usually the case. Digital materials exist in a bewilderingly large number of formats; there is still little standardization. The most significant concept is that the preservation of digital materials is much more than the preservation of information content or physical carrier:
&gt;&gt; it is about preserving the intellectual integrity of information objects, including capturing information about the various contexts within which information is created, organized, and used; organic relationships with other information objects; and characteristics that provide meaning and evidential value (Gilliland-Swetland, 2000, p.29).

&gt; Preserving the original bit-stream is only one part of the problem; equally im- portant is the requirement to preserve ‘the means of interpreting, reading and utilizing the bit stream’ (Deegan and Tanner, 2002).
-&gt; Deegan, M. and Tanner, S. (2002) The digital dark ages. Update, May
-&gt; Deegan, M. and Tanner, S. (eds) (2006) Digital preservation. London: Facet

# Changes in the availability

‘technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterize the classic industrial model of print commodities’ (Nurnberg, 1995, p.21). -&gt; [Nurnberg, G. (1995) The places of books in the age of electronic reproduction. In *Future libraries*, ed. R.H. Bloch and C.A. Hesse, pp.13-37. Berkeley: University of California Press] &gt;&gt;&gt; 
“This has significant implications for preservation, especially in terms of who takes responsibility for it and at what stage preservation actions are first applied. For instance, in the industrial-mode print world, acquiring the artifact – the book – so that it could be preserved occurred by means such as legal deposit legislation, requiring publishers to provide copies to libraries for preservation and other purposes. If the creator is now also the publisher and distributor, as is often the case in the digital world, who has the responsibility of acquiring the information?
[developed later]”

# Why preserve digital material 

&gt; Preservation is based on the notion that, because man learns from the past,  ‘evidence of the past therefore has considerable signifcance to the human race and is worth saving’ (Harvey, 1993, p.6).



—


——

"We don't know where this Internet is going, and once we get there it will be very instructive to look back."

Donald Heath, president of the Internet Society in Reston, Virginia (quoted in https://archive.org/about/)</Text>
        </Document>
        <Document ID="33">
            <Title>Draft2</Title>
            <Text>
# Introduction

As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts. This literature review aims to get an overview of the current problems, techniques and practices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the various methods used to do so. It also encompasses legal and ethical issues arising from it,  and how the paradigms and methods change when applied to different types of archiving (e.g. for researchers, for businesses, and for personal businesses).

# Why digital preservation
[Stats of numbers on digital vs physical]

## Why digital degrades faster
### 	UNESCO’s Threats to digital continuity
UNESCO (2003, pp. 30-31) has identified a list of threats to what they call *digital continuity*. These are:
+ “The carriers used to store these digital materials are usually unstable and deteriorate within a few years or decades at most”. Where, in the traditional preservation paradigms for paper-based artifacts, the main rule is that “benign neglect may be the best treatment” (derived from Cloonan (1993, p.596), Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612-613)),  this cannot be applied to digital storage media because their lifetime is much shorter. This varies highly with the type of medium used and with the storage conditions; for example, samples by the Digital Preservation Coalition (2008, p. 154) show that D3 cartridge tapes deteriorates after 50 years in optimal conditions (25% RH at 10º) but only one year in high humidity and temperatures (50%RH at 28º). Similar results happen for the more commercially available optical media (down to three months and up to 200 years), which are more sensitive to moisture (Harvey, 2012, p.47).

+ “Use of digital materials depends on means of access that work in particular ways: often complex combinations of tools including hardware and software, which typically become obsolete within a few years and are replaced with new tools that work diﬀerently” (UNESCO, 2003). Even if storage media could survive decades or even centuries, technological change means we will not necessarily have the means to access the data later. In other words, “to retain appropriate access to a digital object, we must maintain a mechanism to derive meaning from that object” (del Pozo et al., 2012, p6): for optical media, this includes not only the drives to read the disc, but also a cable to connect the drive to the computer’s motherboard, a motherboard that has a connector for this type of cable, and an operating system that has drivers for this connectivity (Pearson 2009, slide 11). Once we have access to the bitstream from the computer we need to be able to represent it, which means we also need to keep the software in a version that can open the preserved file.
There is a myth, kept by both customers and vendors, that media is long-lived: “[An IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” (Weathley, 2003, cited by Harvey, 2012, p. 37)

+ Poor preservation documentation and metadata means it could be hard for potential users to find the data (UNESCO 2003)
+ + poor preservation (“Critical aspects of functionality, such as formatting of documents or the rules by which databases operate, may not be recognised and may be discarded or damaged in preservation processing.”, UNESCO 2003) + “So much contextual information may be lost that the materials themselves are un- intelligible or not trusted even when they can be accessed” -&gt; poor integrity

+ “Materials may be lost in the event of disasters such as fire, flood, equipment failure, or virus or direct attack that disables stored data and operating systems”
+ “Access barriers such as password protection, encryption, security devices, or hard-coded access paths may prevent ongoing access beyond the very limited circumstances for which they were designed”. [This argument is particularly true for web archiving, where crawlers of national libraries retrieve all sort of files to preserve them but do not necessarily have the permission or know the rights owner] [back that up maybe yo]

## Importance of data

### Library material: for society

&gt; “if we librarians do not rise to the occasion, successive generations will know less and have access to less for the first time in human history. This is not a challenge from which we can shrink or a mission in which we can fail” (Gorman, 1997, cited in Harvey, 2012, p. 27)

### For businesses (records)
### Personal archiving / domestic archiving
### Preserving interactive material inc. video games

In addition to the preservation of “static” documents and images, there is a significant desire to preserve video games, which are getting recognised as a form of art similarly to movies and music. The Library of Congress (2007) gave awards for the preservation of video games; there is a growing interest in being able to play “retro” games, but the consoles are obsolete. A large community of hobbyists reverse engineered consoles and produced emulators of these platforms for PC and other platforms different from their intended one. Because no documentation is available, this is a Herculean task; byuu (2011), the developer of an emulator for Super Nintendo games, recalls this for reengineering certain cartridges:

&gt; [Low-level emulation] is also a very expensive operation, monetarily speaking: to obtain the DSP program code requires melting the integrated circuit with nitric acid, scanning in the surface of a chip with an electron microscope, and then either staining and manually reading out or physically altering and monitoring the traces to extract the program and data ROMs. This kind of work can cost up to millions of dollars to have done professionally, depending upon the chip's complexity, due to the extremely specialized knowledge and equipment involved.  (byuu, 2011)

Obviously this is not necessarily a route many institutions would like to take for preserving digital objects. Because this also causes intellectual property issues, Nintendo and Sony have launched their own preservation programs, allowing players to play “classic” games on the newer generations of consoles; this is a far more accurate emulation (as they do have the internal documentation to create these emulators) and respects their monetary interests (players have to buy the games, whereas in hobbyist emulation, you would have to download the game file).

### Useful for researchers in the future

Beyond the governmental and cultural needs for preservation, there is also great need for preserving scientific data. “Data are the foundation on which scientific, engineering, and medical knowledge is built” (Committee on Ensuring the Utility and Integrity of Research Data in a Digital Age, 2009, p. ix, cited in Harvey, 2012, p. 26); therefore it is crucial in a digital era, with enormous data sets and research papers becoming widely public, to ensure this doesn’t disappear.

#### Understanding our history

There is a need to define what is the purpose of archives. As a tool to learn from the past, or to keep records, but as Cook (2000) eloquently puts it:
&gt; “Archives […] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)

Preservation should, therefore, be considered very important. There is some skepticism to this:

&gt; “It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002).
&gt; Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole… truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. 
&gt;[…]
&gt; It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33-34)

While it’s difficult to argue that preserving digital objects is necessary, there is certainly a need to define what deserves to be protected, and to what level.

#### Understanding the beginnings of the Internet, as we have shifted in an information society
##### Preserving an accurate + [integrity] image of our society at a given point

###### Twitter &amp; Usenet

Camille Paloque-Bergès (2011; 2013) proposes that we can already find historical and sociological evidence of a given period in Internet time when browsing archives of Usenet [footnote: An Internet discussion system established in the 1980s and that is widely regarded as the predecessor of the Web and online fora]. She analysed how the way of speaking has evolved [footnote: See also http://wwwtxt.org (or @wwwtxt on Twitter), a project collecting short phrases of the Usenet to demonstrate this] and how an self-organised community had built itself, noting that we can “feel [the community’s] informational generativity” and understand that one of the biggest qualities of the early users of the Internet was their “recursivity as a public” (Paloque-Bergès, 2013); that is, how they welcomed newcomers — notably through the use of FAQs [footnote: Frequently Asked Questions], which weren’t a common concept back then. There are also large elements of nostalgia coming back (Paloque-Bergès, 2011).

It is also interesting to come back on the archival of Usenet. The messages were not systematically archived, and obviously not available on the Web as it did not exist and is separate. Today’s collections have mainly been recreated from donations of people who did archived Usenet newsgroup, originally to DejaVu News in 1995, and Google Groups in 2001.
A number of privacy concerns were raised with the publication of these searchable archives; messages who were, 15 to 20 years earlier, thought to be confidential are now considered as digital heritage. There was also a large backlash against the archiving made by for-profit companies, and the credit taken later by Google for its donors, with other critiques like Brad Templeton’s (an Internet veteran and important figure; cited in Paloque-Berges, 2013)  remark that the archive was lacking in integrity. However, the searchability of these archives did bring welcomed technical possibilities for an Internet historiography, including a timeline where “the announcement of the Chernobyl disaster on Usenet stands alongside the first message of Linus Torvalds calling for help on what would become the Linux operating system” (Paloque-Bergès, 2013). 

Similar concerns appeared at the announcement of the archival of Twitter by the Library of Congress in 2010. The two are not really comparable, mostly because the archive is not public and is made by a not-for-profit body. On the mailing list of the Association of Internet Researchers, the idea was met with interest: “The public twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important” (Baym, 2010) [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021125.html]”. However, the privacy concerns (notably with public and private feeds) were discussed, and as Michael Zimmer remarked:
&gt; “This is the classic “but the information is already public” argument that, while technically true, presumes a false dichotomy that information is either strictly public or private, ignoring any contextual norms that might have guided the initial release of information or how a person expects that information to flow.” (Zimmer, M. [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021136.html]; see also his paper (2010) on Facebook privacy, going further in that argument) 

Paloque-Bergès (2010) theorises this argument, suggesting that “information is not an object, but a statement; it goes through socio-technical processes; it doesn’t have an objective nature”. A message in a tweet can have a very different context when taken apart of the moment it was posted. It also emphasises that privacy could change (the user could, later, switch their account to Private, delete the tweet or their account altogether, but this wouldn’t be reflected in the archive. We cannot know what is the user’s original intent when they posted their message, and, as Paloque-Bergès (2010) noted, we aren’t sure the user themselves know.
&gt; “More often than not, in a technical ecosystem in which making content private is more difficult than sharing broadly, teens choose to share, even if doing so creates the impression that they have given up on privacy. It’s not that every teen is desperate for widespread attention; plenty simply see no reason to take the effort to minimize the visibility of their photos and conversations.” (Boyd, 2014).

## Advantages over physical preservation
### Mass preservation, easier access and organisation

### Recording digitally material that’s not born-digital
## Cost of restoration; case studies of lost data

A number of institutions have already experienced loss of data, or data being corrupted. This can have disastrous consequences for businesses, for example, as noted by McAteer (1996, cited by Ross and Gow, 1999, p. iii): “of the 350 companies unexpectedly relocated by the [1993] World Trade Centre (NYC) bombing 150 [43%] ceased trading,
many because they lost access to key business records held in electronic form”. 

Data can, obviously, be sometimes restored. Ross and Gow (1999, pp. 39-42, referenced in Harvey, 2012, p. 34) provide a number of case studies. Harvey (2012, p. 34) also gives the ironic example of the website for the “Functional Requirements for Evidence in Recordkeeping” project, directed by the University of Pittsburgh which was accidentally deleted; but thankfully was automatically saved by the Internet Archive.

There is still the possibility of restoring data by specialised carriers; however Pearson (2009, slide 15) notes that while this was generally effective, this did not work on some items. He also regrets that the restoration loses all metadata in the process; this can be an issue for sensitive or classified information (for business or governmental archives) as the carrier would be able to see it; finally, it is a prohibitely expensive operation, and so a carefully planned preservation could be much cheaper (and obviously more reliable) than neglect.
However, these services are always useful in certain cases. Harvey (2012, p. 41) cites the statistics by the data recovery giant Kroll Ontrack (2011): “hardware and system problems cause most customers to approach them (29 per cent), followed by human error (27 per cent). Software corruption or program problems, computer viruses and natural disasters are the other reasons listed.”

# Defining paradigms for digital preservation
### Pre-digital paradigms
### Inability to preserve the medium, only the bitstream
### Importance of metadata, relationship &amp; context
### Definition of terms		
		
# What to preserve / Selectivity
## Harvey 5 pillars for selectivity (Harvey 2012, p. 26)
* If **unique information** objects that are vulnerable and sensitive and therefore subject to risks can be preserved and protected
* If preservation ensures long-term accessibility for researchers and the public;
* If preservation fosters the accountability of governments and organisations
* If there is an economic or societal advantage in re-using information
* If there is a legal requirement to keep it (NSF-DELOS Working Group on Digital Archiving and Preservation, 2003, p.3).

### Banks reasons for domestic archiving
In *The Future of Looking Back*, Richard Banks (2011) analyses the reasons that lead us to keep or discard physical objects at home. He argues that while making a selection is a positive thing because it forces us to filter our belongings and focus on what is really meaningful, we also run the risk of ridding ourselves of things that we wish we would have kept in retrospect. He points out that the organisation of digital files make this trickier: because we we can keep pretty much everything on virtual space, it is easier to accidentally delete meaningful things alongside the less important. (Banks, 2011 p. 22).

In the context of personal archiving, Banks notes that in the past, the legacy we leave behind us was a highly selective one. Because our possessions are limited by physical space, our ancestors until now “have implicitly indicated that an item is significant through the simple act of keeping it. Although thousands of objects likely crossed their path over their lifetime, the constraints of money and space meant that only a few were retained, often the most significant.” (Banks, 2011, p. 78). He does however argue that this is no longer true in a digital world, because new possibilities mean we simply accumulate digital objects without necessarily ordering them by importance.

### Technical possibility of archiving

### Pros/cons of archiving the entire internet

There are various controversies around whether we should automate the archiving of the Internet, or if we should operate a manual selection. UNESCO (2003, p. 73) notes that those who value a more comprehensive collection (i.e. archiving “all” the Internet) argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything”. This argument is particularly true because of the digital media: “unlike non-digital material such as paper-based artifacts, where there is a period of time in which to make selection decisions before deterioration of materials becomes an issue, the time frame for deciding whether or not to preserve digital materials is very short” (Harvey, 2012, p. 57). UNESCO (2003, p.71) backs that claim: “it may not be possible to wait for evidence of enduring value to emerge before making selection decisions”.

Other people [Cook?] think that it would be preferable to keep a curated collection because of a higher technical quality, and this also allow us to settle [negotiate?] preservation rights with the content producers. Harvey adds that we also do not have the technical capabilities to find all the pages on the Internet, and even if we had we would not have the technical possibility to store the whole of the Internet (Harvey 2012, p. 58); again, this is also something recognised by UNESCO: “‘there are usually more things – more information, more records, more publications, more data – than we have the means to keep” (2003, p.70).

The UNESCO (2003) and Cook (2000) both however recognise that a middle ground should be found and that both approaches are valid depending on the goal of the preservation. For instance, the Internet Archive[IA] is going through an automated process (archive as many pages as possible) but, because of technical limitation, only preserves the text and dismisses all other images, stylesheets and external media, which could be critical in some instances. It seems evident that for valued documents these should be retained. The British Library’s Web Archive[ukwa] [http://www.webarchive.org.uk/ukwa/] 

###	Dangers of selection (Cook)
However, Cook (2000) points out the dangers of manual selection for what is worth archiving: “With memory comes the inevitable privileging of certain records and records creators, and the marginalizing or silencing of others” (Cook, 2000, cited in Harvey p. 58). He asserts that the archivists must be impartial and objective, and ensure all points of view are kept to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination”. This is something that is clear with manual archiving, but could also be a problem, maybe unintentionally, with the automated discovery of content when archiving Web pages.
		
### Automatic selection (Reputation model)
In order to keep the most valuable content, algorithms could be used. Kawano (2008) proposes to use reputation models, that attempts to determine the relative value of a Web page by considering its “importance, fairness, trustiness, uniqueness and valuation”. This is done using a variety of ways; the algorithm suggested by Kawano relies on the consistency of a web page, that is the amount of time it existed, the number of links it contains and the number of external links to this page  (Kawano, 2008, p. 291).

#### Crawling
#### Manual curating
	
### Special Collections for events (eg before elections, see webarchive.org.uk for other ideas)
Another interesting selection process that has emerged is the one of *specific archiving* when certain events are happening. For instance, the UK Web Archive[ukwa] has, on top of their topical-based collections (Energy, Health and Social Care…), a few event-based collections (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks…) which reflect the state of the Web at that given moment in history. Masanès (2006, p.83) notes that this type of archiving must be manually curated and thoroughly preparated. He gives a methodology for this, using presidential elections as an example: a time frame for the collection must be defined (“3 months before the election + 1 month after”), what type of sites will be archived and when (“the political parties’ blogs and websites, every week; analysis, commentary and humourous/satire websites, every month; online newspaper articles, once”).

[Opposing to automated archiving]: Masanès (2006) also describes the technique used for crawling a set of websites automatically. For example, when attempting to save all sites located in France for the French National Library, the robots were instructed to start navigating from 12 existing directories of websites, and restrict what they save to sites with a .fr domain name, or, for more generic top-level domain names (.com, .net, .org…), check if the phone number used for DNS[footnote explanation] registration is a French number (starting with +33). (Masanès 2006, p. 83)

### Selection: by genre [web]
There are different genres of websites: institutional website, blogs, personal pages, forums. [[Genre have been studied in the context of the Web to see how they replicate or diverge from the genre in the print- ing world (see Crowston and Williams 1997) - in Masanès p88]]. An interesting point about this is that often, robots (crawlers, or later data analysis) can automatically identify their type [Rehm 2002 -&gt; check reference, Masanès:88] which permits the automatic generation of metadata, or simply to restrict a collection of web pages to certain Web genres.

# Web archiving: what stands as heritage on the web

# Who should preserve

Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era; but as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterize the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and this is also true for businesses and personal data.
The Task Force on Archiving of Digital Information (1996, pp. 19-20) suggests that when, in general, “stakeholders disseminate, use, reuse, recreate and re-disseminate various kinds of digital information, they can easily, even inadvertently, destroy valuable information, corrupt the cultural record, [and ultimately thwart the pursuit of knowledge that is their common end]. Against such a danger, a safety net is needed to ensure that digital information objects with long-term cultural and intellectual value survive the expressions of stakeholder interest with their integrity intact.

[&gt; Society has always created objects and records describing its activities, and it has consciously preserved them in a permanent way… Cultural institutions are recognised custodians of this collective memory: archives, librar[ies] and museums play a vital role in organizing, preserving and providing access to the cultural, intellectual and historical resources of society. They have established formal preservation programs for traditional materials and they understand how to safeguard both the contextual circumstances and the authenticity and integrity of the objects and information placed in their care… It is now evident that the computer has changed forever the way information is created, managed, archives and accessed, and that digital information is now an integral part of our cultural and intellectual heritage. However the institutions that have traditionally been responsible for preserving information now face major technical, organisational, resource, and legal challenges in taking on the preservation of digital holdings (B. Smith, 2002, pp.133-134) [cited in Harvey p. 29].]

A variety of new stakeholders are now required to collaborate more for a good preservation practice to take place. Lavoie and Dempsey (2004, cited in Harvey, 2012, p. 30) argues that cooperation “can enhance the productive capacity of a limited supply of digital preservation funds, by building shared resources, eliminating redundancies, and exploiting economies of scale”. Chapter 11 of the UNESCO guidelines (2003) give more pratical details on how this can take place, giving structural models and tips on what to share (information, standards, division of labour…). [CLOCKSS cooperation to preserve journals (see Harvey p32 + chapter 9); + Harvey p32 National Library of Netherlands &amp; Elsevier Science + most uni libraries access with publishers, even UoD with eg Dawsonera/ACM]

## Legal issues
### (see later) special case for emulation

In certain cases, the archiving process is not made in accordance with the original publisher. This is often the case for the automated archiving of the Internet (e.g. Wayback Machine), which automatically crawl pages, but as a website publisher, it is easily possible to opt out of these schemes [see http://archive.org/about/exclude.php [Accessed 17th Apr 2014]].
In the case of emulation, this is what happens with *reverse engineering*, that is, disassembling the original program to understand how it works and recreate a similar version which can operate from a different hardware or software architecture. This is a common process for proprietary software or hardware, whose source code is not available to the general public and no documentation is provided for developers. Often, this is developed by amateurs and hobbyists, but is illegal as it breaks the intellectual property of the original creator; Nintendo, for example, attacks reverse engineered emulators[http://www.nintendo.com/corp/legal.jsp [Accessed 17th Apr 2014]] and the sharing of ROMs [Read Only Memory; the bitstream of cartridges or discs containing the games]. There is however popular demand for playing these, and Nintendo has developed their own emulators to play legacy games on their new consoles (see the Virtual Console [http://en.wikipedia.org/wiki/Virtual_Console]), while still retaining their property rights (you need to buy the games again on an e-commerce platform). This however causes issue for the longer term preservation: there is no certainty that Nintendo will continue to provide this service on their future generations of consoles, or if they ever cease operations.



A similar issue happened with Apple Computer. In 2005, Apple changed the architecture (that is, the “language” of instructions needed for the processor) of their personal computers from PowerPC to Intel x86. This means that applications needed to be rewritten, sometimes from the ground up, to work natively on the newer Apple computers. To ease the transition, Apple created **Rosetta**, a software that dynamically translates PowerPC instructions to x86 instructions, so that buyers of the new Apple computers were still able to open legacy applications that were not yet rewritten for x86 — although this came with a significant performance hit. In 2009 however, support for PowerPC was entirely discontinued […]

## Libraries

Good curating and preservation starts early. Smith (2003, pp. 2-3, cited in Harvey, 2012, p. 32) suggests that “the critical dependency of preservation on good stewardship begins with the act of creation, and the creator has a decisive role in the longevity of the digital object”. Harvey (2012, p. 32) notes that “for most creators of information in any form this is a new role”; therefore publishers of digital content are not necessarily well prepared for preservation, and this is why collaboration with librarians and archivists can be helpful (Ayre and Muir, 2004). 

Ayre and Muir (2004) note that if the publisher worries about preservation themselves then they generally already own the rights for preservation, but there are negotiations to be done if an external body helps with preservation. 

## National libraries

Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Elsevier Science) or publishers directly (ACM).
A report by Hedstrom and Montgomery (1998, cited by Ayre and Muir, 2004) found that most research librarians in the UK thought that a legal deposit to national archives was the best option, but this was not a clear consensus. The report also highlighted that these librarians thought that “other libraries and publishers would need to, and should, have some involvement in preservation”.

Because all preservation methods involve copying of the original object, it might be illegal to make such a copy without the necessary rights, even if it is for preservation purposes. Certain countries have laws to overcome this and allow national libraries to preserve all materials; Ayre and Muir (2004) list a few of them and their specificities, but the situation has since evolved, as a lot of legislations have enacted changes to specifically include digital materials.

## Archivists
## New stakeholders
## Profits vs nonprofits

Harvey (2012) points out doubts in the real interests of for-profit companies to achieve long-term preservation;
&gt; Even given the prevailing market-driven political ethos, it is difficult to envisage a situation where market forces will be sufficient to ensure the preservation of this digital material. The opposite is more likely to apply: ‘in some cases market forces work against long-term preservation by locking customers into proprietary formats and systems’ (Workshop on Research Challenges in Digital Archiving and Long-term Preservation, 2003, pp.x-xi). (Harvey, 2012, p. 32). [link with Google concerns]

# How to preserve
## Software methods
### Making hard copies
What appears to be the simplest solution is to make physical copies (i.e. print) of the digital documents. Although this certainly solves some problems in regards to technological obsolescence, Rothenberg (1999) and Granger (2000) pointed out that this cannot be done for more interactive material besides text and images. There is also, obviously, an issue with the amount of content that can be stored in this way — this would not work for archiving websites. Granger (2000) recognises that “if one’s sole concern is with the intellectual content of a document and the document is of a fairly simple nature […] this at least provides some form of security”.

### Standardisation

Standardisation is the transformation of a document’s content to a format that is standardised, open and well documented, ensuring that we will be able to open it with a variety of applications on a variety of platforms and that we can rebuild a program for visualising that document — as opposed to vendor-specific, closed source program that could be discontinued at any point in the future. Rothenberg (1999, p. 10) claims that this is a bad solution because “standardisation sows the seeds of its own destruction by encouraging vendors to implement non-standard features in order to secure market share” (therefore these non-standard features will be lost if opened in a different application). Granger (2000) argues that the blame is not to be put on the method, but on vendors.
Standardisation is a type of migration and therefore share some of it cons (notably, this absence of vendor-specific features could imply a loss in the presentation and other characteristics). Standards eventually become obsolete so it is also paramount to preserve the specifications of the format, or to define formats that are unambiguous, such as CSV or XML.

A slightly different approach to this method is rebuilding viewers. In this scenario, the bitstream is not migrated to a standardised format, but kept as is; we simply re-build a viewer that is able to read that format. This is not as straightforward as it sounds, because most of the time, formats for proprietary software are not documented and decrypting them would require reverse engineering. If they are documented, then it is likely that this format is already a standard. There exists cases where reverse engineering is possible, or where a non-standard format is documented; for example, Microsoft Word files are not a standard, but there is plenty of documentation available online to produce code able to read them. An experiment by the VERS project (Thibodeau 2002, p. 22) has shown that it is possible to reengineer a viewer for the PDF file format from the specification available; as long as we also preserve these specifications, we will be able to read PDF files in the future.

#### UVC

Lorie (2000, in Thibodeau, 2002, p. 22) has also proposed that the use of a portable programming language, such as Java [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine, which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.]. Lorie developed a software called Universal Virtual Computer (UVC), able to decrypt a variety of file formats, which can run on any platform supporting Java; because Java could be implemented on virtually any architecture, this means that a reader could be run on any platform without any effort. However, Lorie points out, this approach is limited in terms of functionality, and comes at the price of performance (because portable programming languages are platform-agnostic, this means the code is not optimised for any of the platforms). I am also wondering if this would really work on the long term, as we cannot be sure that future implementations of Java will be backward compatible with code written for a previous version.

### Migration

Migration is the transformation of a document’s content to a format that is not necessarily standardised, but at least current; or, the newer version of same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed (although this can be overcome by migrating to more flexible formats like PDF or LaTeX).
Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.

### Computer museums

Another approach to preservation, proposed by Swade (1993), would be to preserve a variety of hardware, software and devices to access obsolete media in “computer museums”. This is generally not considered a good solution; Granger (2000) notes that it would be unreasonably expensive to keep old machines running for an extended period of time, that computers chips will eventually decay anyway (and repair or replacement will be impossible), and that storage media not stand the test of time. There are still two possible use cases, identified by Rothenberg (1999): ensuring that emulators work as expected (by comparing them to original platforms), and helping with the recovery of lost data on obsolete media

### Emulation

Emulation is the dynamic transformation of instruction sets to allow software and/or operating system designed for an obsolete architecture or platform to run on current systems. It is a highly complex method that offers certain benefits; notably, this is the most conservative method, as it is not destructive of the content or presentation. It allows us to run the original program used to create a digital object without altering that bitstream ; it “keeps the look and feel as well as the interactivity” (Granger, 2000) and as such, it is particularly interesting for objects rich in interaction, such as video games, data visualisations, or formats that are particularly complex (for example, medical imagery, 3D modelisations), for which methods like migration would be hard. It also ensures complete integrity and authenticity, which could be crucial for some data types.

There are numerous criticisms against emulation. A number of legal and intellectual property problems are raised, if the emulation strategy is not supported by the original author [see Nintendo &amp; Apple]. The complexity involved in creating emulators might be not worth it and requires a coherent organisation to reduce overhead (Granger 2000). Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to the delivery of the preserved content; “most users in the future will never have encountered—not to mention learned how to use—most of the products they will need to access the preserved information objects”, and “it would cut users off from the possibility of using more advanced technologies for discovery, delivery, and analysis”.

&gt; “Emulators themselves become obsolete; therefore, it becomes necessary either to replace the old em- ulator with a new one or to create a new emulator that allows the old emulator to work on new platforms. In fact, if you get into an emula- tion strategy, you have bought into a migration strategy. Either strategy adds complexity over time.” (thibodeau 2002 p.20)

[NB: due to the length limit of this literature review, I have only explained the most popular archiving techniques. See Thibodeau (2002) and Harvey (2012) for a more comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.]

## Choosing one

Thibodeau (2002, pp. 15-16) suggests four criteria to choose a preservation method: *feasibility*, *sustainability*, *practicality* and *appropriateness*. 

Feasability means that the hardware and the software for implementing a given method must be existing and developed. 
Sustainability is ensuring that this method can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable”. This means that the method must be resistant to technological obsolescence, both for storing the data (medium will change) and accessing it (means to access the media ane decode the bitstream will change).

Practicality is establishing that this method will be reasonably difficult and affordable. [This can generally change depending on the resources of the preserving organisation, the available technology at that time and the valuation of the digital objects.]

Finally, appropriateness is using a method that is relevant to the type of material being preserved, and the objectives of the preservation. For example, del Pozo et al. (2012, p. 7) suggests that if the integrity and authenticity of the documents are not paramount, then a migration that keeps the contents but discards the presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).

### Authenticity/integrity and issues with each method

Different preservation methods yield different results in what is called **authenticity**, that is how faithful the rendition [its presentation] of the preserved object will be. Authenticity is subjective and therefore there is debate around this issue (Del Pozo et al., 2012, p. 7; Cook, 2000); however most agree that while as little difference in the presentation is desirable, it is rarely (if ever) possible to keep a truthful rendition. As an example, del Pozo et al. (2012, p. 8) use a spreadsheet within the migration method:
&gt; “For instance, one institution may decide to normalise a spreadsheet into a PDF, which would retain the cell values but destroy any formula used to calculate them. This would favour a particular presentation of that digital object over the information form of the original. On the other hand, another institution might decide to normalise spreadsheets into ODF, which may lose some formatting but retain the formula used to derive each cell. In this case, being able to retain the information form of the file would be seen as more important.”

Thibodeau (2002, p. 28) however points out that “people will want to use the best available technology—or at least technologies they know how to use—for discovery, retrieval, processing, and delivery of preserved information. There is a danger that to the degree that preservation solutions keep things unaltered they will create barriers to satisfying this basic user requirement.” An overly faithful preservation would therefore not be desirable. Again, this is subject to a high number of parameters.

Another important issue is *integrity*, i.e. “ensuring the object is complete and has not been altered or corrupted” (Harvey, 2012, p. 54; Ross [CITED], 2002, p. 7); that is, the object “is what it purports to be”, and no parts are missing from it. This is particularly important, Harvey (2012, p. 54) notes, for business archiving, where the legal value of a digital object could be lost if we cannot demonstrate that this object hasn’t been tampered with, or that a migration processes have not incurred data losses.
However, as Lynch (2000) has argued, the integrity of objects is only a matter of trust. The guidelines of UNESCO (2003, p. 22) recommend that the best protection for authenticity is proper documentation of the archival process; Harvey (2012, p. 54) expands on this idea: “for instance, if it can be established that a digital object has always been kept in the custody of an archive in which every change to it has been recorded (such as changes resulting from migration of the bit-stream – the dates at which migration occurred, to which media, and so on), then we can be more secure about its integrity.” 

### Emulation / legal rights with videogames



## Use of standards

Some standards such as OAIS (Open Archival Information System), originally developed for space science, could be used. Sadly [no implementation] [source??]

# Personal archiving

On a more personal level, Harvey (2012) and Lukesh (1999) note that personal correspondance might be lost if we do not take steps to preserve them:

&gt; “The widespread shift from writing letters to the use of email has diminished the likelihood that personal correspondence will remain accessible to future historians. Lukesh asked in 1999, ‘Where will our understandings of today and, more critically, the next century be, if this rich source of information is no longer available?’, as scientists, scholars, historians and almost everyone increasingly use email” (Lukesh, 1999) (in Harvey, 2012 p. 32)

While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.

Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.
However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited; second, storing photos and data on online services mean we may forget about them in a few years (Banks, 2011).

## What happens after our death
### [Digital heritage]
## Shifts in usages (more photos)
## Advantages (sharing, organisation etc.); record part of our lives we never did before

Digital artifacts have certain fundamental advantages over physical objects: the main two being the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost-free (Banks, 2011). This actually provides numerous advantages in terms of preservation. 

[[+ tie with “In the past ancestors have signified something is important simply by keeping it” part ]]

The first one, ease of organisation, can be significantly helpful in tackling the abundance of digital data. Banks (2011) suggests that the technologies lying behind the ranking in the result of Web search engines could, eventually, help us in understanding and finding what is our most important data. An attempt has been made by the MUSE (Memories USing Email) project (Hangal et al., 2011), which aims to find patterns in our emails archives to help us make sense of this large data set. As the authors note in the introduction:

&gt; “Email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later, and thereby use their email account as an informal backup device. Therefore, email archives contain or reflect memories that are extremely valuable for the purposes of reminiscence.” (Hangal et al., 2011)

Early users reported that they have been using it to: make a summary of their work progress over the year; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; renewing with old relationships; and serendipitous discovery. The authors note in the conclusion that the different uses of their program went beyond their original expectations of simply reminiscing: “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.”

The second advantage, the ability to accurately and easily make copies and backups, is fairly obviously an advantage for personal preservation. However, Banks (2011) notes, the process of backing up is troublesome and storage media do not make our data immune. Additionally, the use of online services to store our data creates an abstraction between the storage material and us; about Flickr: “I have no idea what kind of hardware my files are now stored or even where they are geographically. I just expect to have access to them as long as I pay my bills” (Banks, 2011, p. 27).

## Keeping memories attached to digital objects

Banks (2011) also suggests that we could blend in the physical and the digital to allow recording of things we never had the opportunity to before. He gives as example the Weather Camera, an experimental object by Kjen Wilkens (2011) that records wind and temperature along with commentary, instead of an image, as an alternative to recall a place; or 3D backups by Héctor Serrano (2009), another experimental project that allows us to make backups of sentimentally important objects through 3D scanning and 3D printing. 
Similarly, Banks notes tools by Microsoft Research to recreate places in a 3D environment based on photos, allowing to recreate a sentimentally important place at any given point in time provided enough photos are available. A similar technique is used in bigger preservation projects, as described by Zhou et al. (2012), to make high quality 3D models of culturally important places and objects in China.

Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining that we could augment physical objects with RFID tags (and I would add, virtual reality technologies) to pass down stories attached to these objects.

Conclusion</Text>
        </Document>
        <Document ID="34">
            <Title>draft3-annotated</Title>
            <Text>The need for digital preservation
With an exponential growth in data being produced digitally (SINTEF, 2013), comes a growth in the volume of data worth preserving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional preservation paradigms; where we can consider that for paper and physical artifacts, “benign neglect may be the best treatment” (Harvey, 2012, p. 10; derived from Bastian, Cloonan and Harvey, 1993; 2011), the rapid changes in technology and the fragility of digital media make this rule dangerous for the survival of data.
First, we should define what are archives, and what they are useful for. As Cook eloquently puts it:
“Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)
It is certainly difficult to understand which data was already lost, and what is at stake now. Harvey emitted some criticism of pessimistic views for archiving:
“It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
￼￼￼
While it is difficult to argue that preserving digital objects is necessary, there is certainly a need to make a selection of what deserves to be protected, and to what level. It is clear that the long term preservation of legal and governmental records, scientific publications (Harvey, 2012, p. 26) and business records (Ross and Gow, 1999, p. iii) on digital form is crucial; but the archival of the wider Internet, cultural artifacts and our personal heritage is subject to discussion.
UNESCO note that those who value a more comprehensive collection argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything” (UNESCO, 2003, p. 73). Additionally, digital storage media degrade so rapidly that the content might disappear before a decision about its value has been made (UNESCO, 2003, p. 71; Harvey, 2012, p. 57). Proponents of a more selective collection argue that we could obtain a higher content quality, settle the preservation rights with content producers, and that we do not have the physical resources to store everything anyway (UNESCO, 2003, pp. 70–73; Harvey, 2012, pp. 26, 58). Both UNESCO (2003) and Cook (2000) recognise that a middle ground must be found, and that both approaches are valid depending on the goal of the preservation intent. For example, the Internet Archive (Kahle, 1996) stores copies of as many websites as possible, but discards all images, stylesheets and multimedia objects in the process due to technical limitations; evidently this is not appropriate for valuable websites. The British Library’s Web Archive [footnote: http://www.webarchive.org.uk/ukwa/] curates collections of websites by topic and by events (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks, General Elections ...) to reflect the state and opinion of the Web at these given points in history; because fewer sites are archived and their content is deemed important, they have archived full quality versions of these sites. See Masanès (2006, p.83) for a methodology for this type of selection. Cook reminds us however that archivists have a duty of impartiality and objectivity during the selection and must ensure all points of view are being kept, to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination” (Cook, 2000).
Hiroyuki Kawano also proposes to use reputation models to let crawling robots consider the “importance, fairness, trustiness, uniqueness and valuation” of a Web page (Kawano, 2008) based on numerous parameters, to
￼
decide whether a page is worth archiving. The automated nature of this selection can, by nature, be inaccurate and inadvertently subjective, therefore a manual selection is still sometimes required.
Threats to digital continuity
UNESCO (2003, pp. 30–31) has compiled a list of threats to what they call digital continuity. The two principal ones are the short lifetime of digital materials carriers (i.e. storage media), and the obsolescence of the means to access these digital materials (i.e. the software to read files and the hardware to read discontinued storage media).
The Digital Preservation Coalition (2008, p. 154) show that the reliability of storage material varies highly depending on the type of material and the storage conditions; for example D3 cartridges tapes start to deteriorate after 50 years in optimal conditions (low temperature and humidity) but only a year in warm and humid atmospheres. The range is even greater with optical media like DVDs, going from 3 months to a theoretical 200 years.
But the media are only part of the equation; because these media become obsolete, we will not necessarily be able to read them again even if they are not deteriorated. Weathley (2003, cited by Harvey, 2012, p. 37) denounced that myth of long-lived media: “[an IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” And as Pearson adds, not only is the CD-ROM drive needed, but also the type of cable to plug that drive to the computer, a computer motherboard that has a connector for this cable, an operating system with drivers for these types of connectors, and a program able to open the file itself (Pearson, 2009, slide 11). All of these elements become rapidly obsolete themselves, which mean that media may not be easily accessible on current technology after just one or two decades, even if the storage media last longer than that. Therefore it is needed to periodically migrate (a process also called “refreshing”) the bitstreams from a media type to a more contemporary one in order to ensure that this bitstream will remain easily accessible (Harvey, 2012). As the bitstream is preserved, only the question of software is left.
￼
Who must preserve, and what we should keep
Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era. But as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterise the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and for many publishers the task of preservation is new to them (Harvey, 2012, p. 32); they might not have the awareness, knowledge or resources to do so themselves it is therefore essential that they collaborate with preservation organisations, such as libraries and archives (Ayre and Muir, 2004). See Harvey (2012, chapter 9), Ayre and Muir (2004) and UNESCO (2003, chapter 11) for more resources and case studies. Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Ebrary) or publishers directly (ACM, Elsevier Science, Springer).
How to preserve
There are multiple methods for preservation. Each has advantages and issues, although one parameter is particularly influential: authenticity. This refers to the faithfulness of the rendition of the preserved object in the future, compared to when it was created; while the content should not be altered, its presentation may change (Cook, 2000). What is considered appropriately authentic is subject to debate (del Pozo et al., 2012, p. 7; Cook, 2000) and may vary depending on the preservation intent; del Pozo et al. (2012, p. 8) give, as example, the normalisation of a spreadsheet to formats that may accurately retain either the formatting, or the formulae used in each cell. Retaining integrity, that is ensuring the object is “what it purports
￼
to be” and is “complete and has not been altered or corrupted” (Ross, 2002, p. 7, cited in Harvey, 2012, p. 54), can also be crucially important, particularly for proving that a business or legal document has not been tampered with (Harvey, 2012, p. 54). But as Lynch (2000), UNESCO (2003, p. 22) and Harvey (2012, p. 54) argue, integrity is mostly a matter of trust and can only be ensured with a thorough documentation of the archiving process.
Methods for software preservation
NB: due to the length limit of this literature review, I have only explained the most popular archiving techniques. See Thibodeau (2002) and Harvey (2012) for a comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.
Making hard copies
What appears to be the simplest solution is to make physical copies of the digital documents (i.e. print them). Rothenberg (1999) and Granger (2000) both note that this obviously isn’t a viable option for large data sets and interactive content, but Granger recognises it could provide a form of security for simple documents.
Computer Museums
Swade (1993) proposed to preserve a variety of hardware and software to access legacy media and files in centralised places. Granger (2000) critiques this idea, thinking that it would be prohibitely expensive and would only postpone the issue, as computer chips will decay anyway. Rothenberg (1999) has the same arguments but noted that such museums could be helpful for recovering data found on obsolete media, and testing emulators.
Migration
The most popular option is migration, that is, the transformation of a document’s content to a current format — either a different format of the same type (e.g. image type, text type) or a newer version of the same format. This could be, for example, transferring documents from the WordPerfect 6
￼
format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed. Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.
Standardisation
This option is similar to migration, but it preconises switching to a software-agnostic standardised format, which must be well documented or unambiguous, to allow the re-creation of editors and viewers later (Granger 2000). This solution avoids some of the drawbacks with migration (it avoids the need to migrate periodically and the format/software cannot be discontinued) but, because no vendor-specific formatting is allowed, it could lose some specificities of the document and as such is only usable for certain simpler data types (Rothenberg 1999).
Universal Virtual Computer (UVC)
This model proposed by Lorie (2000, in Thibodeau, 2002, p. 22) uses a portable programming language [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine (itself low-level, different for every platform) which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.] to create an implementation of a viewer which could then theoretically be ran on any later platform supporting that programming language. However, Lorie notes that this approach restricts functionality
￼
and performance, and I am wondering if future implementations of these portable programming languages will be backward compatible with that code.
Emulation
Emulation is the most conservative model; it is not destructive of the original bitstream (unlike migration) and proposes to emulate the characteristics of a legacy platform on a current computer, in order to run the original software used to create it. Therefore it “keeps the look and feel as well as the interactivity” (Granger, 2000) and is particularly useful for highly interactive material like video games and scientific visualisations. It also guarantes integrity and authenticity, which could be crucial in some preservation scenarios.
However, it is highly complex and is criticised for this; Granger (2000) thinks that the amount of work involved in creating emulators would rarely be justified, and if it is, it requires a coherent global organisation to reduce overhead. Emulators also become obsolete (Thibodeau, 2002, p. 20) and so still require a high maintenance cost. Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to delivery: it would deprive new users of future technological advances for discovery and analysis, and force them into learning to use a dated interface they might never have seen before.
It might, also, raise a number of legal and intellectual property issues from the software provider. For software that is proprietary or discontinued, the source code is not available, and being able to emulate it requires to do reverse engineering [footnote: Disassembling the original program to understand how it works and recreate a similar version which can operate from a different hardware or software architecture], which breaks intellectual property of the publishers.
Emulation is highly used for video games, as other methods are unsuitable for accurately recreating them. The Library of Congress (2007) gave awards for the preservation of video games; there is a growing interest in being able to play “retro” games, but the consoles are obsolete or discontinued and so are the games. There has been a thriving community of hobbyists reverse engineering console games; this requires considerable efforts (byuu, 2011)
￼
and is generally considered illegal. In response to the growing interest, and to protect their rights and interests[footnote: See http://www.nintendo.com/corp/legal.jsp [Accessed 17th Apr 2014]], Nintendo started to offer their own emulation solution to play classic games on their current generation consoles. This however causes issue for the longer term preservation: there is no certainty that Nintendo will continue to provide this service on their future generations of consoles, or if they ever cease operations. This has happened in the past with Apple, who provided emulation software to run legacy software on their new architectures to ease transition (MacInsider, 2011; Mesa, A. F., 1997) but was later discontinued, effectively removing support for any pre–2005 application on their current models.
Choosing a method
Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method: * Feasibility: means that the hardware and the software for implementing a given method must be existing and developed. * Sustainability: ensuring that the method is resistant to technological obsolescence and that it can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable” (Thibodeau, 2002). * Practicality: establishing that the method is reasonably easy and affordable, in line with the preserving organisation’s resources. * Appropriateness: the method must be relevant to the type of material being preserved, and the objectives of the preservation. For instance, del Pozo et al. (2012, p. 7) suggest that if the integrity and authenticity of the documents are not paramount, then a migration that keeps the contents but discards its presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).
Web Archiving
Archiving the Internet and preserving privacy
￼
Camille Paloque-Bergès (2011; 2013) suggests that we can already find historical and sociological evidence of a given period in Internet time when browsing archives of Usenet [footnote: An Internet discussion protocol established in the 1980s and that is widely regarded as the predecessor of the Web and online fora]. She analysed how the way of speaking has evolved [footnote: See also http://wwwtxt.org (or @wwwtxt on Twitter), a project collecting short phrases of the Usenet to demonstrate this] and how a self-organised community had built itself, noting that we can “feel [the community’s] informational generativity” and understand that one of the biggest qualities of the early users of the Internet was their “recursivity as a public” (Paloque-Bergès, 2013); that is, how they welcomed newcomers — notably through the use of FAQs [footnote: Frequently Asked Questions], which weren’t a common concept back then. There are also large elements of nostalgia coming back (Paloque-Bergès, 2011).
It is also interesting to come back on the archival of Usenet. The messages were not systematically archived, and obviously not available on the Web as we know it, as it did not exist and is a separate network (albeit functioning on the same Internet). A number of privacy concerns were caused with the publication of searchable archives (first by DejaVu News in 1995, then Google Groups in 2001); messages who were, 15 to 20 years earlier, thought to be confidential are now considered as our common digital heritage.
Similar concerns were raised at the announcement of the archival of Twitter by the Library of Congress in 2010, but two significant elements make it different: the archive is not public and is made by a not-for-profit body. On the mailing list of the Association of Internet Researchers (2010), the idea was met with interest: “The public twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important” (Baym, 2010) [footnote: Direct link: http://listserv.aoir.org/pipermail/air-l- aoir.org/2010- April/021125.html]. However, the privacy concerns (notably with public and private feeds) were discussed, and as Michael Zimmer remarked:
￼
“This is the classic “but the information is already public” argument that, while technically true, presumes a false dichotomy that information is either strictly public or private, ignoring any contextual norms that might have guided the initial release of information or how a person expects that information to flow.” (Zimmer, 2010 [footnote: Direct link: http://listserv.aoir.org/pipermail/air-l-aoir.org/2010- April/021136.html]; see also his paper (2010) on Facebook privacy, expanding on that argument).
Personal archiving
It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal corespondance and sentimental artifacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will understand our modern life without these exchanges. While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.
Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.
However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. Fortunately, digital objects have fundamental properties that physical artifacts don’t have, which actually provide numerous advantages
￼￼
in terms of preservation: the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost- free (Banks, 2011).
The cataloguing advantage allows us to process it using computer science. Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable information.
Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
“the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.” (Hangal et al., 2011)
The copying advantage, while useful for sharing, has issues for backing up. Banks (2011) notes the process is still troublesome, and still feels insecure because of cheap looking media, and nowadays, the abstraction with cloud storage (about Flickr: “I have no idea what kind of hardware my files are now stored on or even where they are geographically. I just expect to have access to them as long as I pay my bills” Banks, 2011, p. 27).
Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining we could also digitally augment physical objects or places. Banks (2011) gives as
￼￼
example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos. A similar technique is used in bigger preservation projects to make high quality 3D models of culturally important places and objects in China (Zhou et al., 2012).
￼</Text>
        </Document>
        <Document ID="35">
            <Title>Draft3</Title>
            <Text># The need for digital preservation

With an exponential growth in data being produced digitally (SINTEF, 2013), comes a growth in the volume of data worth preserving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional preservation paradigms; where we can consider that for paper and physical artifacts, “benign neglect may be the best treatment” (Harvey, 2012, p. 10; derived from Bastian, Cloonan and Harvey, 1993; 2011), the rapid changes in technology and the fragility of digital media make this rule dangerous for the survival of data.

First, we should define what are archives, and what they are useful for. As Cook eloquently puts it:

&gt; “Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)

It is certainly difficult to understand which data was already lost, and what is at stake now. Harvey emitted some criticism of pessimistic views for archiving:

&gt; “It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)

While it is difficult to argue that preserving digital objects is necessary, there is certainly a need to make a selection of what deserves to be protected, and to what level. It is clear that the long term preservation of legal and governmental records, scientific publications (Harvey, 2012, p. 26) and business records (Ross and Gow, 1999, p. iii) on digital form is crucial; but the archival of the wider Internet, cultural artifacts and our personal heritage is subject to discussion.

UNESCO note that those who value a more comprehensive collection argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything” (UNESCO, 2003, p. 73). Additionally, digital storage media degrade so rapidly that the content might disappear before a decision about its value has been made (UNESCO, 2003, p. 71; Harvey, 2012, p. 57. Proponents of a more selective collection argue that we could obtain a higher content quality, settle the preservation rights with content producers, and that we do not have the physical resources to store everything anyway (UNESCO, 2003, pp. 70-73; Harvey, 2012, pp. 26, 58).
Both UNESCO (2003) and Cook (2000) recognise that a middle ground must be found, and that both approaches are valid depending on the goal of the preservation intent. For example, the Internet Archive (Kahle, 1996) stores copies of as many websites as possible, but discards all images, stylesheets and multimedia objects in the process due to technical limitations; evidently this is not appropriate for valuable websites. The British Library’s Web Archive [footnote: http://www.webarchive.org.uk/ukwa/] curates collections of websites by topic and by events (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks, General Elections …) to reflect the state and opinion of the Web at these given points in history; because fewer sites are archived and their content is deemed important, they have archived full quality versions of these sites. See Masanès (2006, p.83) for a methodology for this type of selection. Cook reminds us however that archivists have a duty of impartiality and objectivity during the selection and must ensure all points of view are being kept, to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination” (Cook, 2000).

Hiroyuki Kawano also proposes to use reputation models to let crawling robots consider the “importance, fairness, trustiness, uniqueness and valuation” of a Web page (Kawano, 2008) based on numerous parameters, to decide whether a page is worth archiving. The automated nature of this selection can, by nature, be inaccurate and inadvertently subjective, therefore a manual selection is still sometimes required.


## Threats to digital continuity 

UNESCO (2003, pp. 30–31) has compiled a list of threats to what they call *digital continuity*. The two principal ones are the short lifetime of digital materials carriers (i.e. storage media), and the obsolescence of the means to access these digital materials (i.e. the software to read files and the hardware to read discontinued storage media).

The Digital Preservation Coalition (2008, p. 154) show that the reliability of storage material varies highly depending on the type of material and the storage conditions; for example D3 cartridges tapes start to deteriorate after 50 years in optimal conditions (low temperature and humidity) but only a year in warm and humid atmospheres. The range is even greater with optical media like DVDs, going from 3 months to a theoretical 200 years.

But the media are only part of the equation; because these media become obsolete, we will not necessarily be able to read them again even if they are not deteriorated. Weathley (2003, cited by Harvey, 2012, p. 37) denounced that myth of long-lived media: “[an IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” And as Pearson adds, not only is the CD-ROM drive needed, but also the type of cable to plug that drive to the computer, a computer motherboard that has a connector for this cable, an operating system with drivers for these types of connectors, and a program able to open the file itself (Pearson, 2009, slide 11). All of these elements become rapidly obsolete themselves, which mean that media may not be easily accessible on current technology after just one or two decades, even if the storage media last longer than that. Therefore it is needed to periodically migrate (a process also called “refreshing”) the bitstreams from a media type to a more contemporary one in order to ensure that this bitstream will remain easily accessible (Harvey, 2012). As the bitstream is preserved, only the question of software is left.

# Who must preserve, and what we should keep

Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era. But as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterise the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and for many publishers the task of preservation is new to them (Harvey, 2012, p. 32); they might not have the awareness, knowledge or resources to do so themselves it is therefore essential that they collaborate with preservation organisations, such as libraries and archives (Ayre and Muir, 2004). See Harvey (2012, chapter 9), Ayre and Muir (2004) and UNESCO (2003, chapter 11) for more resources and case studies. 
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Ebrary) or publishers directly (ACM, Elsevier Science, Springer).

# How to preserve

There are multiple methods for preservation. Each has advantages and issues, although one parameter is particularly influential: **authenticity**. This refers to the faithfulness of the rendition of the preserved object in the future, compared to when it was created; while the content should not be altered, its presentation may change (Cook, 2000). What is considered appropriately authentic is subject to debate (del Pozo et al., 2012, p. 7; Cook, 2000) and may vary depending on the preservation intent; del Pozo et al. (2012, p. 8) give, as example, the normalisation of a spreadsheet to formats that may accurately retain either the formatting, or the formulae used in each cell.
Retaining integrity, that is ensuring the object is “what it purports to be” and is “complete and has not been altered or corrupted” (Ross, 2002, p. 7, cited in Harvey, 2012, p. 54), can also be crucially important, particularly for proving that a business or legal document has not been tampered with (Harvey, 2012, p. 54). But as Lynch (2000), UNESCO (2003, p. 22) and Harvey (2012, p. 54) argue, integrity is mostly a matter of trust and can only be ensured with a thorough documentation of the archiving process.


## Methods for software preservation

*NB: due to the length limit of this literature review, I have only explained the most popular archiving techniques. See Thibodeau (2002) and Harvey (2012) for a comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.*

## Making hard copies

What appears to be the simplest solution is to make physical copies of the digital documents (i.e. print them). Rothenberg (1999) and Granger (2000) both note that this obviously isn’t a viable option for large data sets and interactive content, but Granger recognises it could provide a form of security for simple documents.

## Computer Museums
Swade (1993) proposed to preserve a variety of hardware and software to access legacy media and files in centralised places. Granger (2000) critiques this idea, thinking that it would be prohibitely expensive and would only postpone the issue, as computer chips will decay anyway. Rothenberg (1999) has the same arguments but noted that such museums could be helpful for recovering data found on obsolete media, and testing emulators.

## Migration 
The most popular option is migration, that is, the transformation of a document’s content to a current format — either a different format of the same type (e.g. image type, text type) or a newer version of the same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed. Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.

## Standardisation

This option is similar to migration, but it preconises switching to a software-agnostic standardised format, which must be well documented or unambiguous, to allow the re-creation of editors and viewers later (Granger 2000). This solution avoids some of the drawbacks with migration (it avoids the need to migrate periodically and the format/software cannot be discontinued) but, because no vendor-specific formatting is allowed, it could lose some specificities of the document and as such is only usable for certain simpler data types (Rothenberg 1999).

## Universal Virtual Computer (UVC)
This model proposed by Lorie (2000, in Thibodeau, 2002, p. 22) uses a portable programming language [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine (itself low-level, different for every platform) which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.] to create an implementation of a viewer which could then theoretically be ran on any later platform supporting that programming language. However, Lorie notes that this approach restricts functionality and performance, and I am wondering if future implementations of these portable programming languages will be backward compatible with that code.

## Emulation

Emulation is the most conservative model; it is not destructive of the original bitstream (unlike migration) and proposes to emulate the characteristics of a legacy platform on a current computer, in order to run the original software used to create it. Therefore it “keeps the look and feel as well as the interactivity” (Granger, 2000) and is particularly useful for highly interactive material like video games and scientific visualisations. It also guarantes integrity and authenticity, which could be crucial in some preservation scenarios.

However, it is highly complex and is criticised for this; Granger (2000) thinks that the amount of work involved in creating emulators would rarely be justified, and if it is, it requires a coherent global organisation to reduce overhead. Emulators also become obsolete (Thibodeau, 2002, p. 20) and so still require a high maintenance cost. Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to delivery: it would deprive new users of future technological advances for discovery and analysis, and force them into learning to use a dated interface they might never have seen before.

It might, also, raise a number of legal and intellectual property issues from the software provider. For software that is proprietary or discontinued, the source code is not available, and being able to emulate it requires to do reverse engineering [footnote: Disassembling the original program to understand how it works and recreate a similar version which can operate from a different hardware or software architecture], which breaks intellectual property of the publishers.

Emulation is highly used for video games, as other methods are unsuitable for accurately recreating them. The Library of Congress (2007) gave awards for the preservation of video games; there is a growing interest in being able to play “retro” games, but the consoles are obsolete or discontinued and so are the games. There has been a thriving community of hobbyists reverse engineering console games; this requires considerable efforts (byuu, 2011) and is generally considered illegal. In response to the growing interest, and to protect their rights and interests[footnote: See http://www.nintendo.com/corp/legal.jsp [Accessed 17th Apr 2014]], Nintendo started to offer their own emulation solution to play classic games on their current generation consoles. This however causes issue for the longer term preservation: there is no certainty that Nintendo will continue to provide this service on their future generations of consoles, or if they ever cease operations. This has happened in the past with Apple, who provided emulation software to run legacy software on their new architectures to ease transition (MacInsider, 2011; Mesa, A. F., 1997) but was later discontinued, effectively removing support for any pre-2005 application on their current models.

## Choosing a method

Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method:
* **Feasibility**: means that the hardware and the software for implementing a given method must be existing and developed.
* **Sustainability**: ensuring that the method is resistant to technological obsolescence and that it can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable” (Thibodeau, 2002).
* **Practicality**: establishing that the method is reasonably easy and affordable, in line with the preserving organisation’s resources.
* **Appropriateness**: the method must be relevant to the type of material being preserved, and the objectives of the preservation. For instance, del Pozo et al. (2012, p. 7) suggest that if the integrity and authenticity of the documents are not paramount, then a migration that keeps the contents but discards its presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).

# Web Archiving

## Archiving the Internet and preserving privacy

Camille Paloque-Bergès (2011; 2013) suggests that we can already find historical and sociological evidence of a given period in Internet time when browsing archives of Usenet [footnote: An Internet discussion protocol established in the 1980s and that is widely regarded as the predecessor of the Web and online fora]. She analysed how the way of speaking has evolved [footnote: See also http://wwwtxt.org (or @wwwtxt on Twitter), a project collecting short phrases of the Usenet to demonstrate this] and how a self-organised community had built itself, noting that we can “feel [the community’s] informational generativity” and understand that one of the biggest qualities of the early users of the Internet was their “recursivity as a public” (Paloque-Bergès, 2013); that is, how they welcomed newcomers — notably through the use of FAQs [footnote: Frequently Asked Questions], which weren’t a common concept back then. There are also large elements of nostalgia coming back (Paloque-Bergès, 2011).

It is also interesting to come back on the *archival* of Usenet. The messages were not systematically archived, and obviously not available on the Web as we know it, as it did not exist and is a separate network (albeit functioning on the same Internet). A number of privacy concerns were caused with the publication of searchable archives (first by DejaVu News in 1995, then Google Groups in 2001); messages who were, 15 to 20 years earlier, thought to be confidential are now considered as our common digital heritage.

Similar concerns were raised at the announcement of the archival of Twitter by the Library of Congress in 2010, but two significant elements make it different: the archive is not public and is made by a not-for-profit body. On the mailing list of the Association of Internet Researchers (2010), the idea was met with interest: “The public twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important” (Baym, 2010) [footnote: Direct link: http://listserv.aoir.org/pipermail/air-l-aoir.org/2010- April/021125.html]. However, the privacy concerns (notably with public and private feeds) were discussed, and as Michael Zimmer remarked:
&gt; “This is the classic “but the information is already public” argument that, while technically true, presumes a false dichotomy that information is either strictly public or private, ignoring any contextual norms that might have guided the initial release of information or how a person expects that information to flow.” (Zimmer, 2010 [footnote: Direct link: http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021136.html]; see also his paper (2010) on Facebook privacy, expanding on that argument).

# Personal archiving

It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal corespondance and sentimental artifacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will understand our modern life without these exchanges. 
While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.

Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.

However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. Fortunately, digital objects have fundamental properties that physical artifacts don’t have, which actually provide numerous advantages in terms of preservation: the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost-free (Banks, 2011).

The cataloguing advantage allows us to process it using computer science. Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable information.

Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
&gt; “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.” (Hangal et al., 2011)

The copying advantage, while useful for sharing, has issues for backing up. Banks (2011) notes the process is still troublesome, and still *feels* insecure because of cheap looking media, and nowadays, the abstraction with cloud storage (about Flickr: “I have no idea what kind of hardware my files are now stored on or even where they are geographically. I just expect to have access to them as long as I pay my bills” Banks, 2011, p. 27).

Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining we could also digitally augment physical objects or places. Banks (2011) gives as example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos. A similar technique is used in bigger preservation projects to make high quality 3D models of culturally important places and objects in China (Zhou et al., 2012).</Text>
        </Document>
        <Document ID="60">
            <Title>Lecture: gathering data</Title>
            <Text>Talk 17/10/14 how to use data

talk-aloud protocols: ask participants to report what they’re doing
OR talk after (retroactive)
record (?) + transcribe questions &amp; answers, prompt them to tell us what they see, highlight 
CODE the informatº &gt; use colour codes / highlight in same colour different elements
(for instance objects in blue; environment in violet…). Categorise questions (Realness, Anything else…)
Colour code same issues in the end (interview analysis)
Avoid questionnaires &gt; more qualitative than qtitative, prefer interviews
In the report: reference the different interviews/appendices by number (Realness: bla blah findings (4.3.2))
Quote of the itw below the results to back up claims
Link things together to make a point don’t just leave it at the end
Detail age groups/genders not individually by participant but as a whole (on 13 participants, 8 female and 5 male). “General demographics”

Explain methodology (eg authoethnography) -&gt; keep track of what you do, what you think about it, 

3 things to do w/ your data
## Introduce it properly ie talk about participants, methods &amp; procedures involved in gathering data
Provide intro to why gather the data
Who participated in it, ages, gender, profession/background

Methods: itws, questnnrs, video observs, focus grps
What procedures, how long were the itws, what happened during video obs or focus grp

## Present the most important parts
Protocols used to analyse the data
Explain how it is codes
Finding patterns that repeat or themes that emerge from the data,
or new information that contradicts existing theories

State what the results are, provide explanation, provide examples of real-world data
Quotes

## Provide evidence to back up analysis eg example of actual data

Provide ALL raw data in appendices
Questions asked
Provide on disc if video/audio not transcribed… -&gt; then provide timecodes

—
Explain if it contradicts/keeps in line with own opinion, treat it like any other source

SECTIONS of a RESEARCH CHAPTER in the body: (appendices only contain raw data/transcripts)
Intro : why we did this
participants + demographics
methodological approach + method &gt; description of the procedure used (eg what is itw, what is auto ethnography, wht it was relevant)
procedure followed / what did you do, happened, analysed
results presented alongside examples
discussion of results &amp; evidence

</Text>
        </Document>
        <Document ID="36">
            <Title>LiteratureReview-light</Title>
            <Text>DJ32004 RESEARCH &amp; CREATIVE PRACTICE PART 1 LITERATURE REVIEW
DIGITAL PRESERVATION
Victor Loux April 2014
Digital Interaction Design University of Dundee
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼
Table of contents
2 Table of contents
2 List of figures
3 Introduction
4 The need for digital preservation
6 Threats to digital continuity
7 Who must preserve, and what we should keep
7 How to preserve
8 Methods for software preservation
9 Choosing a method
9 Personal archiving
12 Conclusion
13 Bibliography
17 Project Proposal Form
List of figures
1.1 and 1.2 Kjen Wilkens, Sensor Poetics / Weather Camera http://www.kjenwilkens.com/projects/sensor-poetics
2.1 Héctor Seranno, Back Up Objects
http://www.hectorserrano.com/index.php?id=41&amp;m=lab&amp;grupo=backup
￼￼2
Introduction
As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts.
This literature review aims to get an overview of the current problems, techniques and prac- tices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the var- ious methods used to do so. It also encompasses personal archiving which will be the focus of my own research.
3
The need for digital preservation
With an exponential growth in data being produced digitally (SINTEF, 2013), comes a signif- icant growth in the volume of data worth archiving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional pres- ervation paradigms; where we can consider that for paper and physical artefacts, “benign ne- glect may be the best treatment” (Harvey, 2012, p. 10; derived from Bastian, Cloonan and Har- vey, 1993; 2011), the rapid changes in technology and the fragility of digital media make this rule dangerous for the survival of data.
First, we should define what are archives, and what they are useful for. As Cook eloquently puts it:
“Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)
It is certainly difficult to understand which data was already lost, and what is at stake now. Harvey emitted some criticism of pessimistic views for archiving:
“It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p. 32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
4
While it is difficult to argue that preserving digital objects is necessary, there is certainly a need to make a selection of what deserves to be protected, and to what level. It is clear that the long term preservation of legal and governmental records, scientific publications (Harvey, 2012, p. 26) and business records (Ross and Gow, 1999, p. iii) on digital form is crucial; but the archival of the wider Internet, cultural artefacts and our personal heritage is subject to discus- sion, as fewer items could be considered valuable.
UNESCO note that those who value a more comprehensive collection argue that “any informa- tion may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything” (UNESCO, 2003, p. 73). Additionally, digi- tal storage media degrade so rapidly that the content might disappear before a decision about its value has been made (UNESCO, 2003, p. 71; Harvey, 2012, p. 57). Proponents of a more selective collection argue that we could obtain a higher content quality, settle the preserva- tion rights with content producers, and that we do not have the physical resources to store everything anyway (UNESCO, 2003, pp. 70-73; Harvey, 2012, pp. 26, 58).
Both UNESCO (2003) and Cook (2000) recognise that a middle ground must be found, and that both approaches are valid depending on the goal of the preservation intent. To give an ex- ample in archiving the Web, the Internet Archive (Kahle, 1996) has chosen to store copies of as many websites as possible, but due to technical limitations discards all images, stylesheets and multimedia objects; evidently this is not appropriate for valuable websites. The British Library’s Web Archive 1 curates collections of websites by topic and by events (Queen Jubi- lee, London 2005 terrorist attacks, General Elections, Olympic and Paralympic Games, ...) to reflect the state and opinion of the Web at these given points in history; because fewer sites are archived and their content is deemed important, they have archived full quality versions of these sites. See Masanès (2006, p. 83) for a methodology for this type of selection. Cook reminds us however that archivists have a duty of impartiality and objectivity during the se- lection and must ensure all points of view are being kept, to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination” (Cook, 2000).
Hiroyuki Kawano also proposes to use reputation models to let crawling robots consider the
￼1 http://www.webarchive.org.uk/ukwa/ [Accessed: 11 Apr 2014]
￼5
“importance, fairness, trustiness, uniqueness and valuation” of a Web page (Kawano, 2008) based on numerous parameters, to decide whether a page is worth archiving. The automated nature of this selection can, by nature, be inaccurate and inadvertently subjective, therefore a manual selection is still sometimes required.
Threats to digital continuity
UNESCO (2003, pp. 30–31) has compiled a list of threats to what they call digital continuity. The two principal ones are the short lifetime of digital materials carriers (i.e. storage media), and the obsolescence of the means to access these digital materials (i.e. the software to read files and the hardware to read discontinued storage media). Research by the Digital Preserva- tion Coalition (2008, p. 154) show that the reliability of storage material varies highly depend- ing on the type of material and the storage conditions, going from a few months to decades or even centuries.
But the media are only part of the equation; because all storage media eventually become obsolete, we will not necessarily be able to read them again even if they are not deteriorat- ed. Weathley (2003, cited by Harvey, 2012, p. 37) denounced that myth of long-lived media: “[an IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” And as Pearson adds, not only is the CD-ROM drive needed, but also the type of cable to plug that drive to the computer, a computer motherboard that has a connector for this cable, an operating system with drivers for these types of connectors, and a program able to open the file itself (Pearson, 2009, slide 11). All of these elements become rapidly obsolete themselves, which mean that media may not be easily accessible on current technology after just one or two decades, even if the storage media last longer than that. Therefore it is needed to periodically migrate (a process also called “refreshing”) the bitstreams from a media type to a more contemporary one in order to ensure that this bitstream will remain easily accessi- ble (Harvey, 2012). As the bitstream is preserved, only the question of preserving software to read it is left.
6
Who must preserve, and what we should keep
Digital media also changes the original preservation paradigm for deciding who takes the re- sponsibility for archiving content, and how. Publishing processes used to be distinct in the “analogue” era. But as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and dis- tribution that characterise the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and for many publishers the task of preser- vation is new to them (Harvey, 2012, p. 32); they might not have the awareness, knowledge or resources to do so themselves it is therefore essential that they collaborate with preservation organisations, such as libraries and archives (Ayre and Muir, 2004). See Harvey (2012, chapter 9), Ayre and Muir (2004) and UNESCO (2003, chapter 11) for more resources and case studies.
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preser- vation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preserva- tion systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Ebrary) or publishers directly (ACM, Elsevier Science, Springer).
How to preserve
There are multiple methods for preservation. Each has advantages and issues, although one parameter is particularly influential: authenticity. This refers to the faithfulness of the rendi- tion of the preserved object in the future, compared to when it was created; while the content should not be altered, its presentation may change (Cook, 2000). What is considered appro- priately authentic is subject to debate (del Pozo et al., 2012, p. 7; Cook, 2000) and may vary depending on the preservation intent; del Pozo et al. (2012, p. 8) give, as example, the nor- malisation of a spreadsheet to formats that may accurately retain either the formatting, or the formulae used in each cell.
7
Retaining integrity, that is ensuring the object is “what it purports to be” and is “complete and has not been altered or corrupted” (Ross, 2002, p. 7, cited in Harvey, 2012, p. 54), can also be crucially important, particularly for proving that a business or legal document has not been tampered with (Harvey, 2012, p. 54). But as Lynch (2000), UNESCO (2003, p. 22) and Harvey (2012, p. 54) argue, integrity is mostly a matter of trust and can only be ensured with a thor- ough documentation of the archiving process.
Methods for software preservation
[NB: due to the length limit of this literature review, I only give a simplified overview of the main archiving techniques. See Granger (2000), Thibodeau (2002) and Harvey (2012) for a comprehensive list of methods, including configurable chips, persistent archives, object inter- change format, etc.]
• Hard copies: print documents to archive them. Rarely considered a viable option for large data sets and interactive documents (Granger, 2000; Rothenberg, 1998).
• Computer Museums: Swade (1993) proposed to preserve hardware and software central- ised places. Considered short-term and prohibitively expensive by Granger (2000) but can be useful to recover old media or testing emulators (Rothenberg, 1998).
• Migration: the most popular option, consisting of periodically saving files to a current file type (newer version of a format, different format, or a standardised format) (Granger, 2000; Thibodeau, 2002) to avoid technological obsolescence. It is labour intensive and risky, as it compromises authenticity (Rothenberg, 1998).
• Universal Virtual Computer (UVC): proposed by Lorie (2000, in Thibodeau, 2002, p. 22). It consists of implementing a format viewer in a portable programming language like Java 2 which could then theoretically run on any future platform supporting that pro- gramming language. It is however slow and functionally limited (Lorie 2000), and runs the risk of the portable language itself becoming obsolete.
• Emulation is the most conservative model; it simulates a legacy architec-
2 Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine (itself low-level, different for every platform) which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.
￼8
ture on current platforms, allowing to run the original software used to create a file, therefore not modifying them. It “keeps the look and feel as well as the in- teractivity” (Granger, 2000) therefore is highly relevant for video games (Gut- tenbrunner et al., 2010) and interactive systems, and it guarantees authenticity. It is however highly complex to implement (Granger, 2000; byuu, 2011) and need renew- al, since emulators themselves become obsolete (Thibodeau, 2002), as exemplified by em- ulators provided by Apple for their architecture switches (Mesa, A. F., 1997; AppleInsider, 2011) that were later discontinued, effectively removing the ability to run pre-2005 appli- cations on their current models.
Choosing a method
Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method. It must be:
• technically feasible
• sustainable and resistant to technological obsolescence
• practical (the preserving organisation must have the resources to do it)
• appropriate to the type of material being preserved, and the objectives of the preservation
(see del Pozo et al., 2012, p. 7 and Granger, 2000 for examples).
Personal archiving
It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal correspondence and sentimental ar- tefacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will be able to understand our modern life without these exchanges.
While this is a correct idea, I think that few people kept their letters in the sole purpose of leav- ing researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.
9
Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artefacts for ourselves. The majority of the time, we simply keep what we consider significant to re- mind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundancy) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.
However, the digital age changes this situation. First, the space to store our objects on com- puters and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. Fortunately, digital objects have fundamental properties that physical artefacts don’t have, which actually provide numerous advantages in terms of pres- ervation: the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accu- rately and virtually cost-free (Banks, 2011).
The cataloguing advantage allows us to process it using computer science. Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable in- formation.
Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that has been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
“The stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering in- tentions. Further, it suggests that browsing and remembering the past can affect the fu- ture.” (Hangal et al., 2011)
10
The copying advantage, while useful for sharing, has issues for backing up. Banks (2011) notes the process is still troublesome, and still feels insecure because of cheap looking media, and nowadays, the abstraction with cloud storage (about Flickr: “I have no idea what kind of hard- ware my files are now stored on or even where they are geographically. I just expect to have access to them as long as I pay my bills” Banks, 2011, p. 27).
Kirk and Sellen (2010) found however that ultimately, stories and narrative are more impor- tant than the preservation of the artefact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagin- ing we could also digitally augment physical objects or places. Banks (2011) gives as example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos. A similar technique is used in bigger preservation projects to make high quality 3D models of culturally important places and objects in China (Zhou et al., 2012).
Fig. 1.1: The Weather Camera, by Jens Wilkens. Fig. 1.2: Associating stories and weather to a timeline with the Weather Camera.
Fig. 2: backing up physical sentimental items using a 3D scanner and 3D printing, 11 with Back Up Objects by Héctor Serrano
￼￼￼
Conclusion
This literature review, although shallow considering the breadth of the topic, allowed me to gain an understanding of the current practices and debates in the digital archiving communi- ty, and to gather relevant sources for any future research in each sub-topic. I found the theme of personal archiving captivating but not explored as intensely as large scale preservation for our common knowledge and data; I would like to do deeper research in this particular area of digital preservation, notably on our use of social media and Internet services on the long term.
12
Bibliography
AppleInsider. (2011) ‘Inside Mac OS X 10.7 Lion: Missing Front Row, Rosetta and Java runtime’. AppleInsider. [web page] Accessible at http://appleinsider.com/articles/11/02/26/ mac_os_x_lion_drops_front_row_java_runtime_rosetta.html [Accessed: 19th Apr 2014]
Ayre, C. and Muir, A. (2004) ‘The right to preserve’. D-Lib Magazine, vol. 10 (No. 3). March. Available at http://www.dlib.org/dlib/march04/ayre/03ayre.html [Accessed: 11th Apr 2014]
Banks, R. (2011) The Future of Looking Back. Sebastopol: Microsoft Press.
Bearman, D. (1999) ‘Reality and Chimeras in the Preservation of Electronic Records’. D-Lib Magazine, vol. 5 (No. 4). April. Available at http://www.dlib.org/dlib/april99/ bearman/04bearman.html [Accessed: 7th Apr 2014]
Boyd, D. (2014) It’s Complicated: The Social Lives of Networked Teens. New Haven and London: Yale University Press.
byuu.1 (2011) ‘Accuracy takes power: one man’s 3 GHz quest to build a perfect SNES emulator’. Ars Technica. [web page] Available at: http://arstechnica.com/gaming/2011/08/ accuracy-takes-power-one-mans-3ghz-quest-to-build-a-perfect-snes-emulator/ [Accessed: 8th Apr 2014]
Cook, T. (2000) ‘Beyond the screen: the records continuum and archival cultural heritage.’ Presented at the Australian Society of Archivists Conference, Melbourne, 18 August. Available at http://www.mybestdocs.com/cook-t-beyondthescreen-000818.htm [Accessed: 9th Apr 2014]
Granger, S. (2000) ‘Emulation as a Digital Preservation Strategy’. D-Lib Magazine, vol. 6 (No. 10). October. Available at http://www.dlib.org/dlib/october00/granger/10granger.html [Accessed: 7th Apr 2014]
Guttenbrunner, M., Becker, C. and Rauber, A. (2010) ‘Keeping the game alive: Evaluating strategies for the preservation of console video games’. International Journal of Digital Curation, vol. 5 (Iss. 1), pp. 64-90.
￼￼￼￼￼￼￼￼￼￼1 The article is only credited to the developer’s pseudonym.
13
Bibliography (cont.)
Hangal, S., Lam, M. S. and Heer, J. (2011) ‘MUSE: reviving memories using email archives’, in
Proceedings of the 24th annual ACM symposium on User interface software and technology (UIST ‘11). New York, NY: ACM, pp. 75-84. doi:10.1145/2047196.2047206
Harvey, D. R. (2012) Preserving digital materials. Berlin: De Gruyter Saur.
Kahle, B. (1996) ‘Archiving the Internet’. Scientific American, Iss. March 1997. Available at http://web.archive.org/web/19971211123138/www.archive.org/sciam_article.html [Accessed: 27th Feb 2014]
Kawano, H. (2008) ‘Strategy of Digital Contents Archive Based on Reputation Model’, in ICSENG ‘08. Proceedings of 19th International Conference on Systems Engineering, 19-21 Aug, pp. 288-293. doi: 10.1109/ICSEng.2008.75
Kirk, D. S. and Sellen, A. (2010) ‘On human remains: Values and practice in the home archiving of cherished objects’. ACM Transactions on Human-Computer Interaction, vol. 17 (Iss. 3), article 10. doi:0.1145/1806923.1806924
Library of Congress. (2007) Digital Preservation Program Makes Awards to Preserve American Creative Works. [press release] Available at http://www.loc.gov/today/ pr/2007/07-156.html [Accessed: 14th Apr 2014]
Lubar, S. (1999) ‘Information Culture and the Archival Record’, in American Archivist, vol. 62 (Iss. 1), pp. 10-22.
Lynch, C. (2000) “Authenticity and Integrity in the Digital Environment: An Exploratory Analysis of the Central Role of Trust’, in Authenticity in a Digital Environment. Washington, DC: Council on Library and Information Resources. Available at http://www. clir.org/pubs/abstract/pub92abst.html [Accessed: 16th Apr 2014]
Masanès, J. (2006) Web archiving. Berlin: Springer.
Mesa, A. F. (1997) ‘The PowerPC Triumph’. The Apple Museum. [web page] Available at: http://applemuseum.bott.org/sections/ppc.html [Accessed: 19th Apr 2014]
￼￼￼￼￼￼￼￼￼14
Bibliography (cont.)
Paloque-Bergès, C. (2011) Entre trivialité et culture : une histoire de l’Internet vernaculaire. Émergence et médiations d’un folklore de réseau [Between Triviality and Culture: a History of the Vernacular Internet. Emergence and mediations in network folklore]. PhD thesis, self-published. Available at http://camillepaloqueberges.wordpress.com/phd-thesis/ [Accessed: 6th Apr 2014] 2
Paloque-Bergès, C. (2013) ‘Un patrimoine composite : le public Internet face à l’archivage
de sa matière culturelle’ [A composite heritage: the Internet public confronted to the archiving of its cultural matter], in I. Dragan, P. Stefanescu, N. Pelissier, J.-F. Tétu and
L. Idjeroui-Ravez (eds.) Traces, mémoire, communication. Bucharest: Editura Universităţii din Bucureşti. 2
Pearson, D. (2009) Preserve or Preserve Not, There is No Try: some dilemmas relating
to Personal Digital Archiving. [PowerPoint slides]. National Library of Australia Staff Papers. Available at http://www.nla.gov.au/openpublish/index.php/nlasp/article/view/1388 [Accessed: 9th Apr 2014]
del Pozo, N., Long, A. S. and Pearson, D. (2012) ‘Land of the Lost: a discussion of what can be preserved through digital preservation’. Library Hi Tech, vol. 28 (Iss. 2), pp. 290-300. Available from: doi: 10.1108/07378831011047686. [Accessed: 6th Apr 2014]
Ross, S. and Gow, A. (1999) Digital archaeology: rescuing neglected and damaged data resources: a JISC/NPO study within Electronic Libraries (eLib) Programme on the Preservation of Electronic Materials. London: Library Information Technology Centre. Available at http://www.ukoln.ac.uk/services/elib/papers/supporting/pdf/p2.pdf [Accessed: 17th Apr 2014]
Rothenberg, J. (1998) Avoiding Technological Quicksand: Finding a Viable Technical Foundation for Digital Preservation. [report] Washington, DC: Council on Library and Information Resources.
￼￼￼￼￼2 In French.
15
Bibliography (cont.)
Serrano, H. (2009) Back Up Objects, Héctor Serrano. [web page] Available at: http://www. hectorserrano.com/index.php?id=41&amp;m=lab&amp;grupo=backup [Accessed: 17th Apr 2014].
SINTEF. (2013) ‘Big Data, for better or worse: 90% of world’s data generated over last two years.’ ScienceDaily. [web page] Available at: http://www.sciencedaily.com/ releases/2013/05/130522085217.htm [Accessed: 16th Apr 2014]
Swade, D. (1993) ‘The problems of software conservation”, in Computer Resurrection, vol. 7. Available at: http://www.cs.man.ac.uk/CCS/res/res07.htm#f [Accessed: 12th Apr 2014]
Task Force on Archiving of Digital Information. (1996) Preserving digital information, Report of the Task Force on Archiving of Digital Information. Washington, DC: Council on Library and Information Resources.
Thibodeau, K. (2002) ‘Overview of technological approaches to digital preservation
and challenges in coming years’, in The state of digital preservation: an international perspective. Washington, DC: Council on Library and Information Resources, pp. 4-31.
UNESCO. (2003) Guidelines for the preservation of digital heritage, prepared by the National Library of Australia. Paris: UNESCO. Available at http://unesdoc.unesco.org/ images/0013/001300/130071e.pdf [Accessed: 9 Apr 2014]
Wilkens, K. (2011) Sensor Poetics, Kjenwilkens.com. [web page] Available at http://www. kjenwilkens.com/projects/sensor-poetics [Accessed: 18th Apr 2014]
Zimmer, M. (2010) ‘“But the data is already public”: on the ethics of research in Facebook’, in Ethics and information technology, vol. 12 (Iss. 4), pp. 313-325. doi: 10.1007/s10676-010- 9227-5
Zhou, M., Geng, G. and Wu, Z. (2012) Digital preservation technology for cultural heritage. Berlin: Springer.
￼￼￼￼￼￼￼￼￼￼￼￼16
Project Proposal Form
￼￼Name Programme/Course Project/working title
Project Aims (i.e. what you want to learn about through further investigation. E.g. I want toa learn more about the creative process of animators)
Objectives (i.e. the particular things you propose to do
in order to carry out your investigation. E.g. Make contact with professional animators and arrange
to meet them. Possibly Interview them or observe their creative activities to gather data)
Methods (i.e. the different ways in which you will achieve these objectives. E.g. Open ended interview techniques and grounded theory analysis or video observation of working animators)
Victor Loux
Digital Interaction Design
Digital preservation for the masses
I would like to look at further research papers on personal preservation and focus on ways to apply “large-scale” paradigms to our personal heritage while trying to be respectful of people’s privacy and unintrusive.
I first intend to do further reading in this area, as until now I have been exploring digital preservation as a whole with no particular focus, to get a broader understanding of the issues
and solutions. I would like to interview several people of different age ranges to understand their relationship to technology and their personal digital heritage, notably concerning photographs and conversations.
Using open ended interview techniques, further literature review and possibly research through practice as I intend to explore this theme for my final year project.
￼￼￼￼￼￼￼￼￼￼￼￼17
</Text>
        </Document>
        <Document ID="61">
            <Title>Literature review</Title>
        </Document>
        <Document ID="37">
            <Title>LiteratureReview</Title>
            <Text># The need for digital preservation

With an exponential growth in data being produced digitally (SINTEF, 2013), comes a significant growth in the volume of data worth archiving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional preservation paradigms; where we can consider that for paper and physical artifacts, “benign neglect may be the best treatment” (Harvey, 2012, p. 10; derived from Bastian, Cloonan and Harvey, 1993; 2011), the rapid changes in technology and the fragility of digital media make this rule dangerous for the survival of data.

First, we should define what are archives, and what they are useful for. As Cook eloquently puts it:

&gt; “Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)

It is certainly difficult to understand which data was already lost, and what is at stake now. Harvey emitted some criticism of pessimistic views for archiving:

&gt; “It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)

While it is difficult to argue that preserving digital objects is necessary, there is certainly a need to make a selection of what deserves to be protected, and to what level. It is clear that the long term preservation of legal and governmental records, scientific publications (Harvey, 2012, p. 26) and business records (Ross and Gow, 1999, p. iii) on digital form is crucial; but the archival of the wider Internet, cultural artifacts and our personal heritage is subject to discussion, as fewer items could be considered valuable.

UNESCO note that those who value a more comprehensive collection argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything” (UNESCO, 2003, p. 73). Additionally, digital storage media degrade so rapidly that the content might disappear before a decision about its value has been made (UNESCO, 2003, p. 71; Harvey, 2012, p. 57). Proponents of a more selective collection argue that we could obtain a higher content quality, settle the preservation rights with content producers, and that we do not have the physical resources to store everything anyway (UNESCO, 2003, pp. 70-73; Harvey, 2012, pp. 26, 58).
Both UNESCO (2003) and Cook (2000) recognise that a middle ground must be found, and that both approaches are valid depending on the goal of the preservation intent. To give an example in archiving the Web, the Internet Archive (Kahle, 1996) has chosen to store copies of as many websites as possible, but due to technical limitations discards all images, stylesheets and multimedia objects; evidently this is not appropriate for valuable websites. The British Library’s Web Archive [footnote: http://www.webarchive.org.uk/ukwa/] curates collections of websites by topic and by events (Queen Jubilee, London 2005 terrorist attacks, General Elections, Olympic and Paralympic Games, …) to reflect the state and opinion of the Web at these given points in history; because fewer sites are archived and their content is deemed important, they have archived full quality versions of these sites. See Masanès (2006, p.83) for a methodology for this type of selection. Cook reminds us however that archivists have a duty of impartiality and objectivity during the selection and must ensure all points of view are being kept, to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination” (Cook, 2000).

Hiroyuki Kawano also proposes to use reputation models to let crawling robots consider the “importance, fairness, trustiness, uniqueness and valuation” of a Web page (Kawano, 2008) based on numerous parameters, to decide whether a page is worth archiving. The automated nature of this selection can, by nature, be inaccurate and inadvertently subjective, therefore a manual selection is still sometimes required.


## Threats to digital continuity 

UNESCO (2003, pp. 30–31) has compiled a list of threats to what they call *digital continuity*. The two principal ones are the short lifetime of digital materials carriers (i.e. storage media), and the obsolescence of the means to access these digital materials (i.e. the software to read files and the hardware to read discontinued storage media). Research by the Digital Preservation Coalition (2008, p. 154) show that the reliability of storage material varies highly depending on the type of material and the storage conditions, going from a few months to decades or even centuries.

But the media are only part of the equation; because all storage media eventually become obsolete, we will not necessarily be able to read them again even if they are not deteriorated. Weathley (2003, cited by Harvey, 2012, p. 37) denounced that myth of long-lived media: “[an IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” And as Pearson adds, not only is the CD-ROM drive needed, but also the type of cable to plug that drive to the computer, a computer motherboard that has a connector for this cable, an operating system with drivers for these types of connectors, and a program able to open the file itself (Pearson, 2009, slide 11). All of these elements become rapidly obsolete themselves, which mean that media may not be easily accessible on current technology after just one or two decades, even if the storage media last longer than that. Therefore it is needed to periodically migrate (a process also called “refreshing”) the bitstreams from a media type to a more contemporary one in order to ensure that this bitstream will remain easily accessible (Harvey, 2012). As the bitstream is preserved, only the question of preserving software to read it is left.

# Who must preserve, and what we should keep

Digital media also changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era. But as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterise the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and for many publishers the task of preservation is new to them (Harvey, 2012, p. 32); they might not have the awareness, knowledge or resources to do so themselves it is therefore essential that they collaborate with preservation organisations, such as libraries and archives (Ayre and Muir, 2004). See Harvey (2012, chapter 9), Ayre and Muir (2004) and UNESCO (2003, chapter 11) for more resources and case studies. 
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Ebrary) or publishers directly (ACM, Elsevier Science, Springer).

# How to preserve

There are multiple methods for preservation. Each has advantages and issues, although one parameter is particularly influential: **authenticity**. This refers to the faithfulness of the rendition of the preserved object in the future, compared to when it was created; while the content should not be altered, its presentation may change (Cook, 2000). What is considered appropriately authentic is subject to debate (del Pozo et al., 2012, p. 7; Cook, 2000) and may vary depending on the preservation intent; del Pozo et al. (2012, p. 8) give, as example, the normalisation of a spreadsheet to formats that may accurately retain either the formatting, or the formulae used in each cell.
Retaining integrity, that is ensuring the object is “what it purports to be” and is “complete and has not been altered or corrupted” (Ross, 2002, p. 7, cited in Harvey, 2012, p. 54), can also be crucially important, particularly for proving that a business or legal document has not been tampered with (Harvey, 2012, p. 54). But as Lynch (2000), UNESCO (2003, p. 22) and Harvey (2012, p. 54) argue, integrity is mostly a matter of trust and can only be ensured with a thorough documentation of the archiving process.


## Methods for software preservation

*NB: due to the length limit of this literature review, I only give a simplified overview of the main archiving techniques. See Granger (2000), Thibodeau (2002) and Harvey (2012) for a comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.*

* **Hard copies**: print documents to archive them. Rarely considered a viable option for large data sets and interactive documents (Granger, 2000; Rothenberg, 1999).
* **Computer Museums**: Swade (1993) proposed to preserve hardware and software centralised places. Considered short-term and prohibitely expensive by Granger (2000) but can be useful to recover old media or testing emulators (Rothenberg, 1999).
* **Migration**: the most popular option, consisting of periodically saving files to a current file type (newer version of a format, different format, or a standardised format) (Granger, 2000; Thibodeau, 2002) to avoid technological obsolescence. It is labour intensive and risky, as it compromises authenticity (Rothenberg, 1999).
* **Universal Virtual Computer (UVC)**: proposed by Lorie (2000, in Thibodeau, 2002, p. 22). It consists of implementing a format viewer in a portable programming language like Java [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine (itself low-level, different for every platform) which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.] which could then theoretically run on any future platform supporting that programming language. It is however slow and functionally limited (Lorie 2000), and runs the risk of the portable language itself becoming obsolete.
* **Emulation** is the most conservative model; it simulates a legacy architecture on current platforms, allowing to run the original software used to create a file, therefore not modifying them. It “keeps the look and feel as well as the interactivity” (Granger, 2000) therefore is highly relevant for video games (Guttenbrunner et al., 2010) and interactive systems, and it guarantees authenticity.
It is however highly complex to implement (Granger, 2000; byuu, 2011) and need renewal, since emulators themselves become obsolete (Thibodeau, 2002), as exemplified by emulators provided by Apple for their architecture switches (Mesa, A. F., 1997; AppleInsider, 2011) that were later discontinued, effectively removing the ability to run pre-2005 applications on their current models.

## Choosing a method

Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method. It must be:
* technically feasible
* sustainable and resistant to technological obsolescence
* practical (the preserving organisation must have the resources to do it)
* appropriate to the type of material being preserved, and the objectives of the preservation (see del Pozo et al., 2012, p. 7 and Granger, 2000 for examples).

# Personal archiving

It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal corespondance and sentimental artifacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will be able to understand our modern life without these exchanges. 
While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.

Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.

However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. Fortunately, digital objects have fundamental properties that physical artifacts don’t have, which actually provide numerous advantages in terms of preservation: the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost-free (Banks, 2011).

The cataloguing advantage allows us to process it using computer science. Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable information.

Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
&gt; “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.” (Hangal et al., 2011)

The copying advantage, while useful for sharing, has issues for backing up. Banks (2011) notes the process is still troublesome, and still *feels* insecure because of cheap looking media, and nowadays, the abstraction with cloud storage (about Flickr: “I have no idea what kind of hardware my files are now stored on or even where they are geographically. I just expect to have access to them as long as I pay my bills” Banks, 2011, p. 27).

Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining we could also digitally augment physical objects or places. Banks (2011) gives as example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos. A similar technique is used in bigger preservation projects to make high quality 3D models of culturally important places and objects in China (Zhou et al., 2012).</Text>
        </Document>
        <Document ID="62">
            <Title>Workshop</Title>
            <Text>In order to get a better understanding on how we could map a life, I have organised a workshop where I have asked some people to perform a few tasks such as graphically representing their life and retrieving old content on social networks, and answer a few questions about the project. This chapter will detail the methodological approach used to prepare the workshop and questions, then analyse the results and make conclusions on how these results can be used to design a retrieval interface. The raw questions and results are available in the appendices A to E.</Text>
        </Document>
        <Document ID="38">
            <Title>LiteratureReviewLayout</Title>
        </Document>
        <Document ID="63">
            <Title>Introduction</Title>
            <Synopsis>Provide intro to why gather the data
</Synopsis>
        </Document>
        <Document ID="39">
            <Title>LiteratureReviewLayout</Title>
            <Text>DJ32004 RESEARCH &amp; CREATIVE PRACTICE PART 1 LITERATURE REVIEW
DIGITAL PRESERVATION
Victor Loux April 2014
Digital Interaction Design University of Dundee
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼
Table of contents
2 Table of contents
2 List of figures
3 Introduction
4 The need for digital preservation
6 Threats to digital continuity
7 Who must preserve, and what we should keep
7 How to preserve
8 Methods for software preservation
9 Choosing a method
9 Personal archiving
12 Conclusion
13 Bibliography
17 Project Proposal Form
List of figures
1.1 and 1.2 Kjen Wilkens, Sensor Poetics / Weather Camera http://www.kjenwilkens.com/projects/sensor-poetics
2.1 Héctor Seranno, Back Up Objects
http://www.hectorserrano.com/index.php?id=41&amp;m=lab&amp;grupo=backup
￼￼2
Introduction
As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts.
This literature review aims to get an overview of the current problems, techniques and prac- tices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the var- ious methods used to do so. It also encompasses personal archiving which will be the focus of my own research.
3
The need for digital preservation
With an exponential growth in data being produced digitally (SINTEF, 2013), comes a signif- icant growth in the volume of data worth archiving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional pres- ervation paradigms; where we can consider that for paper and physical artefacts, “benign ne- glect may be the best treatment” (Harvey, 2012, p. 10; derived from Bastian, Cloonan and Har- vey, 1993; 2011), the rapid changes in technology and the fragility of digital media make this rule dangerous for the survival of data.
First, we should define what are archives, and what they are useful for. As Cook eloquently puts it:
“Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)
It is certainly difficult to understand which data was already lost, and what is at stake now. Harvey emitted some criticism of pessimistic views for archiving:
“It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p. 32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
4
While it is difficult to argue that preserving digital objects is necessary, there is certainly a need to make a selection of what deserves to be protected, and to what level. It is clear that the long term preservation of legal and governmental records, scientific publications (Harvey, 2012, p. 26) and business records (Ross and Gow, 1999, p. iii) on digital form is crucial; but the archival of the wider Internet, cultural artefacts and our personal heritage is subject to discus- sion, as fewer items could be considered valuable.
UNESCO note that those who value a more comprehensive collection argue that “any informa- tion may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything” (UNESCO, 2003, p. 73). Additionally, digi- tal storage media degrade so rapidly that the content might disappear before a decision about its value has been made (UNESCO, 2003, p. 71; Harvey, 2012, p. 57). Proponents of a more selective collection argue that we could obtain a higher content quality, settle the preserva- tion rights with content producers, and that we do not have the physical resources to store everything anyway (UNESCO, 2003, pp. 70-73; Harvey, 2012, pp. 26, 58).
Both UNESCO (2003) and Cook (2000) recognise that a middle ground must be found, and that both approaches are valid depending on the goal of the preservation intent. To give an ex- ample in archiving the Web, the Internet Archive (Kahle, 1996) has chosen to store copies of as many websites as possible, but due to technical limitations discards all images, stylesheets and multimedia objects; evidently this is not appropriate for valuable websites. The British Library’s Web Archive 1 curates collections of websites by topic and by events (Queen Jubi- lee, London 2005 terrorist attacks, General Elections, Olympic and Paralympic Games, ...) to reflect the state and opinion of the Web at these given points in history; because fewer sites are archived and their content is deemed important, they have archived full quality versions of these sites. See Masanès (2006, p. 83) for a methodology for this type of selection. Cook reminds us however that archivists have a duty of impartiality and objectivity during the se- lection and must ensure all points of view are being kept, to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination” (Cook, 2000).
Hiroyuki Kawano also proposes to use reputation models to let crawling robots consider the
￼1 http://www.webarchive.org.uk/ukwa/ [Accessed: 11 Apr 2014]
￼5
“importance, fairness, trustiness, uniqueness and valuation” of a Web page (Kawano, 2008) based on numerous parameters, to decide whether a page is worth archiving. The automated nature of this selection can, by nature, be inaccurate and inadvertently subjective, therefore a manual selection is still sometimes required.
Threats to digital continuity
UNESCO (2003, pp. 30–31) has compiled a list of threats to what they call digital continuity. The two principal ones are the short lifetime of digital materials carriers (i.e. storage media), and the obsolescence of the means to access these digital materials (i.e. the software to read files and the hardware to read discontinued storage media). Research by the Digital Preserva- tion Coalition (2008, p. 154) show that the reliability of storage material varies highly depend- ing on the type of material and the storage conditions, going from a few months to decades or even centuries.
But the media are only part of the equation; because all storage media eventually become obsolete, we will not necessarily be able to read them again even if they are not deteriorat- ed. Weathley (2003, cited by Harvey, 2012, p. 37) denounced that myth of long-lived media: “[an IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” And as Pearson adds, not only is the CD-ROM drive needed, but also the type of cable to plug that drive to the computer, a computer motherboard that has a connector for this cable, an operating system with drivers for these types of connectors, and a program able to open the file itself (Pearson, 2009, slide 11). All of these elements become rapidly obsolete themselves, which mean that media may not be easily accessible on current technology after just one or two decades, even if the storage media last longer than that. Therefore it is needed to periodically migrate (a process also called “refreshing”) the bitstreams from a media type to a more contemporary one in order to ensure that this bitstream will remain easily accessi- ble (Harvey, 2012). As the bitstream is preserved, only the question of preserving software to read it is left.
6
Who must preserve, and what we should keep
Digital media also changes the original preservation paradigm for deciding who takes the re- sponsibility for archiving content, and how. Publishing processes used to be distinct in the “analogue” era. But as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and dis- tribution that characterise the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and for many publishers the task of preser- vation is new to them (Harvey, 2012, p. 32); they might not have the awareness, knowledge or resources to do so themselves it is therefore essential that they collaborate with preservation organisations, such as libraries and archives (Ayre and Muir, 2004). See Harvey (2012, chapter 9), Ayre and Muir (2004) and UNESCO (2003, chapter 11) for more resources and case studies.
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preser- vation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preserva- tion systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Ebrary) or publishers directly (ACM, Elsevier Science, Springer).
How to preserve
There are multiple methods for preservation. Each has advantages and issues, although one parameter is particularly influential: authenticity. This refers to the faithfulness of the rendi- tion of the preserved object in the future, compared to when it was created; while the content should not be altered, its presentation may change (Cook, 2000). What is considered appro- priately authentic is subject to debate (del Pozo et al., 2012, p. 7; Cook, 2000) and may vary depending on the preservation intent; del Pozo et al. (2012, p. 8) give, as example, the nor- malisation of a spreadsheet to formats that may accurately retain either the formatting, or the formulae used in each cell.
7
Retaining integrity, that is ensuring the object is “what it purports to be” and is “complete and has not been altered or corrupted” (Ross, 2002, p. 7, cited in Harvey, 2012, p. 54), can also be crucially important, particularly for proving that a business or legal document has not been tampered with (Harvey, 2012, p. 54). But as Lynch (2000), UNESCO (2003, p. 22) and Harvey (2012, p. 54) argue, integrity is mostly a matter of trust and can only be ensured with a thor- ough documentation of the archiving process.
Methods for software preservation
[NB: due to the length limit of this literature review, I only give a simplified overview of the main archiving techniques. See Granger (2000), Thibodeau (2002) and Harvey (2012) for a comprehensive list of methods, including configurable chips, persistent archives, object inter- change format, etc.]
• Hard copies: print documents to archive them. Rarely considered a viable option for large data sets and interactive documents (Granger, 2000; Rothenberg, 1998).
• Computer Museums: Swade (1993) proposed to preserve hardware and software central- ised places. Considered short-term and prohibitively expensive by Granger (2000) but can be useful to recover old media or testing emulators (Rothenberg, 1998).
• Migration: the most popular option, consisting of periodically saving files to a current file type (newer version of a format, different format, or a standardised format) (Granger, 2000; Thibodeau, 2002) to avoid technological obsolescence. It is labour intensive and risky, as it compromises authenticity (Rothenberg, 1998).
• Universal Virtual Computer (UVC): proposed by Lorie (2000, in Thibodeau, 2002, p. 22). It consists of implementing a format viewer in a portable programming language like Java 2 which could then theoretically run on any future platform supporting that pro- gramming language. It is however slow and functionally limited (Lorie 2000), and runs the risk of the portable language itself becoming obsolete.
• Emulation is the most conservative model; it simulates a legacy architec-
2 Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine (itself low-level, different for every platform) which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.
￼8
ture on current platforms, allowing to run the original software used to create a file, therefore not modifying them. It “keeps the look and feel as well as the in- teractivity” (Granger, 2000) therefore is highly relevant for video games (Gut- tenbrunner et al., 2010) and interactive systems, and it guarantees authenticity. It is however highly complex to implement (Granger, 2000; byuu, 2011) and need renew- al, since emulators themselves become obsolete (Thibodeau, 2002), as exemplified by em- ulators provided by Apple for their architecture switches (Mesa, A. F., 1997; AppleInsider, 2011) that were later discontinued, effectively removing the ability to run pre-2005 appli- cations on their current models.
Choosing a method
Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method. It must be:
• technically feasible
• sustainable and resistant to technological obsolescence
• practical (the preserving organisation must have the resources to do it)
• appropriate to the type of material being preserved, and the objectives of the preservation
(see del Pozo et al., 2012, p. 7 and Granger, 2000 for examples).
Personal archiving
It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal correspondence and sentimental ar- tefacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will be able to understand our modern life without these exchanges.
While this is a correct idea, I think that few people kept their letters in the sole purpose of leav- ing researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.
9
Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artefacts for ourselves. The majority of the time, we simply keep what we consider significant to re- mind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundancy) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.
However, the digital age changes this situation. First, the space to store our objects on com- puters and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. Fortunately, digital objects have fundamental properties that physical artefacts don’t have, which actually provide numerous advantages in terms of pres- ervation: the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accu- rately and virtually cost-free (Banks, 2011).
The cataloguing advantage allows us to process it using computer science. Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable in- formation.
Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that has been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
“The stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering in- tentions. Further, it suggests that browsing and remembering the past can affect the fu- ture.” (Hangal et al., 2011)
10
The copying advantage, while useful for sharing, has issues for backing up. Banks (2011) notes the process is still troublesome, and still feels insecure because of cheap looking media, and nowadays, the abstraction with cloud storage (about Flickr: “I have no idea what kind of hard- ware my files are now stored on or even where they are geographically. I just expect to have access to them as long as I pay my bills” Banks, 2011, p. 27).
Kirk and Sellen (2010) found however that ultimately, stories and narrative are more impor- tant than the preservation of the artefact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagin- ing we could also digitally augment physical objects or places. Banks (2011) gives as example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos. A similar technique is used in bigger preservation projects to make high quality 3D models of culturally important places and objects in China (Zhou et al., 2012).
Fig. 1.1: The Weather Camera, by Jens Wilkens. Fig. 1.2: Associating stories and weather to a timeline with the Weather Camera.
Fig. 2: backing up physical sentimental items using a 3D scanner and 3D printing, 11 with Back Up Objects by Héctor Serrano
￼￼￼
Conclusion
This literature review, although shallow considering the breadth of the topic, allowed me to gain an understanding of the current practices and debates in the digital archiving communi- ty, and to gather relevant sources for any future research in each sub-topic. I found the theme of personal archiving captivating but not explored as intensely as large scale preservation for our common knowledge and data; I would like to do deeper research in this particular area of digital preservation, notably on our use of social media and Internet services on the long term.
12
Bibliography
AppleInsider. (2011) ‘Inside Mac OS X 10.7 Lion: Missing Front Row, Rosetta and Java runtime’. AppleInsider. [web page] Accessible at http://appleinsider.com/articles/11/02/26/ mac_os_x_lion_drops_front_row_java_runtime_rosetta.html [Accessed: 19th Apr 2014]
Ayre, C. and Muir, A. (2004) ‘The right to preserve’. D-Lib Magazine, vol. 10 (No. 3). March. Available at http://www.dlib.org/dlib/march04/ayre/03ayre.html [Accessed: 11th Apr 2014]
Banks, R. (2011) The Future of Looking Back. Sebastopol: Microsoft Press.
Bearman, D. (1999) ‘Reality and Chimeras in the Preservation of Electronic Records’. D-Lib Magazine, vol. 5 (No. 4). April. Available at http://www.dlib.org/dlib/april99/ bearman/04bearman.html [Accessed: 7th Apr 2014]
Boyd, D. (2014) It’s Complicated: The Social Lives of Networked Teens. New Haven and London: Yale University Press.
byuu.1 (2011) ‘Accuracy takes power: one man’s 3 GHz quest to build a perfect SNES emulator’. Ars Technica. [web page] Available at: http://arstechnica.com/gaming/2011/08/ accuracy-takes-power-one-mans-3ghz-quest-to-build-a-perfect-snes-emulator/ [Accessed: 8th Apr 2014]
Cook, T. (2000) ‘Beyond the screen: the records continuum and archival cultural heritage.’ Presented at the Australian Society of Archivists Conference, Melbourne, 18 August. Available at http://www.mybestdocs.com/cook-t-beyondthescreen-000818.htm [Accessed: 9th Apr 2014]
Granger, S. (2000) ‘Emulation as a Digital Preservation Strategy’. D-Lib Magazine, vol. 6 (No. 10). October. Available at http://www.dlib.org/dlib/october00/granger/10granger.html [Accessed: 7th Apr 2014]
Guttenbrunner, M., Becker, C. and Rauber, A. (2010) ‘Keeping the game alive: Evaluating strategies for the preservation of console video games’. International Journal of Digital Curation, vol. 5 (Iss. 1), pp. 64-90.
￼￼￼￼￼￼￼￼￼￼1 The article is only credited to the developer’s pseudonym.
13
Bibliography (cont.)
Hangal, S., Lam, M. S. and Heer, J. (2011) ‘MUSE: reviving memories using email archives’, in
Proceedings of the 24th annual ACM symposium on User interface software and technology (UIST ‘11). New York, NY: ACM, pp. 75-84. doi:10.1145/2047196.2047206
Harvey, D. R. (2012) Preserving digital materials. Berlin: De Gruyter Saur.
Kahle, B. (1996) ‘Archiving the Internet’. Scientific American, Iss. March 1997. Available at http://web.archive.org/web/19971211123138/www.archive.org/sciam_article.html [Accessed: 27th Feb 2014]
Kawano, H. (2008) ‘Strategy of Digital Contents Archive Based on Reputation Model’, in ICSENG ‘08. Proceedings of 19th International Conference on Systems Engineering, 19-21 Aug, pp. 288-293. doi: 10.1109/ICSEng.2008.75
Kirk, D. S. and Sellen, A. (2010) ‘On human remains: Values and practice in the home archiving of cherished objects’. ACM Transactions on Human-Computer Interaction, vol. 17 (Iss. 3), article 10. doi:0.1145/1806923.1806924
Library of Congress. (2007) Digital Preservation Program Makes Awards to Preserve American Creative Works. [press release] Available at http://www.loc.gov/today/ pr/2007/07-156.html [Accessed: 14th Apr 2014]
Lubar, S. (1999) ‘Information Culture and the Archival Record’, in American Archivist, vol. 62 (Iss. 1), pp. 10-22.
Lynch, C. (2000) “Authenticity and Integrity in the Digital Environment: An Exploratory Analysis of the Central Role of Trust’, in Authenticity in a Digital Environment. Washington, DC: Council on Library and Information Resources. Available at http://www. clir.org/pubs/abstract/pub92abst.html [Accessed: 16th Apr 2014]
Masanès, J. (2006) Web archiving. Berlin: Springer.
Mesa, A. F. (1997) ‘The PowerPC Triumph’. The Apple Museum. [web page] Available at: http://applemuseum.bott.org/sections/ppc.html [Accessed: 19th Apr 2014]
￼￼￼￼￼￼￼￼￼14
Bibliography (cont.)
Paloque-Bergès, C. (2011) Entre trivialité et culture : une histoire de l’Internet vernaculaire. Émergence et médiations d’un folklore de réseau [Between Triviality and Culture: a History of the Vernacular Internet. Emergence and mediations in network folklore]. PhD thesis, self-published. Available at http://camillepaloqueberges.wordpress.com/phd-thesis/ [Accessed: 6th Apr 2014] 2
Paloque-Bergès, C. (2013) ‘Un patrimoine composite : le public Internet face à l’archivage
de sa matière culturelle’ [A composite heritage: the Internet public confronted to the archiving of its cultural matter], in I. Dragan, P. Stefanescu, N. Pelissier, J.-F. Tétu and
L. Idjeroui-Ravez (eds.) Traces, mémoire, communication. Bucharest: Editura Universităţii din Bucureşti. 2
Pearson, D. (2009) Preserve or Preserve Not, There is No Try: some dilemmas relating
to Personal Digital Archiving. [PowerPoint slides]. National Library of Australia Staff Papers. Available at http://www.nla.gov.au/openpublish/index.php/nlasp/article/view/1388 [Accessed: 9th Apr 2014]
del Pozo, N., Long, A. S. and Pearson, D. (2012) ‘Land of the Lost: a discussion of what can be preserved through digital preservation’. Library Hi Tech, vol. 28 (Iss. 2), pp. 290-300. Available from: doi: 10.1108/07378831011047686. [Accessed: 6th Apr 2014]
Ross, S. and Gow, A. (1999) Digital archaeology: rescuing neglected and damaged data resources: a JISC/NPO study within Electronic Libraries (eLib) Programme on the Preservation of Electronic Materials. London: Library Information Technology Centre. Available at http://www.ukoln.ac.uk/services/elib/papers/supporting/pdf/p2.pdf [Accessed: 17th Apr 2014]
Rothenberg, J. (1998) Avoiding Technological Quicksand: Finding a Viable Technical Foundation for Digital Preservation. [report] Washington, DC: Council on Library and Information Resources.
￼￼￼￼￼2 In French.
15
Bibliography (cont.)
Serrano, H. (2009) Back Up Objects, Héctor Serrano. [web page] Available at: http://www. hectorserrano.com/index.php?id=41&amp;m=lab&amp;grupo=backup [Accessed: 17th Apr 2014].
SINTEF. (2013) ‘Big Data, for better or worse: 90% of world’s data generated over last two years.’ ScienceDaily. [web page] Available at: http://www.sciencedaily.com/ releases/2013/05/130522085217.htm [Accessed: 16th Apr 2014]
Swade, D. (1993) ‘The problems of software conservation”, in Computer Resurrection, vol. 7. Available at: http://www.cs.man.ac.uk/CCS/res/res07.htm#f [Accessed: 12th Apr 2014]
Task Force on Archiving of Digital Information. (1996) Preserving digital information, Report of the Task Force on Archiving of Digital Information. Washington, DC: Council on Library and Information Resources.
Thibodeau, K. (2002) ‘Overview of technological approaches to digital preservation
and challenges in coming years’, in The state of digital preservation: an international perspective. Washington, DC: Council on Library and Information Resources, pp. 4-31.
UNESCO. (2003) Guidelines for the preservation of digital heritage, prepared by the National Library of Australia. Paris: UNESCO. Available at http://unesdoc.unesco.org/ images/0013/001300/130071e.pdf [Accessed: 9 Apr 2014]
Wilkens, K. (2011) Sensor Poetics, Kjenwilkens.com. [web page] Available at http://www. kjenwilkens.com/projects/sensor-poetics [Accessed: 18th Apr 2014]
Zimmer, M. (2010) ‘“But the data is already public”: on the ethics of research in Facebook’, in Ethics and information technology, vol. 12 (Iss. 4), pp. 313-325. doi: 10.1007/s10676-010- 9227-5
Zhou, M., Geng, G. and Wu, Z. (2012) Digital preservation technology for cultural heritage. Berlin: Springer.
￼￼￼￼￼￼￼￼￼￼￼￼16
Project Proposal Form
￼￼Name Programme/Course Project/working title
Project Aims (i.e. what you want to learn about through further investigation. E.g. I want toa learn more about the creative process of animators)
Objectives (i.e. the particular things you propose to do
in order to carry out your investigation. E.g. Make contact with professional animators and arrange
to meet them. Possibly Interview them or observe their creative activities to gather data)
Methods (i.e. the different ways in which you will achieve these objectives. E.g. Open ended interview techniques and grounded theory analysis or video observation of working animators)
Victor Loux
Digital Interaction Design
Digital preservation for the masses
I would like to look at further research papers on personal preservation and focus on ways to apply “large-scale” paradigms to our personal heritage while trying to be respectful of people’s privacy and unintrusive.
I first intend to do further reading in this area, as until now I have been exploring digital preservation as a whole with no particular focus, to get a broader understanding of the issues
and solutions. I would like to interview several people of different age ranges to understand their relationship to technology and their personal digital heritage, notably concerning photographs and conversations.
Using open ended interview techniques, further literature review and possibly research through practice as I intend to explore this theme for my final year project.
￼￼￼￼￼￼￼￼￼￼￼￼17
</Text>
        </Document>
        <Document ID="64">
            <Title>Demographics</Title>
            <Synopsis>Demographics: Who participated in it, ages, gender, profession/background.
Maybe use a table? Do not allow to individually identify the participants</Synopsis>
            <Text>Nine participants attended the workshop. All of them were final year design students at Duncan of Jordanstone College of Art and Design, in Dundee.
Amongst the participants were 3 women and 6 men, ages ranging from 21 to 24. Six were native speakers of English; three were from overseas and had English as a second language. All were raised in a Western culture and their native language reads left-to-right,which ensured consistent results (as we’ve seen before, culture and language alters our visual representation of time); but one of the native English speakers has been raised with a bicultural identity and also natively speaks Cantonese, which reads left-to-right horizontally but can also be written vertically. They are all frequent users of Facebook; while most owned Twitter accounts, few of them actually used it, so the questions focused on Facebook.</Text>
            <Comments>Top to bottom, and columns read right to left; like Mandarin, this can influence perception of time, see Boroditsky, 2011, pp. 335-336</Comments>
        </Document>
        <Document ID="90">
            <Title>Preservation conditions</Title>
            <Text>This varies highly with the type of medium used and with the storage conditions; for example, samples by the Digital Preservation Coalition (2008, p. 154) show that D3 cartridge tapes deteriorates after 50 years in optimal conditions (25% RH at 10º) but only one year in high humidity and temperatures (50%RH at 28º). Similar results happen for the more commercially available optical media (down to three months and up to a theoretical 200 years), which are more sensitive to moisture (Harvey, 2012, p.47).
</Text>
        </Document>
        <Document ID="65">
            <Title>Questionnaire on the usage of social media</Title>
            <Text>The third task was a questionnaire, asking the participants about their use of social media and their opinion of the project. Questions and reasons for using a questionnaire are outlined in [appendix F], and a table with the raw results is situated in [appendix G]. These questions will only be useful for the honours project, so the results will not be analysed in too much depth.

The usages that were most often rated as important were:
1. Use groups for school/work/activities, and Chat with friends (same proportion)
3. Keep in touch with friends far away and Follow news of friends (same proportion)
5. Keep friends up to date

The goals that were the least popular in terms of importance were:

12. Stimulate friends to think about certain topics, and Leisure activities (same proportion)
14. Follow celebrities or brands
15. Preserve things that affect me emotionally 

The results do not match with Julius’ (n. d.), who did a similar survey for other purposes and with fewer options. In her results, the most popular goals were, in order: “Keep friends up to date”; “Preserve things that affect me emotionally”; “Stimulate friends to think about certain topics”; and “Satisfy a spontaneous need for communication”. The second and third most popular options in Julius’ (n. d.) results are at the bottom of my ranking. The methodology was however a bit different — she asked her participants to choose the most important goal for them on social networks, whereas I asked, for each goal, how important this goal was to them. Her sample was much larger and more varied (112 participants, in an online questionnaire) and might therefore be more representative.
On the second question, 4 people thought that Facebook would stay popular for 10 years; 3 thought it would stay popular for 5 years; one thought it would stay popular for two years; and one thought it would stay there forever.
On the third question, a majority (7 respondents) answered that they would like to curate their social, network archive every year or so. Two would prefer the curation to be done automatically even if that meant a lower accuracy. One of the respondent who checked the option for manually curating every year or so, indicated that they would also be happy to do so more often (every few weeks).</Text>
            <Comments>Although one of them explained (on the sheet and orally during the workshop) that they would still be able to manually sort artefacts if they thought that it was not curated correctly.</Comments>
            <Notes>see Universal Methods of Design, pp. 17, 32, 74, 156.
</Notes>
        </Document>
        <Document ID="91">
            <Title>Natural disasters</Title>
            <Synopsis>“Materials may be lost in the event of disasters such as fire, flood, equipment failure, or virus or direct attack that disables stored data and operating systems”

src? + same if you store it locally, need for backups in different locations
</Synopsis>
            <Text>[Natural disasters can occur to any kind of artefact and digital have advantage there because of easy backup + datacenters better protected?]</Text>
        </Document>
        <Document ID="66">
            <Title>Analysis of results</Title>
        </Document>
        <Document ID="92">
            <Title>Software barriers</Title>
        </Document>
        <Document ID="3">
            <Title>Title</Title>
            <Text>Victor Loux / 110017909
Digital Interaction Design
Research &amp; Creative Pratice
Dissertation
 Long-term backups and retrieval of digital memories posted on social networks
</Text>
        </Document>
        <Document ID="67">
            <Title>Results</Title>
        </Document>
        <Document ID="4">
            <Title>Context</Title>
            <Text>This dissertation is tied to my honours project, that I will introduce in more detail here. As we have seen, there is a need to backup our data from social networks to protect it, if social networks go down, are discontinued or forgotten. 
Several challenges appear there. Applying the “large-scale” paradigms of conservation  established in the previous literature review (Loux, 2014) for small-scale, personal archiving is complex, due to the resources and knowledge needed to conserve information over time, so this needs to be as automated and seamless as possible. The experience of retrieval of digital memories, once stored, is the main theme of the next chapter and my main focus as an interaction designer. Many variables encompass this experience: the representation of time, the hierarchisation of memories, the visual presentation, and the feeling of durability of the backup and object containing them.</Text>
        </Document>
        <Document ID="68">
            <Title>Discussion of results &amp; evidence</Title>
        </Document>
        <Document ID="93">
            <Title>Interactive material</Title>
        </Document>
        <Document ID="5">
            <Title>Introduction</Title>
            <Synopsis>Explain what I have shifted to, existing ideas that influence this shift, critique them; explain how I think it might influence my own prototypes
</Synopsis>
        </Document>
        <Document ID="69">
            <Title>Introduction-1</Title>
            <Notes>http://www2.warwick.ac.uk/fac/soc/al/learning_english/leap/writing/moreinfo/

a statement of the importance of the subject
mention of previous work on the subject
a justification for dealing with the subject
a statement of your objectives
a statement of the limitations of the work
a mention of some of the differing viewpoints on the subject
a definition of the topic being discussed

Move 1: Establishing a research territory
- by showing that the general research area is important, central, interesting, problematic, etc. (optional)

- by introducing and reviewing items of previous research in the area (obligatory)

Move 2: Establishing a niche
- by indicating a gap in the previous research or by extending previous knowledge in some way (obligatory)

Move 3: Occupying the niche
- by outlining purposes or stating the nature of the present research (obligatory)

- by listing research questions of hypotheses

- by announcing principal findings

- by stating the value of the previous research

</Notes>
        </Document>
        <Document ID="94">
            <Title>Context/emulation</Title>
            <Text>[Possibility of keeping context/interfaces along with content for remembering better]</Text>
        </Document>
        <Document ID="6">
            <Title>Notes</Title>
        </Document>
        <Document ID="7">
            <Title>Ideas</Title>
        </Document>
        <Document ID="95">
            <Title>Understanding history</Title>
            <Text>Harvey (2012) and Lukesh (1999) question whether digital personal correspondance might be lost if we do not take steps to preserve them:
“The widespread shift from writing letters to the use of email has diminished the likelihood that personal correspondence will remain accessible to future historians. Lukesh asked in 1999, ‘Where will our understandings of today and, more critically, the next century be, if this rich source of information is no longer available?’, as scientists, scholars, historians and almost everyone increasingly use email” (Lukesh, 1999) (in Harvey, 2012 p. 32)
While this is a correct idea, I think that few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There have to be other motivations for preserving our conversations and our digital objects.</Text>
            <Comments>Grammar a bit confusing (review)</Comments>
        </Document>
        <Document ID="8">
            <Title>About</Title>
            <Text>UNDERGRADUATE ESSAY FORMAT

About
This template is designed for writing and formatting an undergraduate essay suitable for humanities subjects. It is based on a format used at several UK universities (such as Cambridge). Bear in mind, however, that many universities have different formatting requirements, so you should check the exact guidelines of the institution to which you are submitting your paper.

How To Use This Template
	•	Edit the “Title” document so that it contains the title of your essay, your instructor’s name and so on. Alternatively, you can just edit the title of your essay and enter the rest of the information during the compile process (see below).
	•	Compose your essay in text documents inside the “Main Content” folder. Whether you use a single document or multiple text files to write your essay is entirely up to you - just make sure they are all inside the “Main Content” folder.
	•	Indent block quotes or other special passages using the ruler settings you require in the finished document and enclose them in a “Preserve Formatting” block. To do this, select the text of the block quote and go to Format &gt; Formatting &gt; Preserve Formatting. (The quickest way of formatting a block quote is to click in the paragraph and select “Essay Block Quote (Preserved)” from the formatting presets, either using the “Presets…” control in the format bar, or by going to the Format  menu and choosing Formatting &gt; Apply Preset - this will indent the text and apply the “Preserve Formatting” block for you.) All other text will have the default indentation and formatting assigned during the compile process.
	•	Use File &gt; Compile… to compile your essay for printing or exporting.
	•	In the Compile sheet, make sure you edit the entries in the “Replacements” pane, replacing “YourStudentID”, “SupervisorSurname” and so on with the appropriate information - these will be used in the page header and on the title page.

Sample Document
The “Example Essay” PDF file in the Research folder shows how the essay will look when compiled.

Final Note
Scrivener project templates are flexible and are not intended to restrict you to a particular workflow. You can change, delete or move the files and folders contained in the template and you can create your own templates by setting up a skeletal project with the files, folders and settings you would like to use for new projects and using File &gt; Save As Template.</Text>
        </Document>
        <Document ID="9">
            <Title>Example Essay</Title>
            <Text>B Twemlow (BXT32) / Bing-Tredmille / 30 Oct 2010 ... 1
BARRY TWEMLOW (BXT32 - DOGNOBBLER COLLEGE) ENGLISH TRIPOS PART II – TRAGEDY PAPER ESSAY FOR DR. HEIRONYMUS BING-TREDMILLE (30 Oct 2010)
“Cur vel habeo delenit interpretaris, usu et alienum epicuri consetetur.” Discuss
Lorem ipsum qui porro insolens reprimique an, appetere verterem conceptam eam eu. Ut nam nullam commune explicari. Vis ex mazim choro accusamus, sed civibus complectitur ex. Mazim aliquando vel in.
Pri vero aliquam docendi ut, cu mei suas adhuc facilisis, saepe eloquentiam ad nec. Epicuri detracto principes sit in, vis latine luptatum recusabo et. An sed officiis vulputate, minim oratio duo no. Prima minimum oportere eum in. Id pro augue virtute. Eam unum laboramus adolescens te, alia tritani vix id, sit in labores iracundia moderatius.
Mel in meis mutat scripserit, summo tantas apeirian ius id. Mei eu voluptua neglegentur philosophia, corrumpit evertitur sea no. Fabellas invidunt invenire sed cu. No mel volumus intellegebat. Ex novum delicata usu, eros probo ad mel. Amet cibo vim ex. Per tibique probatus insolens id.
Sonet consequuntur eam ex, ea placerat expetendis referrentur mea. Unum commodo minimum mea at, at sea possim posidonium concludaturque. Sit quodsi deseruisse ne, dicta consul insolens pro ad. No essent persius mediocritatem est, sed et dico sanctus, qui te latine signiferumque. Ad facilis percipitur duo, usu equidem euripidis an, id erat dicunt temporibus pri.
Alia puto eos ut, errem tempor melius vel eu. Vim te omnis scripta quaeque, in his
B Twemlow (BXT32) / Bing-Tredmille / 30 Oct 2010 ... 2
oratio veniam fierent. Eum dictas molestie definiebas ne, te maiorum persequeris vim. Pri at integre dolorem.
Cum menandri postulant te, causae accusam te has. No solet gubergren pro, tollit molestie signiferumque cu usu, qui nostrum partiendo adversarium ut. Vis oportere constituto id, mel odio eirmod verterem id, fugit dicunt argumentum pri ex. Sensibus petentium iracundia ut vim. Ius ei dicta molestie sententiae, modus voluptaria ut nam.
Nonummy delicatissimi eu pro, ubique inimicus voluptaria at sea. Cu nec delectus invenire. Eos possim vocibus ut. Ut kasd solet qualisque sit, cu lucilius signiferumque sea, no populo consequat usu.
Cu vel habeo delenit interpretaris, usu et alienum epicuri consetetur. Vel an soleat alienum, no vim impedit sapientem. Id nec ceteros consectetuer interpretaris, eum ad audiam eloquentiam, ad quo falli mandamus. Pro ad quodsi denique, ad intellegat assueverit honestatis per, cum eu labitur inimicus. Pro altera definitionem ea, vim no unum mutat dicunt. Et quo malis nullam essent.
Antiopam maluisset ne mea. Ei solet saepe qui. Cu vocent fuisset vix. Eos ad electram assentior, erat assum saepe sed ne. Ut facete eruditi elaboraret duo, ex est tempor vocibus consetetur. Mea debet singulis ut, erat facer simul mei te.
Mei id quis petentium, meis nostrum eu ius, vocent takimata principes ei nec. Sea laoreet delectus in, aperiri omittantur eum cu, detracto nominavi at cum. Mel an dolores officiis, patrioque adipiscing definitiones ius ad, at sed cibo velit. Pri solet vocent prompta no, eos ut quaerendum consequuntur, nam no commodo voluptatibus. Mei at forensibus comprehensam.’i Lorem ipsum qui porro insolens reprimique an, appetere verterem conceptam eam eu. Ut nam nullam commune explicari. Vis ex mazim choro accusamus, sed civibus complectitur ex. Mazim aliquando vel in.
B Twemlow (BXT32) / Bing-Tredmille / 30 Oct 2010 ... 3
Cum menandri postulant te, causae accusam te has. No solet gubergren pro, tollit molestie signiferumque cu usu, qui nostrum partiendo adversarium ut. Vis oportere constituto id, mel odio eirmod verterem id, fugit dicunt argumentum pri ex. Sensibus petentium iracundia ut vim. Ius ei dicta molestie sententiae, modus voluptaria ut nam.
Nonummy delicatissimi eu pro, ubique inimicus voluptaria at sea. Cu nec delectus invenire. Eos possim vocibus ut. Ut kasd solet qualisque sit, cu lucilius signiferumque sea, no populo consequat usu.
Mei id quis petentium, meis nostrum eu ius, vocent takimata principes ei nec. Sea laoreet delectus in, aperiri omittantur eum cu, detracto nominavi at cum. Mel an dolores officiis, patrioque adipiscing definitiones ius ad, at sed cibo velit. Pri solet vocent prompta no, eos ut quaerendum consequuntur, nam no commodo voluptatibus. Mei at forensibus comprehensam.ii Lorem ipsum qui porro insolens reprimique an, appetere verterem conceptam eam eu. Ut nam nullam commune explicari. Vis ex mazim choro accusamus, sed civibus complectitur ex. Mazim aliquando vel in.
Pri vero aliquam docendi ut, cu mei suas adhuc facilisis, saepe eloquentiam ad nec. Epicuri detracto principes sit in, vis latine luptatum recusabo et. An sed officiis vulputate, minim oratio duo no. Prima minimum oportere eum in. Id pro augue virtute. Eam unum laboramus adolescens te, alia tritani vix id, sit in labores iracundia moderatius.
Mel in meis mutat scripserit, summo tantas apeirian ius id. Mei eu voluptua neglegentur philosophia, corrumpit evertitur sea no. Fabellas invidunt invenire sed cu. No mel volumus intellegebat. Ex novum delicata usu, eros probo ad mel. Amet cibo vim ex. Per tibique probatus insolens id.
B Twemlow (BXT32) / Bing-Tredmille / 30 Oct 2010 ... 4
Alia puto eos ut, errem tempor melius vel eu. Vim te omnis scripta quaeque, in his oratio veniam fierent. Eum dictas molestie definiebas ne, te maiorum persequeris vim. Pri at integre dolorem.
Cu vel habeo delenit interpretaris, usu et alienum epicuri consetetur. Vel an soleat alienum, no vim impedit sapientem. Id nec ceteros consectetuer interpretaris, eum ad audiam eloquentiam, ad quo falli mandamus. Pro ad quodsi denique, ad intellegat assueverit honestatis per, cum eu labitur inimicus. Pro altera definitionem ea, vim no unum mutat dicunt. Et quo malis nullam essent.iii Cu vel habeo delenit interpretaris, usu et alienum epicuri consetetur. Vel an soleat alienum, no vim impedit sapientem. Id nec ceteros consectetuer interpretaris, eum ad audiam eloquentiam, ad quo falli mandamus. Pro ad quodsi denique, ad intellegat assueverit honestatis per, cum eu labitur inimicus. Pro altera definitionem ea, vim no unum mutat dicunt. Et quo malis nullam essent.iv
i John Donne, Selected Prose, ed. Helen Gardner and Timothy Healy (Oxford: Clarendon Press, 1967), p. 46. ii Donne, Selected Prose, p. 26.
iii ‘He was a martyr manqué,’ Carey writes, ‘and had to live with a set of basic psychic configurations which had been oriented towards death by his educators.’ John Donne: Life, Mind and Art (London: Faber, 1990), p . 213.
iv Donne, ‘To Mr Tilman after he had taken orders’, ll. 15-16, 17-18, in The Divine Poems, ed. Helen Gardner (Oxford: Clarendon Press, 1952), p. 32. Future references to this edition will be given in the text as line numbers.
</Text>
        </Document>
        <Document ID="96">
            <Title>For social networks</Title>
            <Text>In preparation of future data losses, perhaps, the US Library of Congress maintains a permanent archive of Twitter since 2010 (LoC, 2010). However, this is again kept with a cultural intention: “The public Twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important” (Baym, 2010). Scott (2009) has noted the cultural value of archiving GeoCities, despite its tacky design and content; I believe that the jargon, hashtags and emojis of the present day could become the ‘Under Construction’ GIFs of the next decade, becoming relics and symbols of a time on the Internet. However, there seems to be little possibility for individuals to create archives of their own account, for retrieving their memories at a later time and not in a general, sociological or historical goal. A few services, such as SocialSafe.net or Frostbox.com offer to back up social media accounts; they are principally marketed towards businesses and authorities, but can also be used by individuals. However these services are subscription-based (or offer subscription-based premiums, but back up using proprietary archive formats) and as such we are simply repeating the situation of social networking sites, where backed up data could disappear if the companies go out of business — possibly in a worse way, since these companies do not have the financial means of social networks to survive for very long.</Text>
            <Comments>Whose communications on social media legally need to be archived in case of dispute</Comments>
            <Notes>In The Future of Looking Back, Richard Banks (2011) analyses the reasons that lead us to keep or discard physical objects at home. He argues that while making a selection is a positive thing because it forces us to filter our belongings and focus on what is really meaningful, we also run the risk of ridding ourselves of things that we wish we would have kept in retrospect. He points out that the organisation of digital files make this trickier: because we we can keep pretty much everything on virtual space, it is easier to accidentally delete meaningful things alongside the less important. (Banks, 2011 p. 22).
In the context of personal archiving, Banks notes that in the past, the legacy we leave behind us was a highly selective one. Because our possessions are limited by physical space, our ancestors until now “have implicitly indicated that an item is significant through the simple act of keeping it. Although thousands of objects likely crossed their path over their lifetime, the constraints of money and space meant that only a few were retained, often the most significant.” (Banks, 2011, p. 78). He does however argue that this is no longer true in a digital world, because new possibilities mean we simply accumulate digital objects without necessarily ordering them by importance.
</Notes>
        </Document>
        <Document ID="97">
            <Title>What to preserve</Title>
            <Notes>+ 
In order to keep the most valuable content, algorithms could be used. Kawano (2008) proposes to use reputation models, that attempts to determine the relative value of a Web page by considering its “importance, fairness, trustiness, uniqueness and valuation”. This is done using a variety of ways; the algorithm suggested by Kawano relies on the consistency of a web page, that is the amount of time it existed, the number of links it contains and the number of external links to this page (Kawano, 2008, p. 291).

+ Manual curation
+ all SNSs?</Notes>
        </Document>
        <Document ID="98">
            <Title>Hard copies</Title>
            <Synopsis>Print out photographs etc. Show arguments against mostly but also why it could be a viable option in some contexts</Synopsis>
            <Text>What appears to be the simplest solution is to make physical copies (i.e. print) of the digital documents. Although this certainly solves some problems in regards to technological obsolescence, Rothenberg (1999) and Granger (2000) pointed out that this cannot be done for more interactive material besides text and images. There is also, obviously, an issue with the amount of content that can be stored in this way — this would not work for archiving websites. Granger (2000) recognises that “if one’s sole concern is with the intellectual content of a document and the document is of a fairly simple nature [...] this at least provides some form of security”.
</Text>
        </Document>
        <Document ID="99">
            <Title>Standardisation</Title>
            <Synopsis>Standardisation is the transformation of a document’s content to a format that is standardised, open and well documented, ensuring that we will be able to open it with a variety of applications on a variety of platforms and that we can rebuild a program for visualising that document — as opposed to vendor-specific, closed source program that could be discontinued at any point in the future. Rothenberg (1999, p. 10)</Synopsis>
            <Text>Standardisation is the transformation of a document’s content to a format that is standardised, open and well documented, ensuring that we will be able to open it with a variety of applications on a variety of platforms and that we can rebuild a program for visualising that document — as opposed to vendor-specific, closed source program that could be discontinued at any point in the future. Rothenberg (1999, p. 10) claims that this is a bad solution because “standardisation sows the seeds of its own destruction by encouraging vendors to implement non-standard features in order to secure market share” (therefore these non-standard features will be lost if opened in a different application). Granger (2000) argues that the blame is not to be put on the method, but on vendors. Standardisation is a type of migration and therefore share some of it cons (notably, this absence of vendor-specific features could imply a loss in the presentation and other characteristics). Standards eventually become obsolete so it is also paramount to preserve the specifications of the format, or to define formats that are unambiguous, such as CSV or XML.
A slightly different approach to this method is rebuilding viewers. In this scenario, the bitstream is not migrated to a standardised format, but kept as is; we simply re-build a viewer that is able to read that format. This is not as straightforward as it sounds, because most of the time, formats for proprietary software are not documented and decrypting them would require reverse engineering. If they are documented, then it is likely that this format is already a standard. There exists cases where reverse engineering is possible, or where a non-standard format is documented; for example, Microsoft Word files are not a standard, but there is plenty of documentation available online to produce code able to read them. An experiment by the VERS project (Thibodeau 2002, p. 22) has shown that it is possible to reengineer a viewer for the PDF file format from the specification available; as long as we also preserve these specifications, we will be able to read PDF files in the future.</Text>
        </Document>
        <Document ID="100">
            <Title>Migration</Title>
            <Synopsis>Migration is the transformation of a document’s content to a format that is not necessarily standardised, but at least current; or, the newer version of same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011</Synopsis>
            <Text>Migration is the transformation of a document’s content to a format that is not necessarily standardised, but at least current; or, the newer version of same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed (although this can be overcome by migrating to more flexible formats like PDF or LaTeX). Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.
</Text>
        </Document>
        <Document ID="10">
            <Title>Appendices</Title>
            <Synopsis>“Be honest and rigorous”
Only contain ALL raw data/transcripts, not analysis

Questions asked
Provide on disc if long audio/video</Synopsis>
        </Document>
        <Document ID="11">
            <Title>Introduction</Title>
            <Text>The research presented in this dissertation stems from observations of the recent shift of many of our communications towards social networking websites. Whilst creating memories (be it photographs, videos, textual stories…) digitally rather than physically is not exactly a new thing, the places where we share them online are progressively going further away from our own control. This creates worrying uncertainty in terms of preservation of our digital legacy.
Traditionally, we have kept what was sentimentally important to us in our homes, on materials that were not aging very fast (paper, for instance, will last for decades without any particular intervention needed to retain its integrity). Most importantly, the constraints of cost and physical space meant that we produced and kept relatively few artifacts, retaining only what was the most important to us in our lives. The immateriality of current technologies, however, allow us to create these artifacts very cheaply and store hundreds of these elements in a reduced space, which progressively eliminates this need for curation and selection, and instead let us record our lives more frequently and accumulate these records.
But this immateriality does not come without its downsides. Digital information is, as we will see, very fragile; not only because of the storage media used to store it, but also due to the technological obsolescence of interfaces and software to access these media. The emergence of social networks and services of “cloud” storage, however, produces a whole new issue: the long-term existence and safety of the data that we put on these is entirely dependent on the commercial success and policies of the provider. The short history of the Internet has already proven us that social networks and online spaces do not last eternally, and when they shut down or stop being maintained, our data disappears forever (examples include Bebo, MSN, MySpace, Orkut, GeoCities…). There are numerous reasons, that will be described later in this dissertation, to think that some (if not all) of the current dominant social networks will be replaced in a few years and that our data will share the same fate, with possibly bigger consequences considering the extreme growth in the amount of users and content shared. There is an alarming lack of awareness about this impending destruction  of our memories, and most importantly a lack of simple solutions for the general public to be able to preserve digital memories over the long term. The questions that I will try to answer here are: is it worth capturing digital memories shared on social networks? How to store these in the long-term? And finally, how can we design an interface that would allow users to go through a complex lifetime of digital memories in a meaningful and organised way? 
The present research was done in parallel with my final year's honours project that is aiming to tackle this issue. As such I have used elements of the development of this project to inform the questions asked, and used prototypes to gather insights and find answers. Through a literature review in the field of digital preservation, an exploration of representations of time and a series of activities with potential users, I am trying here to answer these questions, and shed some light on personal archiving and representation of events over time.</Text>
            <Comments>At the time of writing: Facebook, Twitter, Instagram, LinkedIn, Pinterest… (Ebizmba, 2014)</Comments>
            <Notes>http://www2.warwick.ac.uk/fac/soc/al/learning_english/leap/writing/moreinfo/

a statement of the importance of the subject
mention of previous work on the subject
a justification for dealing with the subject
a statement of your objectives
a statement of the limitations of the work
a mention of some of the differing viewpoints on the subject
a definition of the topic being discussed

Move 1: Establishing a research territory
- by showing that the general research area is important, central, interesting, problematic, etc. (optional)

- by introducing and reviewing items of previous research in the area (obligatory)

Move 2: Establishing a niche
- by indicating a gap in the previous research or by extending previous knowledge in some way (obligatory)

Move 3: Occupying the niche
- by outlining purposes or stating the nature of the present research (obligatory)

- by listing research questions of hypotheses

- by announcing principal findings

- by stating the value of the previous research

</Notes>
        </Document>
        <Document ID="101">
            <Title>Emulation</Title>
            <Synopsis>Does it make sense for social networks? (emulate interface?)
Talk about R. Banks retrieval of old computers</Synopsis>
            <Text>
Emulation is the dynamic transformation of instruction sets to allow software and/or operating system designed for an obsolete architecture or platform to run on current systems. It is a highly complex method that offers certain benefits; notably, this is the most conservative method, as it is not destructive of the content or presentation. It allows us to run the original program used to create a digital object without altering that bitstream ; it “keeps the look and feel as well as the interactivity” (Granger, 2000) and as such, it is particularly interesting for objects rich in interaction, such as video games, data visualisations, or formats that are particularly complex (for example, medical imagery, 3D modelisations), for which methods like migration would be hard. It also ensures complete integrity and authenticity, which could be crucial for some data types.
There are numerous criticisms against emulation. A number of legal and intellectual property problems are raised, if the emulation strategy is not supported by the original author [see Nintendo &amp; Apple]. The complexity involved in creating emulators might be not worth it and requires a coherent organisation to reduce overhead (Granger 2000). Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to the delivery of the preserved content; “most users in the future will never have encountered—not to mention learned how to use—most of the products they will need to access the preserved information objects”, and “it would cut users off from the possibility of using more advanced technologies for discovery, delivery, and analysis”.
“Emulators themselves become obsolete; therefore, it becomes necessary either to replace the old emulator with a new one or to create a new emulator that allows the old emulator to work on new platforms. In fact, if you get into an emulation strategy, you have bought into a migration strategy. Either strategy adds complexity over time.” (Thibodeau 2002 p.20)</Text>
        </Document>
        <Document ID="12">
            <Title>Untitled</Title>
        </Document>
        <Document ID="110">
            <Title>Annotated draft</Title>
            <Text>Introduction
As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts. This literature review aims to get an overview of the current problems, techniques and practices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the various methods used to do so. It also encompasses legal and ethical issues arising from it, and how the paradigms and methods change when applied to different types of archiving (e.g. for researchers, for businesses, and for personal businesses).
Why digital preservation
[Stats of numbers on digital vs physical]
Why digital degrades faster UNESCO’s Threats to digital continuity
UNESCO (2003, pp. 30–31) has identified a list of threats to what they call digital continuity. These are: + “The carriers used to store these digital materials are usually unstable and deteriorate within a few years or decades at most”. Where, in the traditional preservation paradigms for paper-based artifacts, the main rule is that “benign neglect may be the best treatment” (derived from Cloonan (1993, p.596), Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612–613)), this cannot be applied to digital storage media because their lifetime is much shorter. This varies highly with the type of medium used and with the storage conditions; for example, samples by the Digital Preservation Coalition (2008, p. 154) show that D3 cartridge tapes deteriorates after 50 years in optimal conditions (25% RH at 10o) but only one year in high humidity and temperatures (50%RH at 28o). Similar results happen for the more commercially available optical media (down to three months and up to 200 years), which are more sensitive to moisture (Harvey, 2012, p.47).
“Use of digital materials depends on means of access that work in
￼￼
￼particular ways: often complex combinations of tools including hardware and software, which typically become obsolete within a few years and are replaced with new tools that work differently” (UNESCO, 2003). Even if storage media could survive decades or even centuries, technological change means we will not necessarily have the means to access the data later. In other words, “to retain appropriate access to a digital object, we must maintain a mechanism to derive meaning from that object” (del Pozo et al., 2012, p6): for optical media, this includes not only the drives to read the disc, but also a cable to connect the drive to the computer’s motherboard, a motherboard that has a connector for this type of cable, and an operating system that has drivers for this connectivity (Pearson 2009, slide 11). Once we have access to the bitstream from the computer we need to be able to represent it, which means we also need to keep the software in a version that can open the preserved file. There is a myth, kept by both customers and vendors, that media is long-lived: “[An IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” (Weathley, 2003, cited by Harvey, 2012, p. 37)
Poor preservation documentation and metadata means it could be hard for potential users to find the data (UNESCO 2003)
poor preservation (“Critical aspects of functionality, such as formatting of documents or the rules by which databases operate, may not be recognised and may be discarded or damaged in preservation processing.”, UNESCO 2003) + “So much contextual information may be lost that the materials themselves are un- intelligible or not trusted even when they can be accessed” -&gt; poor integrity
“Materials may be lost in the event of disasters such as fire, flood, equipment failure, or virus or direct attack that disables stored data and operating systems”
“Access barriers such as password protection, encryption, security devices, or hard-coded access paths may prevent ongoing access beyond the very limited circumstances for which they were designed”. [This argument is particularly true for web archiving, where crawlers of national libraries retrieve all sort of files to preserve them but do not
￼￼￼￼￼
￼necessarily have the permission or know the rights owner][back that up maybe yo]
Importance of data Library material: for society
“if we librarians do not rise to the occasion, successive generations will know less and have access to less for the first time in human history. This is not a challenge from which we can shrink or a mission in which we can fail” (Gorman, 1997, cited in Harvey, 2012, p. 27)
For businesses (records)
Personal archiving / domestic archiving
Preserving interactive material inc. video games
In addition to the preservation of “static” documents and images, there is a significant desire to preserve video games, which are getting recognised as a form of art similarly to movies and music. The Library of Congress (2007) gave awards for the preservation of video games; there is a growing interest in being able to play “retro” games, but the consoles are obsolete. A large community of hobbyists reverse engineered consoles and produced emulators of these platforms for PC and other platforms different from their intended one. Because no documentation is available, this is a Herculean task; byuu (2011), the developer of an emulator for Super Nintendo games, recalls this for reengineering certain cartridges:
[Low-level emulation] is also a very expensive operation, monetarily speaking: to obtain the DSP program code requires melting the integrated circuit with nitric acid, scanning in the surface of a chip with an electron microscope, and then either staining and manually reading out or physically altering and monitoring the traces to extract the program and data ROMs. This kind of work can cost up to millions of dollars to have done professionally, depending upon the chip’s complexity, due to the extremely specialized knowledge and equipment involved. (byuu, 2011)
Obviously this is not necessarily a route many institutions would like to take for preserving digital objects. Because this also causes intellectual
￼￼
￼property issues, Nintendo and Sony have launched their own preservation programs, allowing players to play “classic” games on the newer generations of consoles; this is a far more accurate emulation (as they do have the internal documentation to create these emulators) and respects their monetary interests (players have to buy the games, whereas in hobbyist emulation, you would have to download the game file).
Useful for researchers in the future
Beyond the governmental and cultural needs for preservation, there is also great need for preserving scientific data. “Data are the foundation on which scientific, engineering, and medical knowledge is built” (Committee on Ensuring the Utility and Integrity of Research Data in a Digital Age, 2009, p. ix, cited in Harvey, 2012, p. 26); therefore it is crucial in a digital era, with enormous data sets and research papers becoming widely public, to ensure this doesn’t disappear.
Understanding our history
There is a need to define what is the purpose of archives. As a tool to learn from the past, or to keep records, but as Cook (2000) eloquently puts it:
“Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)
Preservation should, therefore, be considered very important. There is some skepticism to this:
￼
￼￼“It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p.32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
While it’s difficult to argue that preserving digital objects is necessary, there is certainly a need to define what deserves to be protected, and to what level.
Understanding the beginnings of the Internet, as we have shifted in an information society
Preserving an accurate + [integrity] image of our society at a given point Twitter &amp; Usenet
Camille Paloque-Bergès (2011; 2013) proposes that we can already find historical and sociological evidence of a given period in Internet time when browsing archives of Usenet [footnote: An Internet discussion system established in the 1980s and that is widely regarded as the predecessor of the Web and online fora]. She analysed how the way of speaking has evolved [footnote: See also http://wwwtxt.org (or @wwwtxt on Twitter), a project collecting short phrases of the Usenet to demonstrate this] and how an self-organised community had built itself, noting that we can “feel [the community’s] informational generativity” and understand that one of the biggest qualities of the early users of the Internet was their “recursivity as a public” (Paloque-Bergès, 2013); that is, how they welcomed newcomers — notably through the use of FAQs [footnote: Frequently Asked Questions], which weren’t a common concept back then. There are also large elements of nostalgia coming back (Paloque-Bergès, 2011).
It is also interesting to come back on the archival of Usenet. The messages were not systematically archived, and obviously not available on the Web as
￼it did not exist and is separate. Today’s collections have mainly been recreated from donations of people who did archived Usenet newsgroup, originally to DejaVu News in 1995, and Google Groups in 2001. A number of privacy concerns were raised with the publication of these searchable archives; messages who were, 15 to 20 years earlier, thought to be confidential are now considered as digital heritage. There was also a large backlash against the archiving made by for-profit companies, and the credit taken later by Google for its donors, with other critiques like Brad Templeton’s (an Internet veteran and important figure; cited in Paloque- Berges, 2013) remark that the archive was lacking in integrity. However, the searchability of these archives did bring welcomed technical possibilities for an Internet historiography, including a timeline where “the announcement of the Chernobyl disaster on Usenet stands alongside the first message of Linus Torvalds calling for help on what would become the Linux operating system” (Paloque-Bergès, 2013).
Similar concerns appeared at the announcement of the archival of Twitter by the Library of Congress in 2010. The two are not really comparable, mostly because the archive is not public and is made by a not-for-profit body. On the mailing list of the Association of Internet Researchers, the idea was met with interest: “The public twitter stream is of historical cultural significance and is an amazing repository of mundane moments in the daily lives of many people and records of what they thought important” (Baym, 2010) [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010- April/021125.html]”. However, the privacy concerns (notably with public and private feeds) were discussed, and as Michael Zimmer remarked:
“This is the classic “but the information is already public” argument that, while technically true, presumes a false dichotomy that information is either strictly public or private, ignoring any contextual norms that might have guided the initial release of information or how a person expects that information to flow.” (Zimmer, M. [on http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021136.html]; see also his paper (2010) on Facebook privacy, going further in that argument)
Paloque-Bergès (2010) theorises this argument, suggesting that “information is not an object, but a statement; it goes through socio-technical processes; it doesn’t have an objective nature”. A message in a tweet can have a very
￼
￼different context when taken apart of the moment it was posted. It also emphasises that privacy could change (the user could, later, switch their account to Private, delete the tweet or their account altogether, but this wouldn’t be reflected in the archive. We cannot know what is the user’s original intent when they posted their message, and, as Paloque-Bergès (2010) noted, we aren’t sure the user themselves know.
“More often than not, in a technical ecosystem in which making content private is more difficult than sharing broadly, teens choose to share, even if doing so creates the impression that they have given up on privacy. It’s not that every teen is desperate for widespread attention; plenty simply see no reason to take the effort to minimize the visibility of their photos and conversations.” (Boyd, 2014).
Advantages over physical preservation Mass preservation, easier access and organisation Recording digitally material that’s not born-digital
Cost of restoration; case studies of lost data
A number of institutions have already experienced loss of data, or data being corrupted. This can have disastrous consequences for businesses, for example, as noted by McAteer (1996, cited by Ross and Gow, 1999, p. iii): “of the 350 companies unexpectedly relocated by the [1993] World Trade Centre (NYC) bombing 150 [43%] ceased trading, many because they lost access to key business records held in electronic form”.
Data can, obviously, be sometimes restored. Ross and Gow (1999, pp. 39–42, referenced in Harvey, 2012, p. 34) provide a number of case studies. Harvey (2012, p. 34) also gives the ironic example of the website for the “Functional Requirements for Evidence in Recordkeeping” project, directed by the University of Pittsburgh which was accidentally deleted; but thankfully was automatically saved by the Internet Archive.
There is still the possibility of restoring data by specialised carriers; however Pearson (2009, slide 15) notes that while this was generally effective, this did not work on some items. He also regrets that the
￼
￼restoration loses all metadata in the process; this can be an issue for sensitive or classified information (for business or governmental archives) as the carrier would be able to see it; finally, it is a prohibitely expensive operation, and so a carefully planned preservation could be much cheaper (and obviously more reliable) than neglect. However, these services are always useful in certain cases. Harvey (2012, p. 41) cites the statistics by the data recovery giant Kroll Ontrack (2011): “hardware and system problems cause most customers to approach them (29 per cent), followed by human error (27 per cent). Software corruption or program problems, computer viruses and natural disasters are the other reasons listed.”
Defining paradigms for digital
preservation
Pre-digital paradigms
Inability to preserve the medium, only the bitstream Importance of metadata, relationship &amp; context Definition of terms
What to preserve / Selectivity
Harvey 5 pillars for selectivity (Harvey 2012, p. 26)
If unique information objects that are vulnerable and sensitive and therefore subject to risks can be preserved and protected
If preservation ensures long-term accessibility for researchers and the public;
If preservation fosters the accountability of governments and organisations
If there is an economic or societal advantage in re-using information
￼￼￼￼
￼If there is a legal requirement to keep it (NSF-DELOS Working Group on Digital Archiving and Preservation, 2003, p.3).
Banks reasons for domestic archiving
In The Future of Looking Back, Richard Banks (2011) analyses the reasons that lead us to keep or discard physical objects at home. He argues that while making a selection is a positive thing because it forces us to filter our belongings and focus on what is really meaningful, we also run the risk of ridding ourselves of things that we wish we would have kept in retrospect. He points out that the organisation of digital files make this trickier: because we we can keep pretty much everything on virtual space, it is easier to accidentally delete meaningful things alongside the less important. (Banks, 2011 p. 22).
In the context of personal archiving, Banks notes that in the past, the legacy we leave behind us was a highly selective one. Because our possessions are limited by physical space, our ancestors until now “have implicitly indicated that an item is significant through the simple act of keeping it. Although thousands of objects likely crossed their path over their lifetime, the constraints of money and space meant that only a few were retained, often the most significant.” (Banks, 2011, p. 78). He does however argue that this is no longer true in a digital world, because new possibilities mean we simply accumulate digital objects without necessarily ordering them by importance.
Technical possibility of archiving Pros/cons of archiving the entire internet
There are various controversies around whether we should automate the archiving of the Internet, or if we should operate a manual selection. UNESCO (2003, p. 73) notes that those who value a more comprehensive collection (i.e. archiving “all” the Internet) argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything”. This argument is particularly true because of the digital media: “unlike non-digital material such as paper-based artifacts, where there is a period of time in which to make selection decisions before deterioration of materials becomes an issue, the time frame for deciding whether or not to preserve digital materials is very short” (Harvey, 2012, p. 57). UNESCO (2003, p.71)
￼
￼backs that claim: “it may not be possible to wait for evidence of enduring value to emerge before making selection decisions”.
Other people [Cook?] think that it would be preferable to keep a curated collection because of a higher technical quality, and this also allow us to settle [negotiate?] preservation rights with the content producers. Harvey adds that we also do not have the technical capabilities to find all the pages on the Internet, and even if we had we would not have the technical possibility to store the whole of the Internet (Harvey 2012, p. 58); again, this is also something recognised by UNESCO: “‘there are usually more things – more information, more records, more publications, more data – than we have the means to keep” (2003, p.70).
The UNESCO (2003) and Cook (2000) both however recognise that a middle ground should be found and that both approaches are valid depending on the goal of the preservation. For instance, the Internet Archive[IA] is going through an automated process (archive as many pages as possible) but, because of technical limitation, only preserves the text and dismisses all other images, stylesheets and external media, which could be critical in some instances. It seems evident that for valued documents these should be retained. The British Library’s Web Archive[ukwa] [http://www.webarchive.org.uk/ukwa/]
Dangers of selection (Cook)
However, Cook (2000) points out the dangers of manual selection for what is worth archiving: “With memory comes the inevitable privileging of certain records and records creators, and the marginalizing or silencing of others” (Cook, 2000, cited in Harvey p. 58). He asserts that the archivists must be impartial and objective, and ensure all points of view are kept to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination”. This is something that is clear with manual archiving, but could also be a problem, maybe unintentionally, with the automated discovery of content when archiving Web pages.
Automatic selection (Reputation model)
In order to keep the most valuable content, algorithms could be used. Kawano (2008) proposes to use reputation models, that attempts to
￼determine the relative value of a Web page by considering its “importance, fairness, trustiness, uniqueness and valuation”. This is done using a variety of ways; the algorithm suggested by Kawano relies on the consistency of a web page, that is the amount of time it existed, the number of links it contains and the number of external links to this page (Kawano, 2008, p. 291).
Crawling
Manual curating
Special Collections for events (eg before elections, see webarchive.org.uk for other ideas)
Another interesting selection process that has emerged is the one of specific archiving when certain events are happening. For instance, the UK Web Archive[ukwa] has, on top of their topical-based collections (Energy, Health and Social Care...), a few event-based collections (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks...) which reflect the state of the Web at that given moment in history. Masanès (2006, p.83) notes that this type of archiving must be manually curated and thoroughly preparated. He gives a methodology for this, using presidential elections as an example: a time frame for the collection must be defined (“3 months before the election + 1 month after”), what type of sites will be archived and when (“the political parties’ blogs and websites, every week; analysis, commentary and humourous/satire websites, every month; online newspaper articles, once”).
Selection: by genre
There are different genres of websites: institutional website, blogs, personal pages, forums. [[Genre have been studied in the context of the Web to see how they replicate or diverge from the genre in the print- ing world (see Crowston and Williams 1997) - in Masanès p88]]. An interesting point about this is that often, robots (crawlers, or later data analysis) can automatically identify their type [Rehm 2002 -&gt; check reference, Masanès:88] which permits the automatic generation of metadata, or simply to restrict a collection of web pages to certain Web genres.
Web archiving: what stands as
heritage on the web Who should preserve
Digital media changes the original preservation paradigm for deciding who takes the responsibility for archiving content, and how. The processes of creation, fabrication and publication used to be distinct in the “analog” era; but as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and distribution that characterize the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and this is also true for businesses and personal data. The Task Force on Archiving of Digital Information (1996, pp. 19–20) suggests that when, in general, “stakeholders disseminate, use, reuse, recreate and re-disseminate various kinds of digital information, they can easily, even inadvertently, destroy valuable information, corrupt the cultural record, [and ultimately thwart the pursuit of knowledge that is their common end]. Against such a danger, a safety net is needed to ensure that digital information objects with long-term cultural and intellectual value survive the expressions of stakeholder interest with their integrity intact.
[&gt; Society has always created objects and records describing its activities, and it has consciously preserved them in a permanent way... Cultural institutions are recognised custodians of this collective memory: archives, librar[ies] and museums play a vital role in organizing, preserving and providing access to the cultural, intellectual and historical resources of society. They have established formal preservation programs for traditional materials and they understand how to safeguard both the contextual circumstances and the authenticity and integrity of the objects and information placed in their care... It is now evident that the computer has changed forever the way information is created, managed, archives and accessed, and that digital information is now an integral part of our cultural and intellectual heritage. However the institutions that have traditionally been responsible for preserving information now face major technical, organisational, resource, and legal challenges in taking on the preservation of digital holdings (B. Smith, 2002, pp.133–134) [cited in Harvey p. 29].]
￼
￼A variety of new stakeholders are now required to collaborate more for a good preservation practice to take place. Lavoie and Dempsey (2004, cited in Harvey, 2012, p. 30) argues that cooperation “can enhance the productive capacity of a limited supply of digital preservation funds, by building shared resources, eliminating redundancies, and exploiting economies of scale”. Chapter 11 of the UNESCO guidelines (2003) give more pratical details on how this can take place, giving structural models and tips on what to share (information, standards, division of labour...). [CLOCKSS cooperation to preserve journals (see Harvey p32 + chapter 9); + Harvey p32 National Library of Netherlands &amp; Elsevier Science + most uni libraries access with publishers, even UoD with eg Dawsonera/ACM]
Legal issues
(see later) special case for emulation
In certain cases, the archiving process is not made in accordance with the original publisher. This is often the case for the automated archiving of the Internet (e.g. Wayback Machine), which automatically crawl pages, but as a website publisher, it is easily possible to opt out of these schemes [see http://archive.org/about/exclude.php [Accessed 17th Apr 2014]]. In the case of emulation, this is what happens with reverse engineering, that is, disassembling the original program to understand how it works and recreate a similar version which can operate from a different hardware or software architecture. This is a common process for proprietary software or hardware, whose source code is not available to the general public and no documentation is provided for developers. Often, this is developed by amateurs and hobbyists, but is illegal as it breaks the intellectual property of the original creator; Nintendo, for example, attacks reverse engineered emulators[http://www.nintendo.com/corp/legal.jsp [Accessed 17th Apr 2014]] and the sharing of ROMs [Read Only Memory; the bitstream of cartridges or discs containing the games]. There is however popular demand for playing these, and Nintendo has developed their own emulators to play legacy games on their new consoles (see the Virtual Console [http://en.wikipedia.org/wiki/Virtual_Console]), while still retaining their property rights (you need to buy the games again on an e-commerce platform). This however causes issue for the longer term preservation: there is no certainty that Nintendo will continue to provide this service on their future generations of consoles, or if they ever cease operations.
￼A similar issue happened with Apple Computer. In 2005, Apple changed the architecture (that is, the “language” of instructions needed for the processor) of their personal computers from PowerPC to Intel x86. This means that applications needed to be rewritten, sometimes from the ground up, to work natively on the newer Apple computers. To ease the transition, Apple created Rosetta, a software that dynamically translates PowerPC instructions to x86 instructions, so that buyers of the new Apple computers were still able to open legacy applications that were not yet rewritten for x86 — although this came with a significant performance hit. In 2009 however, support for PowerPC was entirely discontinued [...]
Libraries
Good curating and preservation starts early. Smith (2003, pp. 2–3, cited in Harvey, 2012, p. 32) suggests that “the critical dependency of preservation on good stewardship begins with the act of creation, and the creator has a decisive role in the longevity of the digital object”. Harvey (2012, p. 32) notes that “for most creators of information in any form this is a new role”; therefore publishers of digital content are not necessarily well prepared for preservation, and this is why collaboration with librarians and archivists can be helpful (Ayre and Muir, 2004).
Ayre and Muir (2004) note that if the publisher worries about preservation themselves then they generally already own the rights for preservation, but there are negotiations to be done if an external body helps with preservation.
National libraries
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preservation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preservation systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Elsevier Science) or publishers directly (ACM). A report by Hedstrom and Montgomery (1998, cited by Ayre and Muir, 2004) found that most research librarians in the UK thought that a legal deposit to national archives was the best option, but this was not a
￼clear consensus. The report also highlighted that these librarians thought that “other libraries and publishers would need to, and should, have some involvement in preservation”.
Because all preservation methods involve copying of the original object, it might be illegal to make such a copy without the necessary rights, even if it is for preservation purposes. Certain countries have laws to overcome this and allow national libraries to preserve all materials; Ayre and Muir (2004) list a few of them and their specificities, but the situation has since evolved, as a lot of legislations have enacted changes to specifically include digital materials.
Archivists
New stakeholders
Profits vs nonprofits
Harvey (2012) points out doubts in the real interests of for-profit companies to achieve long-term preservation;
Even given the prevailing market-driven political ethos, it is difficult to envisage a situation where market forces will be sufficient to ensure the preservation of this digital material. The opposite is more likely to apply: ‘in some cases market forces work against long-term preservation by locking customers into proprietary formats and systems’ (Workshop on Research Challenges in Digital Archiving and Long-term Preservation, 2003, pp.x-xi). (Harvey, 2012, p. 32). [link with Google concerns]
How to preserve
Software methods Making hard copies
What appears to be the simplest solution is to make physical copies (i.e. print) of the digital documents. Although this certainly solves some
￼
￼problems in regards to technological obsolescence, Rothenberg (1999) and Granger (2000) pointed out that this cannot be done for more interactive material besides text and images. There is also, obviously, an issue with the amount of content that can be stored in this way — this would not work for archiving websites. Granger (2000) recognises that “if one’s sole concern is with the intellectual content of a document and the document is of a fairly simple nature [...] this at least provides some form of security”.
Standardisation
Standardisation is the transformation of a document’s content to a format that is standardised, open and well documented, ensuring that we will be able to open it with a variety of applications on a variety of platforms and that we can rebuild a program for visualising that document — as opposed to vendor-specific, closed source program that could be discontinued at any point in the future. Rothenberg (1999, p. 10) claims that this is a bad solution because “standardisation sows the seeds of its own destruction by encouraging vendors to implement non-standard features in order to secure market share” (therefore these non-standard features will be lost if opened in a different application). Granger (2000) argues that the blame is not to be put on the method, but on vendors. Standardisation is a type of migration and therefore share some of it cons (notably, this absence of vendor-specific features could imply a loss in the presentation and other characteristics). Standards eventually become obsolete so it is also paramount to preserve the specifications of the format, or to define formats that are unambiguous, such as CSV or XML.
A slightly different approach to this method is rebuilding viewers. In this scenario, the bitstream is not migrated to a standardised format, but kept as is; we simply re-build a viewer that is able to read that format. This is not as straightforward as it sounds, because most of the time, formats for proprietary software are not documented and decrypting them would require reverse engineering. If they are documented, then it is likely that this format is already a standard. There exists cases where reverse engineering is possible, or where a non-standard format is documented; for example, Microsoft Word files are not a standard, but there is plenty of documentation available online to produce code able to read them. An experiment by the VERS project (Thibodeau 2002, p. 22) has shown that it is possible to reengineer a viewer for the PDF file format from the specification available; as long as we also preserve these specifications, we
￼will be able to read PDF files in the future.
UVC
Lorie (2000, in Thibodeau, 2002, p. 22) has also proposed that the use of a portable programming language, such as Java [footnote: Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine, which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.]. Lorie developed a software called Universal Virtual Computer (UVC), able to decrypt a variety of file formats, which can run on any platform supporting Java; because Java could be implemented on virtually any architecture, this means that a reader could be run on any platform without any effort. However, Lorie points out, this approach is limited in terms of functionality, and comes at the price of performance (because portable programming languages are platform-agnostic, this means the code is not optimised for any of the platforms). I am also wondering if this would really work on the long term, as we cannot be sure that future implementations of Java will be backward compatible with code written for a previous version.
Migration
Migration is the transformation of a document’s content to a format that is not necessarily standardised, but at least current; or, the newer version of same format. This could be, for example, transferring documents from the WordPerfect 6 format (used in the 80s and late 90s) to a Word 2011 format, or a Word 98 file to Word 2011. This should be done regularly, as after a certain period of time new programs will stop having backward compatibility to import these old formats (Thibodeau, 2002). This method has several downsides, mainly being that it is labour intensive and expensive (Thibodeau, 2002; Rothenberg, 1999); product lines, and therefore the migration path, could be terminated at any point (Thibodeau, 2002); the presentation and other characteristics could be changed (although this can be overcome by migrating to more flexible formats like PDF or LaTeX). Rothenberg (1999) adds that this method is also prone to error, risky (as it could compromise the integrity of the data), not scalable and it requires new solutions for each new format. Granger (2000) argues however that
￼comparatively, other methods (particularly emulation) are potentially much more expensive and labour intensive, and that for most preservation programmes, migration remains the only viable method.
Computer museums
Another approach to preservation, proposed by Swade (1993), would be to preserve a variety of hardware, software and devices to access obsolete media in “computer museums”. This is generally not considered a good solution; Granger (2000) notes that it would be unreasonably expensive to keep old machines running for an extended period of time, that computers chips will eventually decay anyway (and repair or replacement will be impossible), and that storage media not stand the test of time. There are still two possible use cases, identified by Rothenberg (1999): ensuring that emulators work as expected (by comparing them to original platforms), and helping with the recovery of lost data on obsolete media
Emulation
Emulation is the dynamic transformation of instruction sets to allow software and/or operating system designed for an obsolete architecture or platform to run on current systems. It is a highly complex method that offers certain benefits; notably, this is the most conservative method, as it is not destructive of the content or presentation. It allows us to run the original program used to create a digital object without altering that bitstream ; it “keeps the look and feel as well as the interactivity” (Granger, 2000) and as such, it is particularly interesting for objects rich in interaction, such as video games, data visualisations, or formats that are particularly complex (for example, medical imagery, 3D modelisations), for which methods like migration would be hard. It also ensures complete integrity and authenticity, which could be crucial for some data types.
There are numerous criticisms against emulation. A number of legal and intellectual property problems are raised, if the emulation strategy is not supported by the original author [see Nintendo &amp; Apple]. The complexity involved in creating emulators might be not worth it and requires a coherent organisation to reduce overhead (Granger 2000). Additionally, Thibodeau (2002, p. 21) argues that keeping the original functionality is not necessarily a positive thing when it comes to the delivery of the preserved content; “most users in the future will never have encountered—not to
￼mention learned how to use—most of the products they will need to access the preserved information objects”, and “it would cut users off from the possibility of using more advanced technologies for discovery, delivery, and analysis”.
“Emulators themselves become obsolete; therefore, it becomes necessary either to replace the old em- ulator with a new one or to create a new emulator that allows the old emulator to work on new platforms. In fact, if you get into an emula- tion strategy, you have bought into a migration strategy. Either strategy adds complexity over time.” (thibodeau 2002 p.20)
[NB: due to the length limit of this literature review, I have only explained the most popular archiving techniques. See Thibodeau (2002) and Harvey (2012) for a more comprehensive list of methods, including configurable chips, persistent archives, object interchange format, etc.]
Choosing one
Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method: feasibility, sustainability, practicality and appropriateness.
Feasability means that the hardware and the software for implementing a given method must be existing and developed. Sustainability is ensuring that this method can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable”. This means that the method must be resistant to technological obsolescence, both for storing the data (medium will change) and accessing it (means to access the media ane decode the bitstream will change).
Practicality is establishing that this method will be reasonably difficult and affordable. [This can generally change depending on the resources of the preserving organisation, the available technology at that time and the valuation of the digital objects.]
Finally, appropriateness is using a method that is relevant to the type of material being preserved, and the objectives of the preservation. For example, del Pozo et al. (2012, p. 7) suggests that if the integrity and
￼
￼authenticity of the documents are not paramount, then a migration that keeps the contents but discards the presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).
Authenticity/integrity and issues with each method
Different preservation methods yield different results in what is called authenticity, that is how faithful the rendition [its presentation] of the preserved object will be. Authenticity is subjective and therefore there is debate around this issue (Del Pozo et al., 2012, p. 7; Cook, 2000); however most agree that while as little difference in the presentation is desirable, it is rarely (if ever) possible to keep a truthful rendition. As an example, del Pozo et al. (2012, p. 8) use a spreadsheet within the migration method:
“For instance, one institution may decide to normalise a spreadsheet into a PDF, which would retain the cell values but destroy any formula used to calculate them. This would favour a particular presentation of that digital object over the information form of the original. On the other hand, another institution might decide to normalise spreadsheets into ODF, which may lose some formatting but retain the formula used to derive each cell. In this case, being able to retain the information form of the file would be seen as more important.”
Thibodeau (2002, p. 28) however points out that “people will want to use the best available technology—or at least technologies they know how to use— for discovery, retrieval, processing, and delivery of preserved information. There is a danger that to the degree that preservation solutions keep things unaltered they will create barriers to satisfying this basic user requirement.” An overly faithful preservation would therefore not be desirable. Again, this is subject to a high number of parameters.
Another important issue is integrity, i.e. “ensuring the object is complete and has not been altered or corrupted” (Harvey, 2012, p. 54; Ross [CITED], 2002, p. 7); that is, the object “is what it purports to be”, and no parts are missing from it. This is particularly important, Harvey (2012, p. 54) notes, for business archiving, where the legal value of a digital object could be lost if we cannot demonstrate that this object hasn’t been tampered with, or that a
￼
￼migration processes have not incurred data losses. However, as Lynch (2000) has argued, the integrity of objects is only a matter of trust. The guidelines of UNESCO (2003, p. 22) recommend that the best protection for authenticity is proper documentation of the archival process; Harvey (2012, p. 54) expands on this idea: “for instance, if it can be established that a digital object has always been kept in the custody of an archive in which every change to it has been recorded (such as changes resulting from migration of the bit-stream – the dates at which migration occurred, to which media, and so on), then we can be more secure about its integrity.”
Emulation / legal rights with videogames Use of standards
Some standards such as OAIS (Open Archival Information System), originally developed for space science, could be used. Sadly [no implementation][source??]
Personal archiving
On a more personal level, Harvey (2012) and Lukesh (1999) note that personal correspondance might be lost if we do not take steps to preserve them:
“The widespread shift from writing letters to the use of email has diminished the likelihood that personal correspondence will remain accessible to future historians. Lukesh asked in 1999, ‘Where will our understandings of today and, more critically, the next century be, if this rich source of information is no longer available?’, as scientists, scholars, historians and almost everyone increasingly use email” (Lukesh, 1999) (in Harvey, 2012 p. 32)
While this is a correct idea, I think that, just like the archiving of Usenet, few people kept their letters in the sole purpose of leaving researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.
￼
￼Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artifacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundance) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths. However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited; second, storing photos and data on online services mean we may forget about them in a few years (Banks, 2011).
What happens after our death
### [Digital heritage]
Shifts in usages (more photos)
Advantages (sharing, organisation etc.); record part of our lives we never did before
Digital artifacts have certain fundamental advantages over physical objects: the main two being the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost- free (Banks, 2011). This actually provides numerous advantages in terms of preservation.
[[+ tie with “In the past ancestors have signified something is important simply by keeping it” part ]]
The first one, ease of organisation, can be significantly helpful in tackling the abundance of digital data. Banks (2011) suggests that the technologies lying behind the ranking in the result of Web search engines could, eventually, help us in understanding and finding what is our most important data. An attempt has been made by the MUSE (Memories USing
￼Email) project (Hangal et al., 2011), which aims to find patterns in our emails archives to help us make sense of this large data set. As the authors note in the introduction:
“Email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later, and thereby use their email account as an informal backup device. Therefore, email archives contain or reflect memories that are extremely valuable for the purposes of reminiscence.” (Hangal et al., 2011)
Early users reported that they have been using it to: make a summary of their work progress over the year; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; renewing with old relationships; and serendipitous discovery. The authors note in the conclusion that the different uses of their program went beyond their original expectations of simply reminiscing: “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.”
The second advantage, the ability to accurately and easily make copies and backups, is fairly obviously an advantage for personal preservation. However, Banks (2011) notes, the process of backing up is troublesome and storage media do not make our data immune. Additionally, the use of online services to store our data creates an abstraction between the storage material and us; about Flickr: “I have no idea what kind of hardware my files are now stored or even where they are geographically. I just expect to have access to them as long as I pay my bills” (Banks, 2011, p. 27).
Keeping memories attached to digital objects
Banks (2011) also suggests that we could blend in the physical and the digital to allow recording of things we never had the opportunity to before. He gives as example the Weather Camera, an experimental object by Kjen Wilkens (2011) that records wind and temperature along with commentary,
￼
￼instead of an image, as an alternative to recall a place; or 3D backups by Héctor Serrano (2009), another experimental project that allows us to make backups of sentimentally important objects through 3D scanning and 3D printing. Similarly, Banks notes tools by Microsoft Research to recreate places in a 3D environment based on photos, allowing to recreate a sentimentally important place at any given point in time provided enough photos are available. A similar technique is used in bigger preservation projects, as described by Zhou et al. (2012), to make high quality 3D models of culturally important places and objects in China.
Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining that we could augment physical objects with RFID tags (and I would add, virtual reality technologies) to pass down stories attached to these objects.
Conclusion
</Text>
        </Document>
        <Document ID="102">
            <Title>Choosing a method</Title>
            <Text>Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method: feasibility, sustainability, practicality and appropriateness.
Feasibility means that the hardware and the software for implementing a given method must be existing and developed. Sustainability is ensuring that this method can be “applied indefinitely into the future, or that there are credible grounds for asserting that another path will offer a logical sequel to the method, should it cease being sustainable”. This means that the method must be resistant to technological obsolescence, both for storing the data (medium will change) and accessing it (means to access the media and decode the bitstream will change).
Practicality is establishing that this method will be reasonably difficult and affordable. This can generally change depending on the resources of the preserving organisation, the available technology at that time and the valuation of the digital objects.
Finally, appropriateness is using a method that is relevant to the type of material being preserved, and the objectives of the preservation. For example, del Pozo et al. (2012, p. 7) suggests that if the integrity and authenticity of the documents are not paramount, then a migration that keeps the contents but discards the presentation might be the least expensive and simplest option. Inversely, when trying to preserve highly interactive material such as video games or when the specifications for a format are unknown, then emulation is a more pertinent option, because migration would be extremely difficult and inaccurate (Granger, 2000).</Text>
        </Document>
        <Document ID="13">
            <Title>Untitled</Title>
        </Document>
        <Document ID="14">
            <Title>Conclusion</Title>
            <Text>This dissertation has explored different aspects of the preservation of digital artefacts, the issues with preservation of personal memories from social networks, and, in the context of interaction design, looked at potential methods for the retrieval of these memories in large archives, notably by delving into a variety of representations of time through history and analysing the results of a workshop to understand users’ responses.
By dissecting how the timeline used by social networks works, I have attempted to expose the fact that as a tool that attempts to be neutral and unopinionated, it is ultimately a deceptive and inefficient way of organising items once the amount of information is large enough. For interaction design, it is a challenge to organise information in a manner that is pertinent for users, and looking at alternative ways of representing time was important to be able to design an efficient system to retrieve memories from an archive. The workshop I have held also allowed me to obtain great insights from the potential users’ perspective, and what are important factors and concepts to think about when designing such a system: the need for different filters when looking up in an archive, when simply increasing the granularity is not sufficient to help finding something with the information we remember; the importance of careful design in terms of readability and separation, to allow complexity while retaining the user; the general use of periods and events as main reference points when asking people to visually describe their life, rather than time units such as years or months.
The research presented here is a stepping stone for my honours project, and the observations made here will allow me to drive the development of new prototypes. However, it is far from being a comprehensive answer to all the questions originally asked. I have only obtained a limited understanding of people’s behaviour and attitudes towards the preservation of their online data, and the research done on visual representation is not sufficient to establish strong design guidelines for the design of such systems.
To consolidate the research presented here and help in fully answering the questions asked, further research will be needed. Building prototypes and testing them with users, which is what I set out to do when originally planning this dissertation, actually requires a good understanding of the existing representations of time in the first place. I will now be able to do this with my honours project, but a more complete study with a wider variety of interface paradigms, as part of a MSc or PhD research, would reveal new insights. It would also be necessary to go further in depth when attempting to understand the processes used by users when retrieving old memories on social networks, using ethnographic observation with a careful ethical consideration, and a larger pool of participants.
This area of study is complex, because it has a “futuristic” aspect to it: the full potential of a retrieval system would only be achieved once several decades of data have been accumulated, which has not happened yet since all the social networking sites are still relatively young. However, I am hoping that small pieces of research and experimentation such as this one will pave the way for larger projects in this field, so that powerful, user-friendly systems can be built to preserve emotionally important content before it disappears, and allow new experiences for its exploration and recovery.</Text>
            <Notes>- Longer section on the limitations of your research. 
- need to emphasise the contribution that it makes to research.
- need for future research. 
- suggest something that could be developed from your work as a PhD thesis

(source http://www2.warwick.ac.uk/fac/soc/al/learning_english/leap/writing/conclusions/)


—

A summary of the main points (being careful not to repeat exactly what you have written before)
Concluding statements 
Recommendations
Predictions
Solutions

or

A summary of the main part of the text
A deduction made on the basis of the main body
Your personal opinion on what has been discussed
A statement about the limitations of the work
A comment about the future based on what has been discussed
The implications of the work for future research
Important facts and figures not mentioned in the main body</Notes>
        </Document>
        <Document ID="111">
            <Title>Loss of metadata</Title>
            <Text>Poor preservation documentation and metadata means it could be hard for potential users to find the data (UNESCO 2003). “Critical aspects of functionality, such as formatting of documents or the rules by which databases operate, may not be recognised and may be discarded or damaged in preservation processing.” (UNESCO 2003)
Poor integrity: “So much contextual information may be lost that the materials themselves are unintelligible or not trusted even when they can be accessed”</Text>
        </Document>
        <Document ID="103">
            <Title>Keeping track</Title>
            <Synopsis>Banks, 2011, p. 124</Synopsis>
            <Text>Banks (2011, pp. 124-136) thinks that the multiplication of online services is a good thing, creating competition and allowing users to try several services until they try one that fits their needs. However he notes that this is an issue for digital preservation as it scatters our data all over the network with few means to keep track of it:
“While I played around on Instagram I posted a number of images to their site, including a few of my daughter. I have a few more images posted up on Twitpic.com, a service that you can use for sharing images when publishing to Twitter. I may never use either of these services again, yet they have both got content on them that is a part of my personal history.” (Banks, 2011, p. 128)]
This problem is to be combined with the transience of such services. As Banks reminds us, services that were highly popular a decade ago (MySpace, Geocities) have suffered from an “exodus” of their users towards new services, for new competitors that are seen as more attractive, or due to a decline in quality of the platforms (he cites MySpace becoming inundated with advertising as a possible reason). Such a loss of users would hit the company financially, and as such they may be forced to close down or reinvent their model, erasing their users’ data as a result.</Text>
            <Comments>Twitpic, mentioned here, shut down in September 2014, after being around since 2008. (Everett, 2014)
bebo.com, which once was the most popular service in the UK, has shut down in 2013 and is reopening with different services, having completely erased the original website.</Comments>
        </Document>
        <Document ID="15">
            <Title>Untitled</Title>
        </Document>
        <Document ID="40">
            <Title>mindmap</Title>
        </Document>
        <Document ID="120">
            <Title>Keeping more context</Title>
            <Text>Banks (2011) also suggests that we could blend in the physical and the digital to allow recording of things we never had the opportunity to before. He gives as example the Weather Camera, an experimental object by Kjen Wilkens (2011) that records wind and temperature along with commentary, instead of an image, as an alternative to recall a place; or 3D backups by Héctor Serrano (2009), another experimental project that allows us to make backups of sentimentally important objects through 3D scanning and 3D printing.
Similarly, Banks notes tools by Microsoft Research to recreate places in a 3D environment based on photos, allowing to recreate a sentimentally important place at any given point in time provided enough photos are available. A similar technique is used in bigger preservation projects, as described by Zhou et al. (2012), to make high quality 3D models of culturally important places and objects in China.
Kirk and Sellen (2010) found however that ultimately, stories and narrative are more important than the preservation of the artifact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagining that we could augment physical objects with RFID tags (and I would add, virtual reality technologies) to pass down stories attached to these objects.</Text>
        </Document>
        <Document ID="112">
            <Title>The disappearance of constraints</Title>
            <Text>Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artefacts for ourselves. The majority of the time, we simply keep what we consider significant to remind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundancy) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.
However, the digital age changes this situation. First, the space to store our objects on computers and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting it (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. When analysing the reasons that lead us to keep or discard physical objects at home, Banks argues that while making a selection is a positive thing, because it forces us to filter our belongings and focus on what is really meaningful, we also run the risk of ridding ourselves of things that we wish we would have kept in retrospect. He points out that the organisation of digital files make this trickier: because we we can keep pretty much everything on virtual space, it is easier to accidentally delete meaningful things alongside the less important. (Banks, 2011 p. 22).
In the context of personal archiving, Banks notes that in the past, the legacy we left behind us was a highly selective one. Because our possessions are limited by physical space, until now our ancestors “have implicitly indicated that an item is significant through the simple act of keeping it. Although thousands of objects likely crossed their path over their lifetime, the constraints of money and space meant that only a few were retained, often the most significant.” (Banks, 2011, p. 78). He does however argue that this is no longer true in a digital world, because new possibilities mean we simply accumulate digital objects without necessarily ordering them by importance.</Text>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="16">
            <Title>What I want to prove</Title>
            <Synopsis>What are my objectives with that research, what are the results I expect
</Synopsis>
        </Document>
        <Document ID="41">
            <Title>sensor-poetics-screenshot</Title>
        </Document>
        <Document ID="104">
            <Title>Finding patterns to make sense</Title>
            <Synopsis>Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable in- formation.
Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that has been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
“The stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering in- tentions. Further, it suggests that browsing and remembering the past can affect the fu- ture.” (Hangal et al., 2011)</Synopsis>
        </Document>
        <Document ID="121">
            <Title>Post death</Title>
            <Text>Web 2.0 has impacted strongly on attitudes to who the audience for a memorial should be. Memorialization of deceased users through online social network sites makes death and grief hard to avoid [43]. Personal memorials abound that are to some degree publicly accessible online. Eulogies of dead loved ones can reach a larger audience and achieve greater longevity online compared to that achieved via obituary pages in the newspapers – e.g. the actor Kevin Costner’s eulogy to the singer Whitney Houston at her funeral has reached over 2.5 million viewers via YouTube9. However, unlike some offline memorials, the online ‘public’ audience can be controlled by privacy settings: whilst the general public cannot gain access to a memorialized Facebook page, an extended personal social network can. These same privacy controls and settings can conversely (and ironically) block those close to the deceased from accessing the same pages, if they were not already ‘friends’ online prior to memorialization. In summary, digital memorials can be expected to operate at various levels from the entirely private and domestic to the completely public and national, with various points in between wherein they might be privately created and curated but have levels of openness to public observation and/or contribution. The audience for a memorial may evolve over time, as personal relevance fades yet public significance continues.
{Moncur:2014by}

</Text>
        </Document>
        <Document ID="17">
            <Title>Document prototypes</Title>
            <Synopsis>Document the creation of prototypes (put full process/documentation in appendix, but generally mention what made me come to this research)</Synopsis>
            <Text>Find inspiration for prototypes
How to make prototypes
What questions needs to be answered — which ones will be answered by prototypes, which ones by ethnography, which ones by asking directly
</Text>
            <Notes>“be your own ethnographer”
see book on auto ethnography
appendices should contain concrete information

Start off by explaining which questions need to be answered by the workshop

WHY do I want alternative visualisations — what’s wrong with the timeline, why do I think it’s relevant to think about alternative ways

Get people’s opinion on this
Would people curate it themselves?

-&gt; explain why it would be more interesting to make it automatic and not manually curated (people would not be bothered probably, back that up with interaction design books/thoughts about blocking the user in what they’re doing) 

-&gt; Try that (make them draw it, map their life, highlight which parts are present on SNS)
(don’t be too directive but give examples, eg what led you to get to Dundee, what happened in Dundee that caused you to meet your partner, etc)


-&gt; make people find important photos on fb, look at how they proceed
-&gt; ask more questions about what they do not post on FB, if they would like to get this integrated in the archive

-&gt; concerns about privacy
</Notes>
        </Document>
        <Document ID="42">
            <Title>Structure</Title>
            <Text>STRUCTURE

Introduction
Why digital preservation
	Stats of numbers on digital vs physical
	Why digital degrades faster
		UNESCO’s Threats to digital continuity
		Fast decay of preservation medium
		Technological change of hardware and software
		Issues for long term storage
	Importance of data
		Library material: for society
		For businesses (records)
		Personal archiving / domestic archiving
		Preserving interactive material inc. video games
		Useful for researchers in the future
			Understanding our history
			Understanding the beginnings of the Internet, as we have shifted in an information society
			Preserving an accurate and integrity image of our society at a given point
				Twitter &amp; Usenet
	Advantages over physical preservation
		Mass preservation, easier access and organisation
		Recording digitally material that’s not born-digital
	Cost of restoration; case studies of lost data
		
Defining paradigms for digital preservation
	Pre-digital paradigms
	Inability to preserve the medium, only the bitstream
	Importance of metadata, relationship &amp; context
	Definition of terms		
		
What to preserve / Selectivity
	Harvey 5 pillars for selectivity
	Banks reasons for domestic archiving
	Technical possibility of archiving
	Pros/cons of archiving the entire internet
	Dangers of selection (Cook)
	Automatic selection (Reputation model)
	Crawling
	Manual curating
	Special Collections for events (eg before elections, see webarchive.org.uk for other ideas)
	Web archiving: what stands as heritage on the web

Who should preserve
	Legal issues
		(see later) special case for emulation
	Depends on the type of content
	Libraries
	National libraries
	Archivists
	New: how the creator/publisher is now fully responsible for it
	New stakeholders
	Profits vs nonprofits
	Personal archiving
		Yourself?
		Online services

How to preserve
	Preparation
	Software methods and choosing one
	+ Authenticity/integrity and issues with each method
	+ Emulation / legal rights with videogames
	Use of standards

Domestic archiving
    Archiving photos
    	What we store online
    		Personal media &amp; teenagers; privacy options
    		Data already public
    What happens after our deaths
    [Digital heritage]
    Shifts in usages (more photos)
    Advantages (sharing, organisation etc.); record part of our lives we never did before
    Keeping memories attached to digital objects
    or storing physical objects digitally
    -&gt; (larger scale?)


Conclusion</Text>
        </Document>
        <Document ID="113">
            <Title>Pro/cons of archiving everything</Title>
            <Text>
There are various controversies around whether we should automate the archiving of the Internet, or if we should operate a manual selection. UNESCO (2003, p. 73) notes that those who value a more comprehensive collection (i.e. archiving “all” the Internet) argue that “any information may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything”. This argument is particularly true because of the digital media: “unlike non-digital material such as paper-based artifacts, where there is a period of time in which to make selection decisions before deterioration of materials becomes an issue, the time frame for deciding whether or not to preserve digital materials is very short” (Harvey, 2012, p. 57). UNESCO (2003, p.71)backs that claim: “it may not be possible to wait for evidence of enduring value to emerge before making selection decisions”.
Other people [Cook?] think that it would be preferable to keep a curated collection because of a higher technical quality, and this also allow us to settle [negotiate?] preservation rights with the content producers. Harvey adds that we also do not have the technical capabilities to find all the pages on the Internet, and even if we had we would not have the technical possibility to store the whole of the Internet (Harvey 2012, p. 58); again, this is also something recognised by UNESCO: “‘there are usually more things – more information, more records, more publications, more data – than we have the means to keep” (2003, p.70).
The UNESCO (2003) and Cook (2000) both however recognise that a middle ground should be found and that both approaches are valid depending on the goal of the preservation. For instance, the Internet Archive[IA] is going through an automated process (archive as many pages as possible) but, because of technical limitation, only preserves the text and dismisses all other images, stylesheets and external media, which could be critical in some instances. It seems evident that for valued documents these should be retained. The British Library’s Web Archive[ukwa] [http://www.webarchive.org.uk/ukwa/]</Text>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="18">
            <Title>Literature review: the need for preservation</Title>
            <Synopsis>Reference (but edit) the literature review in line with what I have written before

Go through methods of archiving, particularly</Synopsis>
            <Text>The first chapter will look at some of the existing material concerned with the issues and interests surrounding personal digital archiving, and the preservation of social networking sites (SNS). For a review of the general issues around the practice of digital preservation, with more technical details, please refer to the literature review preceding this dissertation (Loux, 2014).</Text>
        </Document>
        <Document ID="130">
            <Title>Geocities</Title>
        </Document>
        <Document ID="43">
            <Title>weather-camera-wilkins</Title>
        </Document>
        <Document ID="105">
            <Title>Advantages of digital</Title>
            <Synopsis>Kirk and Sellen (2010) found however that ultimately, stories and narrative are more impor- tant than the preservation of the artefact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagin- ing we could also digitally augment physical objects or places. Banks (2011) gives as example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos.</Synopsis>
            <Text>Digital artifacts have certain fundamental advantages over physical objects: the main two being the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accurately and virtually cost- free (Banks, 2011). This actually provides numerous advantages in terms of preservation.</Text>
        </Document>
        <Document ID="122">
            <Title>Authenticity/integrity</Title>
            <Text>Different preservation methods yield different results in what is called authenticity, that is how faithful the rendition (i.e. the presentation) of the preserved object will be. Authenticity is subjective and therefore there is debate around this issue (Del Pozo et al., 2012, p. 7; Cook, 2000); however most agree that while as little difference in the presentation is desirable, it is rarely (if at all) possible to keep a truthful rendition. As an example, del Pozo et al. (2012, p. 8) use a spreadsheet within the migration method:
“For instance, one institution may decide to normalise a spreadsheet into a PDF, which would retain the cell values but destroy any formula used to calculate them. This would favour a particular presentation of that digital object over the information form of the original. On the other hand, another institution might decide to normalise spreadsheets into ODF, which may lose some formatting but retain the formula used to derive each cell. In this case, being able to retain the information form of the file would be seen as more important.”
Thibodeau (2002, p. 28) however points out that “people will want to use the best available technology—or at least technologies they know how to use— for discovery, retrieval, processing, and delivery of preserved information. There is a danger that to the degree that preservation solutions keep things unaltered they will create barriers to satisfying this basic user requirement.” An overly faithful preservation would therefore not be desirable. Again, this is subject to a high number of parameters.
Another important issue is integrity, i.e. “ensuring the object is complete and has not been altered or corrupted” (Harvey, 2012, p. 54; Ross [CITED], 2002, p. 7); that is, the object “is what it purports to be”, and no parts are missing from it. 
This is particularly important, Harvey (2012, p. 54) notes, for business archiving, where the legal value of a digital object could be lost if we cannot demonstrate that this object hasn’t been tampered with, or that a migration processes have not incurred data losses. However, as Lynch (2000) has argued, the integrity of objects is only a matter of trust. The guidelines of UNESCO (2003, p. 22) recommend that the best protection for authenticity is proper documentation of the archival process; Harvey (2012, p. 54) expands on this idea: “for instance, if it can be established that a digital object has always been kept in the custody of an archive in which every change to it has been recorded (such as changes resulting from migration of the bit-stream – the dates at which migration occurred, to which media, and so on), then we can be more secure about its integrity.”</Text>
        </Document>
        <Document ID="19">
            <Title>Literature review: Deconstructing the timeline</Title>
            <Synopsis>Origin of research - small review of what I have found about time representation
</Synopsis>
            <Text>Once we have chosen a suitable preservation scheme, there is another equally important question that must then be raised: how do we organise and retrieve our data? We cannot simply gather all digital items and let them pile up unorganised. In the context of a digital personal life, several artefacts are created daily (social network updates, emails, messages) and after a decade this can build up to tens of thousands of pieces of data, that we will need to go through once we are looking for something. This section of the dissertation discusses the gap in research that I want to explore, the experience of retrieval of memories. I will try to understand what encompasses this experience. 
When organising any type of information, there are generally five ways to do so, known as the five hat racks, or LATCH: by Location, Alphabetically, by Time, Category or Hierarchy/ continuum (Wurman, 1989, cited in Lidwell et al., 2010, p. 100; see also Rendgen et al., 2012, p. 96). In the context of my project, I chose to investigate time exclusively. An alphabetical ordering would be irrelevant since there is a lot of non-textual items on a social network, and it would regardless not be helpful on textual updates; location would be impractical as well, as a lot of the content would be concentrated in a single area; and categories and continuum cannot be established computationally from raw data in a manner that would be precise enough to be meaningful to users, although the models can be combined. The following chapter is therefore looking at what is time, how it can be represented, and why it is relevant to look for alternative ways of representing time.</Text>
            <Comments>Also called magnitude. For example, from lowest to highest price, or best to worst result.</Comments>
        </Document>
        <Document ID="44">
            <Title>README</Title>
            <Text>dissertation
============

Archiving the Internet, and Digital Preservation for the masses
</Text>
        </Document>
        <Document ID="114">
            <Title>5 reasons</Title>
            <Synopsis>Harvey 2012, p.26</Synopsis>
            <Text>	•	If unique information objects that are vulnerable and sensitive and therefore subject to risks can be preserved and protected
	•	If preservation ensures long-term accessibility for researchers and the public;
	•	If preservation fosters the accountability of governments and organisations
	•	If there is an economic or societal advantage in re-using information
	•	If there is a legal requirement to keep it (NSF-DELOS Working Group on Digital Archiving and Preservation, 2003, p.3).
— Harvey 2012, p.26. &lt;To rewrite/delete&gt;</Text>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="131">
            <Title>How the research is made</Title>
            <Text>Primary research
	•	Questionnaires
	•	Interviews
	•	Workshops
	•	Through practice - prototypes alternative ways of visualising memories, and see how it affects people. Focus on something over the whole project (visualisation/time representation, object obsolescence and open design, relationship with family and death)</Text>
        </Document>
        <Document ID="45">
            <Title>LiteratureReview-light</Title>
            <Text>DJ32004 RESEARCH &amp; CREATIVE PRACTICE PART 1 LITERATURE REVIEW
DIGITAL PRESERVATION
Victor Loux April 2014
Digital Interaction Design University of Dundee
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼
Table of contents
2 Table of contents
2 List of figures
3 Introduction
4 The need for digital preservation
6 Threats to digital continuity
7 Who must preserve, and what we should keep
7 How to preserve
8 Methods for software preservation
9 Choosing a method
9 Personal archiving
12 Conclusion
13 Bibliography
17 Project Proposal Form
List of figures
1.1 and 1.2 Kjen Wilkens, Sensor Poetics / Weather Camera http://www.kjenwilkens.com/projects/sensor-poetics
2.1 Héctor Seranno, Back Up Objects
http://www.hectorserrano.com/index.php?id=41&amp;m=lab&amp;grupo=backup
￼￼2
Introduction
As we shift into the Information Age and a knowledge-based economy, a number of concerns are being raised over the long-term preservation of digital data and artifacts.
This literature review aims to get an overview of the current problems, techniques and prac- tices in preserving data on digital media, including the definition and understanding of the new paradigms created by digital preservation, the importance of being able to store things on the long term, the processes used to curate and select content to be preserved, and the var- ious methods used to do so. It also encompasses personal archiving which will be the focus of my own research.
3
The need for digital preservation
With an exponential growth in data being produced digitally (SINTEF, 2013), comes a signif- icant growth in the volume of data worth archiving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional pres- ervation paradigms; where we can consider that for paper and physical artefacts, “benign ne- glect may be the best treatment” (Harvey, 2012, p. 10; derived from Bastian, Cloonan and Har- vey, 1993; 2011), the rapid changes in technology and the fragility of digital media make this rule dangerous for the survival of data.
First, we should define what are archives, and what they are useful for. As Cook eloquently puts it:
“Archives [...] are a source of memory about the past, about history, heritage, and culture, about personal roots and family connections, about who we are as human beings and about glimpses into our common humanity through recorded information in all media, much more than they are about narrow accountabilities or administrative continuity.” (Cook, 2000)
It is certainly difficult to understand which data was already lost, and what is at stake now. Harvey emitted some criticism of pessimistic views for archiving:
“It was suggested in 2002 that the last 25 years have been a ‘scenario of data loss and poor records that has dogged our progress’ and that, if this is not reversed, ‘the human record of the early 21st century may be unreadable’ (Deegan and Tanner, 2002). Rhetoric of this kind is common in the literature, but is regrettably poorly supported with specifics and evidence. Alarmist descriptions abound: there will be ‘a digital black hole... truly a digital dark age from which information may never reappear’ (Deegan and Taylor, 2002) if we do not address the problem, and we will become an amnesiac society. [...] It is only possible to conclude, as the authors of the Digital Preservation Coalition’s handbook (2008, p. 32) did for the UK, that the evidence of data loss is ‘as yet only largely anecdotal ... [but] it is certain that many potentially valuable digital materials have already been lost’.” (Harvey, 2012, pp. 33–34)
4
While it is difficult to argue that preserving digital objects is necessary, there is certainly a need to make a selection of what deserves to be protected, and to what level. It is clear that the long term preservation of legal and governmental records, scientific publications (Harvey, 2012, p. 26) and business records (Ross and Gow, 1999, p. iii) on digital form is crucial; but the archival of the wider Internet, cultural artefacts and our personal heritage is subject to discus- sion, as fewer items could be considered valuable.
UNESCO note that those who value a more comprehensive collection argue that “any informa- tion may turn out to have long-term value, and that the costs of detailed selection are greater than the costs of collecting and storing everything” (UNESCO, 2003, p. 73). Additionally, digi- tal storage media degrade so rapidly that the content might disappear before a decision about its value has been made (UNESCO, 2003, p. 71; Harvey, 2012, p. 57). Proponents of a more selective collection argue that we could obtain a higher content quality, settle the preserva- tion rights with content producers, and that we do not have the physical resources to store everything anyway (UNESCO, 2003, pp. 70-73; Harvey, 2012, pp. 26, 58).
Both UNESCO (2003) and Cook (2000) recognise that a middle ground must be found, and that both approaches are valid depending on the goal of the preservation intent. To give an ex- ample in archiving the Web, the Internet Archive (Kahle, 1996) has chosen to store copies of as many websites as possible, but due to technical limitations discards all images, stylesheets and multimedia objects; evidently this is not appropriate for valuable websites. The British Library’s Web Archive 1 curates collections of websites by topic and by events (Queen Jubi- lee, London 2005 terrorist attacks, General Elections, Olympic and Paralympic Games, ...) to reflect the state and opinion of the Web at these given points in history; because fewer sites are archived and their content is deemed important, they have archived full quality versions of these sites. See Masanès (2006, p. 83) for a methodology for this type of selection. Cook reminds us however that archivists have a duty of impartiality and objectivity during the se- lection and must ensure all points of view are being kept, to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination” (Cook, 2000).
Hiroyuki Kawano also proposes to use reputation models to let crawling robots consider the
￼1 http://www.webarchive.org.uk/ukwa/ [Accessed: 11 Apr 2014]
￼5
“importance, fairness, trustiness, uniqueness and valuation” of a Web page (Kawano, 2008) based on numerous parameters, to decide whether a page is worth archiving. The automated nature of this selection can, by nature, be inaccurate and inadvertently subjective, therefore a manual selection is still sometimes required.
Threats to digital continuity
UNESCO (2003, pp. 30–31) has compiled a list of threats to what they call digital continuity. The two principal ones are the short lifetime of digital materials carriers (i.e. storage media), and the obsolescence of the means to access these digital materials (i.e. the software to read files and the hardware to read discontinued storage media). Research by the Digital Preserva- tion Coalition (2008, p. 154) show that the reliability of storage material varies highly depend- ing on the type of material and the storage conditions, going from a few months to decades or even centuries.
But the media are only part of the equation; because all storage media eventually become obsolete, we will not necessarily be able to read them again even if they are not deteriorat- ed. Weathley (2003, cited by Harvey, 2012, p. 37) denounced that myth of long-lived media: “[an IT vendor] offered us a special polymer that they guaranteed would preserve a CD-ROM for 100 years. They were unable to answer how we would preserve a CD-ROM player for that length of time.” And as Pearson adds, not only is the CD-ROM drive needed, but also the type of cable to plug that drive to the computer, a computer motherboard that has a connector for this cable, an operating system with drivers for these types of connectors, and a program able to open the file itself (Pearson, 2009, slide 11). All of these elements become rapidly obsolete themselves, which mean that media may not be easily accessible on current technology after just one or two decades, even if the storage media last longer than that. Therefore it is needed to periodically migrate (a process also called “refreshing”) the bitstreams from a media type to a more contemporary one in order to ensure that this bitstream will remain easily accessi- ble (Harvey, 2012). As the bitstream is preserved, only the question of preserving software to read it is left.
6
Who must preserve, and what we should keep
Digital media also changes the original preservation paradigm for deciding who takes the re- sponsibility for archiving content, and how. Publishing processes used to be distinct in the “analogue” era. But as Nurnberg (1995, p. 21, cited in Harvey, 2012, p. 9) said, “technology tends to erase distinctions between the separate processes of creation, reproduction and dis- tribution that characterise the classic industrial model of print commodities”. Self-publication (particularly on websites) is much more common, and for many publishers the task of preser- vation is new to them (Harvey, 2012, p. 32); they might not have the awareness, knowledge or resources to do so themselves it is therefore essential that they collaborate with preservation organisations, such as libraries and archives (Ayre and Muir, 2004). See Harvey (2012, chapter 9), Ayre and Muir (2004) and UNESCO (2003, chapter 11) for more resources and case studies.
Ayre and Muir (2004) suggest that the complexity and resources needed for digital preser- vation may mean that individual libraries may not have the possibility to do the preservation themselves like they used to, but instead rely on national libraries and centralised preserva- tion systems to reduce overhead. This system is used by a number of libraries; even here at the University of Dundee, most journals and a selection of books are available through centralised systems (Dawsonera, Ebrary) or publishers directly (ACM, Elsevier Science, Springer).
How to preserve
There are multiple methods for preservation. Each has advantages and issues, although one parameter is particularly influential: authenticity. This refers to the faithfulness of the rendi- tion of the preserved object in the future, compared to when it was created; while the content should not be altered, its presentation may change (Cook, 2000). What is considered appro- priately authentic is subject to debate (del Pozo et al., 2012, p. 7; Cook, 2000) and may vary depending on the preservation intent; del Pozo et al. (2012, p. 8) give, as example, the nor- malisation of a spreadsheet to formats that may accurately retain either the formatting, or the formulae used in each cell.
7
Retaining integrity, that is ensuring the object is “what it purports to be” and is “complete and has not been altered or corrupted” (Ross, 2002, p. 7, cited in Harvey, 2012, p. 54), can also be crucially important, particularly for proving that a business or legal document has not been tampered with (Harvey, 2012, p. 54). But as Lynch (2000), UNESCO (2003, p. 22) and Harvey (2012, p. 54) argue, integrity is mostly a matter of trust and can only be ensured with a thor- ough documentation of the archiving process.
Methods for software preservation
[NB: due to the length limit of this literature review, I only give a simplified overview of the main archiving techniques. See Granger (2000), Thibodeau (2002) and Harvey (2012) for a comprehensive list of methods, including configurable chips, persistent archives, object inter- change format, etc.]
• Hard copies: print documents to archive them. Rarely considered a viable option for large data sets and interactive documents (Granger, 2000; Rothenberg, 1998).
• Computer Museums: Swade (1993) proposed to preserve hardware and software central- ised places. Considered short-term and prohibitively expensive by Granger (2000) but can be useful to recover old media or testing emulators (Rothenberg, 1998).
• Migration: the most popular option, consisting of periodically saving files to a current file type (newer version of a format, different format, or a standardised format) (Granger, 2000; Thibodeau, 2002) to avoid technological obsolescence. It is labour intensive and risky, as it compromises authenticity (Rothenberg, 1998).
• Universal Virtual Computer (UVC): proposed by Lorie (2000, in Thibodeau, 2002, p. 22). It consists of implementing a format viewer in a portable programming language like Java 2 which could then theoretically run on any future platform supporting that pro- gramming language. It is however slow and functionally limited (Lorie 2000), and runs the risk of the portable language itself becoming obsolete.
• Emulation is the most conservative model; it simulates a legacy architec-
2 Most programming languages include instructions that are specific to a given platform, therefore the same file will need to be adapted to run on another platform. “Portable” languages like Java are called high-level and are more abstract. They are run inside a virtual machine (itself low-level, different for every platform) which worries about transforming Java code into instructions that are specific to that platform; as such, the same file of code can be ran on any platform.
￼8
ture on current platforms, allowing to run the original software used to create a file, therefore not modifying them. It “keeps the look and feel as well as the in- teractivity” (Granger, 2000) therefore is highly relevant for video games (Gut- tenbrunner et al., 2010) and interactive systems, and it guarantees authenticity. It is however highly complex to implement (Granger, 2000; byuu, 2011) and need renew- al, since emulators themselves become obsolete (Thibodeau, 2002), as exemplified by em- ulators provided by Apple for their architecture switches (Mesa, A. F., 1997; AppleInsider, 2011) that were later discontinued, effectively removing the ability to run pre-2005 appli- cations on their current models.
Choosing a method
Thibodeau (2002, pp. 15–16) suggests four criteria to choose a preservation method. It must be:
• technically feasible
• sustainable and resistant to technological obsolescence
• practical (the preserving organisation must have the resources to do it)
• appropriate to the type of material being preserved, and the objectives of the preservation
(see del Pozo et al., 2012, p. 7 and Granger, 2000 for examples).
Personal archiving
It is interesting to ask ourselves if the paradigms for digital preservation used by librarians and archivists are still valid for preservation of our personal data. Harvey (2012) and Lukesh (1999, cited in Harvey, 2012, p. 32) note that our personal correspondence and sentimental ar- tefacts stored digitally might be lost if we do not take steps to preserve them, and wonder how we will be able to understand our modern life without these exchanges.
While this is a correct idea, I think that few people kept their letters in the sole purpose of leav- ing researchers decades from now understand our epoch’s social habits and ways of speaking. There has to be other motivations for preserving our conversations and our objects.
9
Richard Banks, a researcher at Microsoft Cambridge, suggests that we first preserve artefacts for ourselves. The majority of the time, we simply keep what we consider significant to re- mind ourselves of particular people, events and places, and to share them with people we care about; we discard what is not meaningful to us by pragmatism (lack of physical space, lack of importance, redundancy) (Banks, 2011, p. 6). This selection process contributes to keeping what we want to remember, and what is the legacy we will want to leave to others after our deaths.
However, the digital age changes this situation. First, the space to store our objects on com- puters and online is becoming virtually unlimited, and so we tend to accumulate data instead of selecting (Banks, 2011); second, the abundance of online services makes it harder to keep track of everything we create. Fortunately, digital objects have fundamental properties that physical artefacts don’t have, which actually provide numerous advantages in terms of pres- ervation: the ease of organising a collection of data through indexing, cataloguing and adding metadata (Kirk and Sellen, 2010, p. 35), and the ability to duplicate and share that object accu- rately and virtually cost-free (Banks, 2011).
The cataloguing advantage allows us to process it using computer science. Hangal et al. (2011) have developed MUSE (Memories USing Email), a system finding patterns in email archives to help us make sense of this large data set. As the authors note in the introduction, “email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later”, and so our inboxes contain highly valuable in- formation.
Early users reported that they have been using it to: make a summary of their work progress; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that has been left unfinished and forgotten; or renewing with old relationships. These uses went beyond the authors’ original expectations of simply reminiscing:
“The stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker [2010]: recollection, reminiscing, retrieving, reflecting, and remembering in- tentions. Further, it suggests that browsing and remembering the past can affect the fu- ture.” (Hangal et al., 2011)
10
The copying advantage, while useful for sharing, has issues for backing up. Banks (2011) notes the process is still troublesome, and still feels insecure because of cheap looking media, and nowadays, the abstraction with cloud storage (about Flickr: “I have no idea what kind of hard- ware my files are now stored on or even where they are geographically. I just expect to have access to them as long as I pay my bills” Banks, 2011, p. 27).
Kirk and Sellen (2010) found however that ultimately, stories and narrative are more impor- tant than the preservation of the artefact itself. They propose that “technology might play a role in capturing and associating stories or narratives with different physical objects”, imagin- ing we could also digitally augment physical objects or places. Banks (2011) gives as example the Weather Camera (Wilkens, 2011), which records wind force and temperature along with commentary; a system of physicals backup of sentimental items by Serrano (2009) using 3D scanning and 3D printing; and tools by Microsoft Research to recreate an environment in 3D just using photos. A similar technique is used in bigger preservation projects to make high quality 3D models of culturally important places and objects in China (Zhou et al., 2012).
Fig. 1.1: The Weather Camera, by Jens Wilkens. Fig. 1.2: Associating stories and weather to a timeline with the Weather Camera.
Fig. 2: backing up physical sentimental items using a 3D scanner and 3D printing, 11 with Back Up Objects by Héctor Serrano
￼￼￼
Conclusion
This literature review, although shallow considering the breadth of the topic, allowed me to gain an understanding of the current practices and debates in the digital archiving communi- ty, and to gather relevant sources for any future research in each sub-topic. I found the theme of personal archiving captivating but not explored as intensely as large scale preservation for our common knowledge and data; I would like to do deeper research in this particular area of digital preservation, notably on our use of social media and Internet services on the long term.
12
Bibliography
AppleInsider. (2011) ‘Inside Mac OS X 10.7 Lion: Missing Front Row, Rosetta and Java runtime’. AppleInsider. [web page] Accessible at http://appleinsider.com/articles/11/02/26/ mac_os_x_lion_drops_front_row_java_runtime_rosetta.html [Accessed: 19th Apr 2014]
Ayre, C. and Muir, A. (2004) ‘The right to preserve’. D-Lib Magazine, vol. 10 (No. 3). March. Available at http://www.dlib.org/dlib/march04/ayre/03ayre.html [Accessed: 11th Apr 2014]
Banks, R. (2011) The Future of Looking Back. Sebastopol: Microsoft Press.
Bearman, D. (1999) ‘Reality and Chimeras in the Preservation of Electronic Records’. D-Lib Magazine, vol. 5 (No. 4). April. Available at http://www.dlib.org/dlib/april99/ bearman/04bearman.html [Accessed: 7th Apr 2014]
Boyd, D. (2014) It’s Complicated: The Social Lives of Networked Teens. New Haven and London: Yale University Press.
byuu.1 (2011) ‘Accuracy takes power: one man’s 3 GHz quest to build a perfect SNES emulator’. Ars Technica. [web page] Available at: http://arstechnica.com/gaming/2011/08/ accuracy-takes-power-one-mans-3ghz-quest-to-build-a-perfect-snes-emulator/ [Accessed: 8th Apr 2014]
Cook, T. (2000) ‘Beyond the screen: the records continuum and archival cultural heritage.’ Presented at the Australian Society of Archivists Conference, Melbourne, 18 August. Available at http://www.mybestdocs.com/cook-t-beyondthescreen-000818.htm [Accessed: 9th Apr 2014]
Granger, S. (2000) ‘Emulation as a Digital Preservation Strategy’. D-Lib Magazine, vol. 6 (No. 10). October. Available at http://www.dlib.org/dlib/october00/granger/10granger.html [Accessed: 7th Apr 2014]
Guttenbrunner, M., Becker, C. and Rauber, A. (2010) ‘Keeping the game alive: Evaluating strategies for the preservation of console video games’. International Journal of Digital Curation, vol. 5 (Iss. 1), pp. 64-90.
￼￼￼￼￼￼￼￼￼￼1 The article is only credited to the developer’s pseudonym.
13
Bibliography (cont.)
Hangal, S., Lam, M. S. and Heer, J. (2011) ‘MUSE: reviving memories using email archives’, in
Proceedings of the 24th annual ACM symposium on User interface software and technology (UIST ‘11). New York, NY: ACM, pp. 75-84. doi:10.1145/2047196.2047206
Harvey, D. R. (2012) Preserving digital materials. Berlin: De Gruyter Saur.
Kahle, B. (1996) ‘Archiving the Internet’. Scientific American, Iss. March 1997. Available at http://web.archive.org/web/19971211123138/www.archive.org/sciam_article.html [Accessed: 27th Feb 2014]
Kawano, H. (2008) ‘Strategy of Digital Contents Archive Based on Reputation Model’, in ICSENG ‘08. Proceedings of 19th International Conference on Systems Engineering, 19-21 Aug, pp. 288-293. doi: 10.1109/ICSEng.2008.75
Kirk, D. S. and Sellen, A. (2010) ‘On human remains: Values and practice in the home archiving of cherished objects’. ACM Transactions on Human-Computer Interaction, vol. 17 (Iss. 3), article 10. doi:0.1145/1806923.1806924
Library of Congress. (2007) Digital Preservation Program Makes Awards to Preserve American Creative Works. [press release] Available at http://www.loc.gov/today/ pr/2007/07-156.html [Accessed: 14th Apr 2014]
Lubar, S. (1999) ‘Information Culture and the Archival Record’, in American Archivist, vol. 62 (Iss. 1), pp. 10-22.
Lynch, C. (2000) “Authenticity and Integrity in the Digital Environment: An Exploratory Analysis of the Central Role of Trust’, in Authenticity in a Digital Environment. Washington, DC: Council on Library and Information Resources. Available at http://www. clir.org/pubs/abstract/pub92abst.html [Accessed: 16th Apr 2014]
Masanès, J. (2006) Web archiving. Berlin: Springer.
Mesa, A. F. (1997) ‘The PowerPC Triumph’. The Apple Museum. [web page] Available at: http://applemuseum.bott.org/sections/ppc.html [Accessed: 19th Apr 2014]
￼￼￼￼￼￼￼￼￼14
Bibliography (cont.)
Paloque-Bergès, C. (2011) Entre trivialité et culture : une histoire de l’Internet vernaculaire. Émergence et médiations d’un folklore de réseau [Between Triviality and Culture: a History of the Vernacular Internet. Emergence and mediations in network folklore]. PhD thesis, self-published. Available at http://camillepaloqueberges.wordpress.com/phd-thesis/ [Accessed: 6th Apr 2014] 2
Paloque-Bergès, C. (2013) ‘Un patrimoine composite : le public Internet face à l’archivage
de sa matière culturelle’ [A composite heritage: the Internet public confronted to the archiving of its cultural matter], in I. Dragan, P. Stefanescu, N. Pelissier, J.-F. Tétu and
L. Idjeroui-Ravez (eds.) Traces, mémoire, communication. Bucharest: Editura Universităţii din Bucureşti. 2
Pearson, D. (2009) Preserve or Preserve Not, There is No Try: some dilemmas relating
to Personal Digital Archiving. [PowerPoint slides]. National Library of Australia Staff Papers. Available at http://www.nla.gov.au/openpublish/index.php/nlasp/article/view/1388 [Accessed: 9th Apr 2014]
del Pozo, N., Long, A. S. and Pearson, D. (2012) ‘Land of the Lost: a discussion of what can be preserved through digital preservation’. Library Hi Tech, vol. 28 (Iss. 2), pp. 290-300. Available from: doi: 10.1108/07378831011047686. [Accessed: 6th Apr 2014]
Ross, S. and Gow, A. (1999) Digital archaeology: rescuing neglected and damaged data resources: a JISC/NPO study within Electronic Libraries (eLib) Programme on the Preservation of Electronic Materials. London: Library Information Technology Centre. Available at http://www.ukoln.ac.uk/services/elib/papers/supporting/pdf/p2.pdf [Accessed: 17th Apr 2014]
Rothenberg, J. (1998) Avoiding Technological Quicksand: Finding a Viable Technical Foundation for Digital Preservation. [report] Washington, DC: Council on Library and Information Resources.
￼￼￼￼￼2 In French.
15
Bibliography (cont.)
Serrano, H. (2009) Back Up Objects, Héctor Serrano. [web page] Available at: http://www. hectorserrano.com/index.php?id=41&amp;m=lab&amp;grupo=backup [Accessed: 17th Apr 2014].
SINTEF. (2013) ‘Big Data, for better or worse: 90% of world’s data generated over last two years.’ ScienceDaily. [web page] Available at: http://www.sciencedaily.com/ releases/2013/05/130522085217.htm [Accessed: 16th Apr 2014]
Swade, D. (1993) ‘The problems of software conservation”, in Computer Resurrection, vol. 7. Available at: http://www.cs.man.ac.uk/CCS/res/res07.htm#f [Accessed: 12th Apr 2014]
Task Force on Archiving of Digital Information. (1996) Preserving digital information, Report of the Task Force on Archiving of Digital Information. Washington, DC: Council on Library and Information Resources.
Thibodeau, K. (2002) ‘Overview of technological approaches to digital preservation
and challenges in coming years’, in The state of digital preservation: an international perspective. Washington, DC: Council on Library and Information Resources, pp. 4-31.
UNESCO. (2003) Guidelines for the preservation of digital heritage, prepared by the National Library of Australia. Paris: UNESCO. Available at http://unesdoc.unesco.org/ images/0013/001300/130071e.pdf [Accessed: 9 Apr 2014]
Wilkens, K. (2011) Sensor Poetics, Kjenwilkens.com. [web page] Available at http://www. kjenwilkens.com/projects/sensor-poetics [Accessed: 18th Apr 2014]
Zimmer, M. (2010) ‘“But the data is already public”: on the ethics of research in Facebook’, in Ethics and information technology, vol. 12 (Iss. 4), pp. 313-325. doi: 10.1007/s10676-010- 9227-5
Zhou, M., Geng, G. and Wu, Z. (2012) Digital preservation technology for cultural heritage. Berlin: Springer.
￼￼￼￼￼￼￼￼￼￼￼￼16
Project Proposal Form
￼￼Name Programme/Course Project/working title
Project Aims (i.e. what you want to learn about through further investigation. E.g. I want toa learn more about the creative process of animators)
Objectives (i.e. the particular things you propose to do
in order to carry out your investigation. E.g. Make contact with professional animators and arrange
to meet them. Possibly Interview them or observe their creative activities to gather data)
Methods (i.e. the different ways in which you will achieve these objectives. E.g. Open ended interview techniques and grounded theory analysis or video observation of working animators)
Victor Loux
Digital Interaction Design
Digital preservation for the masses
I would like to look at further research papers on personal preservation and focus on ways to apply “large-scale” paradigms to our personal heritage while trying to be respectful of people’s privacy and unintrusive.
I first intend to do further reading in this area, as until now I have been exploring digital preservation as a whole with no particular focus, to get a broader understanding of the issues
and solutions. I would like to interview several people of different age ranges to understand their relationship to technology and their personal digital heritage, notably concerning photographs and conversations.
Using open ended interview techniques, further literature review and possibly research through practice as I intend to explore this theme for my final year project.
￼￼￼￼￼￼￼￼￼￼￼￼17
</Text>
        </Document>
        <Document ID="106">
            <Title>Social networks</Title>
            <Text>The emergence of reliable broadband and smartphones meant that instead of storing things locally, we often compose and publish them directly online, on social networks or in the cloud, with no stable backup of our own.
 The safety of the content is an issue that’s already been under public spotlight, both in terms of privacy (your content is sometimes publicly accessible) and security (hacking and social engineering[1], governmental surveillance programmes).  What interests me here is the lifespan of the data; the uncertainty of what happens to our data if the provider goes out of business, arbitrarily decides to suspend one’s account[2], or accidentally loses it (be it due to an accidental manipulation, technical failure or a natural disaster at the data centres).
Of course, any data (digital or not) is vulnerable to time, and it is generally possible to back them up and use techniques to keep it available over long period of time. The problems brought by social networks are that:
	•	these techniques are not widely available for the general public 
	•	there is a lack of understanding or concern from the public about this
	•	The data is harder to access and therefore harder to back up


[1] A type of emotive manipulation on someone to gain access to confidential information or an online account. It is based on the malicious exploitation of trust of the victim, and is not a technical flaw.
[2] http://consumerist.com/2011/07/22/google-deletes-last-7-years-of-users-digital-life-shrugs/</Text>
        </Document>
        <Document ID="123">
            <Title>Grammar/spelling checks</Title>
            <Text>	•	Artefact, not artifact
	•	Data always singular (data is); make a style note from Guardian/Observer style guide - “data takes a singular verb (like agenda), though strictly a plural; no one ever uses "agendum" or "datum””
	•	Dates (accessed by): [Accessed: 20 Oct. 2014]
	•	Check for elisions (I’ve -&gt; I have)
Fine type:
	•	Non-breaking space before page numbers (p.⌙22, esp. in sidenotes)

Notes from reviews:

	•	Make a table of contents!
	•	Do not use end notes but footnotes and reference all links in bibliography not as footnotes
	•	Balance literature review with field research
	•	Do not throw out too much
	•	Rw Literature review to Bibliography, referenced to references
	•	Context&gt;Objectives: reads like a design brief for the honours project, focus on the objectives of the dissertation instead
	•	Intro is good
	•	For subsections: flesh out with notes on the question to be resolved (as per introduction)

References:
	•	Comma in-text: (Fowler and Burchfield, 2010)
	•	DOIs: links to a DOI starting with dx.doi.org e.g. http://dx.doi.org/10.1016/B978-0-12-385948-8.00020-7
	•	Years in parentheses, not followed by full stop eg. Last, F. (2010) not Last, F. 2010. 
	•	Re-order by name and year
	•	Double check for what’s actually cited in References, and put the rest in Bibliography and sort out exactly how relevant it is
	•	Italicise names of works; for journals it’s the name of the journal not the name of the article, e.g. Chapman, J. (2009). Design for (Emotional) Durability. Design Issues, 25(4), pp.29-35.
	•	check for consistency
	•	full stop before and after pages eg. City: Publisher. pp. 20-27.
	•	Consistency in US publishers: City, MA: Place (no dots in state initials)
	•	Consistency of Available at links + accessed date: last item, or before page numbers?? check on a reference
	•	list authors with ‘and’ not an ampersand. Check if we should list all or et al. in bibliography
</Text>
        </Document>
        <Document ID="70">
            <Title>Bibliography</Title>
        </Document>
        <Document ID="46">
            <Title>New Folder</Title>
        </Document>
        <Document ID="140">
            <Title>Figures list</Title>
            <Text>
TristamShandy/diagA
Diagrams mapping the course of Tristram Shandy’s life story, by Laurence Sterne. From the 1761 satire on linear narrative The Life and Opinions of Tristram Shandy, Gentleman.
Sterne, L. (1761).  The Life and Opinions of Tristram Shandy, Gentleman. [ebook]. Reprint, Salt Lake City: Project Gutenberg, 2012. Available from: http://www.gutenberg.org/ebooks/39270 [Accessed: 7th Dec. 2014]. pp. 347-348 (Book IV, chapter XL)

TristamShandy/diagB
idem
idem
Cartographies/1-NurembergChronicle
Nuremberg Chronicle by Hartmann Scheidel, undated. Depicts the descendants of  Noah’s son Japhet, using the tree as a metaphor.
Hartmann Scheidel, Nuremberg Chronicle. Courtesy of the Department of Rare Books and Special Collections, Princeton University Library. Found in Cartographies of Time, p. 32.
Cartographies/2-PrincetonMS57
Record of English history from Alfred the Great (871–99) to Henry III (1216–72), in the manuscript 57 of Princeton. 
Anonymous. Princeton MS. 57; Courtesy of the Department of Rare Books and Special Collections, Princeton University Library.  Found in Cartographies of Time, p. 35.
Cartographies/3-Chronicarum
Codex genealogy using vertical streams. Chronicarum et historiarum epitome, 1475, anonymous.
Anonymous. Chronicarum et historiarum epitome, 1475. Courtesy of Burke Library, Union Theological Seminary. Found in Cartographies of Time, p. 39
Cartographies/4-JoachimOfFiore
Diagram showing interestecting states or ages of world history, by followers of Joachim of Fiore, in Oxfords’ manuscript 255a.
Joachim of Fiore. 12th century. Oxford MS. 255a, Corpus Christi College, f. 11r. Cartographies of Time, p. 57.
Cartographies/5-JohannFunck
Historical calendar, showing events of the Old and New testaments in modern dates and terms. Johann Funck, undated.
Johann Funck. Undated. From Cartographies of Time, p. 73
Cartographies/6-DiscusChronologicus
Discus chronologicus by German engraver Christoph Weigel, early 1720s. It is a paper chart with a pivoting central arm, with rings representing kingdoms and radial wedges representing centuries.
Christoph Weigel. Discus Chronologicus. Courtesy of Department of Rare Books and Special Collections, Princeton University Library. From Cartographies of Time, p. 105
Cartographies/7-CartaIstorica
Historical map of Italy by Girolamo Andrea Martignoni, in 1721. It uses a visual analogy between geographic space and historical time. “Though he calls them maps, Martignoni’s works are not historical maps in the conventional sense of geographical snapshots from different moments in history: they are chronological charts presented in a cartographic form. While, at a glance, they seem to depict a circular territory with a great lake at the center and rivers running to and fro, on examination, these rivers and land masses turn out not to be landscape features but temporal metaphors—territories of history and rivers of time. The streams at the top of the chart represent the nations conquered by the Roman Empire; those at the bottom, the nations that emerged from it; and the great lake at the center, the empire itself.” [Cartographies of Time]
Girolamo Andrea Martignoni, Spiegazione della carta istorica dell’Italia (Historical map of Italy), Rome, 1721. Courtesy of Department of Rare Books and Special Collections, Princeton University Library. From Cartographies of Time, p.109.
Cartographies/8-AtlasHistoricus
This very large chronological chart from the Atlas historicus, published by the German engraver Johann Georg Hagelgans in 1718, is exceptionally rich; it contains images, maps and data, while keeping a tabular format.
Johann Georg Hagelgans, Atlas Historicus. 1718. Courtesy of Department of Rare Books and Special Collections, Princeton University Library. From Cartographies of Time, p. 107
Cartographies/9-NewChartOfHistory
A New Chart of History, published in 1769 by Joseph Priestley, normalised the distribution of dates.
Joseph Priestley, A New Chart of History. 1769. Courtesy of the Library Company of Philadelphia. From Cartographies of Time, pp. 120-121
Cartographies/10-HistoricalAtlas
Edward Quin’s An Historical Atlas, published in 1828, is an interesting concept. Page after page, moment in history after another, it shows the progression of the political divisions and Westerners’ knowledge of the world, using clouds rolling back to mask unknown regions.
Edward Quin, An Historical Atlas. Courtesy of Department of Rare Books and Special Collections, Princeton University Library. From Cartographies of Time, pp. 128-129
Cartographies/11-StromDerZeiten
Strom der Zeiten (Stream of Time) is a highly influential chart published in 1804 by Friedrich Strass in Austria. Strass thought that linear charts such as Priestley’s were misleading because their regular measurements implied that history was uniform, and instead chose to use the metaphor of streams.
William Bell, English translation of Friedrich Strass’s 1804 Strom der Zeiten, London, 1849. Courtesy of Cotsen Children’s Collection, Department of Rare Books and Special Collections, Princeton University Library. From Cartographies of Time, p. 144
Cartographies/12-EcclesiasticalChart
1833 chart by Richard Cunningham Shimeall. It is read from the inside to the outside; the radial columns represent centuries from the Creation to the Apocalypse.
Richard Cunningham Shimeall, Distinctive Complete Ecclesiastical Chart from the Earliest Records, Sacred and Profane, Down to the Present Day. 1833. Courtesy of Burke Library, Union Theological Seminary. From Cartographies of Time, p. 164
Cartographies/13-GameOfUniversalHistory
Wallis’ New Game of Universal History and Chronology  is a 1840 game sheet showing various technological advances such as the first use of paper in England, the invention of engraving and the discovery of longitude.
Wallis’ New Game of Universal History and Chronology, 1840. Courtesy of Cotsen Children’s Library, Department of Rare Books and Special Collections, Princeton University Library. From Cartographies of Time, p. 194.
Cartographies/14-WillardTemple
Temple of Time by Emma Willard, published in 1846, is a 3D projection of chronography. Each century is represented by a standing column, with historical figures of the Old and the New world on each side, and a stream chart on the floor.
Emma Willard, Temple of Time, 1846. Courtesy of General Research Division, The New York Public Library, Astor, Lenox and Tilden Foundations. From Cartographies of Time, p. 201
Timelines/movement
Timeline going from left to right
Self made (reuse the one made for the slides)
Timelines/progressBarWestern
Western progress bar
id
Timelines/progressBarRTL
Right-to-left progress bar
web
Timelines/Ouroboros
The symbol of the Ouroboros, a snake or a dragon eating its tail, is extremely ancient; its first known representation can be found in the Enigmatic Book of the Netherworld, a funerary text written in the 14th century BC in ancient Egypt (Hornung, 1999). It has however been used by many cultures across the globes, and particularly for representing cyclical visions of time.
 Ouroboros drawing, from the 1478 manuscript  Parisinus graecus 2327, which was a copy of a lost manuscript of an early medieval tract attributed to Synosius of Cyrene (died in 412).


Timelines/HistoryCommunications
Timeline showing the major advances in communication technology, illustrating an article in Nature Review Cancer, 2005.
Figure in an article by Viswanath, K. (2005). The communications revolution and cancer control. Nature Review Cancer, 5(10), pp.828-835.
Timelines/CathyHaynesHowtoMapaLife2012
Detail from the 20-metre collectively drawn life map made by students and the general public at the Rietveld Academy, Amsterdam, March 2012.
Photos: Taya Hauer.
Workshop/Evaluations-Results
Average grades for the evaluation of historical time representations.
Average grades for the evaluation of historical time representations. Full results in [appendix I].
Review/UnderConstruction
An “under construction” graphic, popular in the 1990s
A “under construction” graphic, popular in the 1990s. source: http://textfiles.com/underconstruction
Review/Geocities
Screenshot of a typical GeoCities page

Review/SlideViewer
Photograph of Digital Slide Viewer, a prototype by Microsoft Research, which allows to browse Flickr albums like an old-style slide viewer.
Photograph of Digital Slide Viewer, a prototype by Microsoft Research, which allows to browse Flickr albums like an old-style slide viewer. Source: http://www.richardbanks.com/2010/03/16/techfest-2010-some-technology-heirlooms/
</Text>
        </Document>
        <Document ID="115">
            <Title>Dangers of selection</Title>
            <Text>However, Cook (2000) points out the dangers of manual selection for what is worth archiving: “With memory comes the inevitable privileging of certain records and records creators, and the marginalizing or silencing of others” (Cook, 2000, cited in Harvey p. 58). He asserts that the archivists must be impartial and objective, and ensure all points of view are kept to ensure our shared memory does not “becomes counterfeit, or at least transformed into forgery, manipulation, or imagination”. This is something that is clear with manual archiving, but could also be a problem, maybe unintentionally, with the automated discovery of content when archiving Web pages.</Text>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="71">
            <Title>Literature review</Title>
            <Text>AppleInsider. (2011) ‘Inside Mac OS X 10.7 Lion: Missing Front Row, Rosetta and Java runtime’. AppleInsider. [web page] Accessible at http://appleinsider.com/articles/11/02/26/mac_os_x_lion_drops_front_row_java_runtime_rosetta.html [Accessed: 19th Apr 2014] 
Ayre, C. and Muir, A. (2004) ‘The right to preserve’. D-Lib Magazine, vol. 10 (No. 3). March. Available at http://www.dlib.org/dlib/march04/ayre/03ayre.html [Accessed: 11th Apr 2014]
Bearman, D. (1999) ‘Reality and Chimeras in the Preservation of Electronic Records’. D-Lib Magazine, vol. 5 (No. 4). April. Available at http://www.dlib.org/dlib/april99/bearman/04bearman.html [Accessed: 7th Apr 2014]
Boyd, D. (2014) It’s Complicated: The Social Lives of Networked Teens. New Haven and London: Yale University Press.
byuu. (2011) ‘Accuracy takes power: one man’s 3 GHz quest to build a perfect SNES emulator’. Ars Technica. [web page] Available at: http://arstechnica.com/gaming/2011/08/accuracy-takes-power-one-mans-3ghz-quest-to-build-a-perfect-snes-emulator/  [Accessed: 8th Apr 2014]
Cook, T. (2000) ‘Beyond the screen: the records continuum and archival cultural heritage.’ Presented at the Australian Society of Archivists Conference, Melbourne, 18 August. Available at http://www.mybestdocs.com/cook-t-beyondthescreen-000818.htm [Accessed: 9th Apr 2014]
Granger, S. (2000) ‘Emulation as a Digital Preservation Strategy’. D-Lib Magazine, vol. 6 (No. 10). October. Available at http://www.dlib.org/dlib/october00/granger/10granger.html [Accessed: 7th Apr 2014]
Guttenbrunner, M., Becker, C. and Rauber, A. (2010) ‘Keeping the game alive: Evaluating strategies for the preservation of console video games’. International Journal of Digital Curation, vol. 5 (Iss. 1), pp. 64-90.
Hangal, S., Lam, M. S. and Heer, J. (2011) ‘MUSE: reviving memories using email archives’, in Proceedings of the 24th annual ACM symposium on User interface software and technology (UIST ‘11). New York, NY: ACM, pp. 75-84. doi:10.1145/2047196.2047206
Harvey, D. R. (2012) Preserving digital materials. Berlin: De Gruyter Saur.
Kahle, B. (1996) ‘Archiving the Internet’. Scientific American, Iss. March 1997. Available at http://web.archive.org/web/19971211123138/www.archive.org/sciam_article.html [Accessed: 27th Feb 2014]
Kawano, H. (2008) ‘Strategy of Digital Contents Archive Based on Reputation Model’, in ICSENG ‘08. Proceedings of 19th International Conference on Systems Engineering, 19-21 Aug, pp. 288-293. doi: 10.1109/ICSEng.2008.75
Kirk, D. S. and Sellen, A. (2010) ‘On human remains: Values and practice in the home archiving of cherished objects’. ACM Transactions on Human-Computer Interaction, vol. 17 (Iss. 3), article 10. doi:0.1145/1806923.1806924
Library of Congress. (2007) Digital Preservation Program Makes Awards to Preserve American Creative Works. [press release] Available at http://www.loc.gov/today/pr/2007/07-156.html [Accessed: 14th Apr 2014]
Lubar, S. (1999) ‘Information Culture and the Archival Record’, in American Archivist, vol. 62 (Iss. 1), pp. 10-22.
Lynch, C. (2000) “Authenticity and Integrity in the Digital Environment: An Exploratory Analysis of the Central Role of Trust’, in Authenticity in a Digital Environment. Washington, DC: Council on Library and Information Resources. Available at http://www.clir.org/pubs/abstract/pub92abst.html [Accessed: 16th Apr 2014]
Masanès, J. (2006) Web archiving. Berlin: Springer.
Mesa, A. F. (1997) ‘The PowerPC Triumph’. The Apple Museum. [web page] Available at: http://applemuseum.bott.org/sections/ppc.html [Accessed: 19th Apr 2014]
Paloque-Bergès, C. (2011) Entre trivialité et culture : une histoire de l’Internet vernaculaire. Émergence et médiations d’un folklore de réseau [Between Triviality and Culture: a History of the Vernacular Internet. Emergence and mediations in network folklore]. PhD thesis, self-published. Available at http://camillepaloqueberges.wordpress.com/phd-thesis/ [Accessed: 6th Apr 2014] 
Paloque-Bergès, C. (2013) ‘Un patrimoine composite : le public Internet face à l’archivage de sa matière culturelle’ [A composite heritage: the Internet public confronted to the archiving of its cultural matter], in I. Dragan, P. Stefanescu, N. Pelissier, J.-F. Tétu and L. Idjeroui-Ravez (eds.) Traces, mémoire, communication. Bucharest: Editura Universităţii din Bucureşti. 2
Pearson, D. (2009) Preserve or Preserve Not, There is No Try: some dilemmas relating to Personal Digital Archiving. [PowerPoint slides]. National Library of Australia Staff Papers. Available at http://www.nla.gov.au/openpublish/index.php/nlasp/article/view/1388 [Accessed: 9th Apr 2014]
del Pozo, N., Long, A. S. and Pearson, D. (2012) ‘Land of the Lost: a discussion of what can be preserved through digital preservation’. Library Hi Tech, vol. 28 (Iss. 2), pp. 290-300. Available from: doi: 10.1108/07378831011047686. [Accessed: 6th Apr 2014]
Ross, S. and Gow, A. (1999) Digital archaeology: rescuing neglected and damaged data resources: a JISC/NPO study within Electronic Libraries (eLib) Programme on the Preservation of Electronic Materials. London: Library Information Technology Centre. Available at http://www.ukoln.ac.uk/services/elib/papers/supporting/pdf/p2.pdf [Accessed: 17th Apr 2014]
Rothenberg, J. (1998) Avoiding Technological Quicksand: Finding a Viable Technical Foundation for Digital Preservation. [report] Washington, DC: Council on Library and Information Resources.
Serrano, H. (2009) Back Up Objects, Héctor Serrano. [web page] Available at: http://www.hectorserrano.com/index.php?id=41&amp;m=lab&amp;grupo=backup [Accessed: 17th Apr 2014].
SINTEF. (2013) ‘Big Data, for better or worse: 90% of world’s data generated over last two years.’ ScienceDaily. [web page] Available at: http://www.sciencedaily.com/releases/2013/05/130522085217.htm [Accessed: 16th Apr 2014]
Swade, D. (1993) ‘The problems of software conservation”, in Computer Resurrection, vol. 7. Available at: http://www.cs.man.ac.uk/CCS/res/res07.htm#f [Accessed: 12th Apr 2014]
Task Force on Archiving of Digital Information. (1996) Preserving digital information, Report of the Task Force on Archiving of Digital Information. Washington, DC: Council on Library and Information Resources.
Thibodeau, K. (2002) ‘Overview of technological approaches to digital preservation and challenges in coming years’, in The state of digital preservation: an international perspective. Washington, DC: Council on Library and Information Resources, pp. 4-31.
UNESCO. (2003) Guidelines for the preservation of digital heritage, prepared by the National Library of Australia. Paris: UNESCO. Available at http://unesdoc.unesco.org/images/0013/001300/130071e.pdf [Accessed: 9 Apr 2014]
Wilkens, K. (2011) Sensor Poetics, Kjenwilkens.com. [web page] Available at http://www.kjenwilkens.com/projects/sensor-poetics [Accessed: 18th Apr 2014]
Zimmer, M. (2010) ‘“But the data is already public”: on the ethics of research in Facebook’, in Ethics and information technology, vol. 12 (Iss. 4), pp. 313-325. doi: 10.1007/s10676-010-9227-5
Zhou, M., Geng, G. and Wu, Z. (2012) Digital preservation technology for cultural heritage. Berlin: Springer.</Text>
            <Comments>The article is only credited to the developer’s pseudonym.
In French.</Comments>
        </Document>
        <Document ID="132">
            <Title>Reducing abstractions</Title>
            <Text>Storing the data locally, in one’s own home — as opposed to an online service — is fundamental. Not only as a protection against online services shutting down eventually, but also as a reassurance by removing the abstraction that lets us access data, remarked by Banks (2011, p. 27):  “I have no idea what kind of hardware my files are now stored or even where they are geographically. I just expect to have access to them as long as I pay my bills.” Ethnographical research shows that this as a concern for most users: “knowing where one’s sensitive digital materials are located is bound to the sense that one is keeping them safe” (Odom et al. 2012a, p.9) and “the ‘materiality’ of digital artifacts is of prime importance for future HCI research” (Odom et al., 2012b).</Text>
            <Comments>This was in the case of the photo storage service Flickr, which offered a premium option back then.</Comments>
        </Document>
        <Document ID="72">
            <Title>Bibliography/Further reading</Title>
            <Text>Hammersley, B. (2012). 64 Things You Need to Know Now for Then,
Hangal, S., Lam, M.S. &amp; Heer, J., 2011. MUSE: reviving memories using email archives, New York, New York, USA: ACM.
Ivonin, L. et al., 2012. Unconscious emotions: quantifying and logging something we are not aware of. Personal and Ubiquitous Computing, 17(4), pp.663–673.
Kirk, D.S. and Sellen, A., 2010. On human remains. ACM Transactions on Computer-Human Interaction, 17(3), pp.1–43.
Massimi, M. &amp; Baecker, R.M., 2011. Dealing with death in design: developing systems for the bereaved. In CHI '11: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. New York, New York, USA:  ACM Request Permissions, pp. 1001–1010.
McCandless, D., 2009. Information is Beautiful, HarperCollins UK.
Olsson, T., Soronen, H. and Väänänen-Vainio-Mattila, K. (2008). User needs and design guidelines for mobile services for sharing digital life memories. Proceedings of the 10th international conference on Human computer interaction with mobile devices and services - MobileHCI '08. Available at: {doi: 10.1145/1409240.1409270} [Accessed 03 Jan 2015]
Taylor, A.S. &amp; Harper, R., 2003. The Gift of the Gab?: A Design Oriented Sociology of Young People's Use of Mobiles. Computer Supported Cooperative Work (CSCW), 12(3), pp.267–296.
</Text>
        </Document>
        <Document ID="47">
            <Title>Objectives</Title>
            <Text>Objectives for my own project

	•</Text>
        </Document>
        <Document ID="124">
            <Title>Reasons for preserving</Title>
        </Document>
        <Document ID="107">
            <Title>Reflection on prototypes</Title>
        </Document>
        <Document ID="73">
            <Title>References</Title>
            <Text>Banks, R. (2010). The 40-Year Old Tweet. [presentation]. 5 February, IXDA interaction10. Savannah, GA: The Theater. Available at: https://vimeo.com/9664533 [Accessed: 09 Jan 2015]
Banks, R. (2011) The Future of Looking Back. Sebastopol: Microsoft Press.
Baym, N. (2010). [Air-L] Library of Congress Acquires Entire (Public) Twitter Archive. [email]. Mailing list of the Association of Internet Researchers. Available at: https://web.archive.org/web/20101225053512/http://listserv.aoir.org/pipermail/air-l-aoir.org/2010-April/021125.html 
Boroditsky, L. (2011). How Languages Construct Time. In: S. Dehaene and E. M. Brannon, eds., Space, Time and Number in the Brain, 1st ed. San Diego: Academic Press, pp.333-341. Available at: doi:10.1016/B978-0-12-385948-8.00020-7(http://dx.doi.org/10.1016/B978-0-12-385948-8.00020-7) [Accessed 7 Dec. 2014].
Chapman, J. (2009). Design for (Emotional) Durability. Design Issues, 25(4), pp.29-35.
ebiz|MBA (2014) Top 15 Most Popular Social Networking Sites | October 2014. [online] Available at:  http://www.ebizmba.com/articles/social-networking-websites [Accessed 17/10/2014]
Evans-Pritchard, E. E. (1940). The Nuer : a description of the modes of livelihood and political institutions of a Nilotic people. Oxford: Clarendon Press. Available at: https://archive.org/details/nuerdescriptiono00evan [Accessed: 29th Dec. 2014]. Chapter III, pp. 94-138.
Everett, N., (2014). Twitpic is shutting down. Twitpic blog. [blog] Available at: http://blog.twitpic.com/2014/09/twitpic-is-shutting-down/ [Accessed 20th October 2014]
Fowler, H. and Burchfield, R. (1996). The new Fowler's modern English usage. Oxford: Clarendon Press, pp. 197–198.
Haynes, C. (2012). How to Map a Life. [Lecture at We Are The Time conference]. Studium Generale Rietveld Academie, Amsterdam.  Available at: https://www.youtube.com/watch?v=wWyKUy0MIJ4 [Accessed: 3rd Dec. 2014].
Haynes, C. (2013a). Drawing Time. [Blog] Thinking in Practice. Available at: http://thinking-in-practice.com/drawing-time-petrie-museum-cathy-haynes [Accessed 6 Dec. 2014].
Haynes, C. (2013b). How do you map a life?. [Blog] The Timekeeper Project. Available at: http://astormisblowing.org/2013/10/11/how-do-you-map-a-life/ [Accessed 6 Dec. 2014].
Haynes, C. (2014a). What would life be like without the word Time? [Blog] Stereochron Island. Available at: http://stereochron.org/post/93491431833/what-would-life-be-like-without-the-word-time [Accessed: 21st Dec. 2014]
Haynes, C. (2014b). Four Geometries of Time. A storm is blowing. [blog] http://astormisblowing.org/2014/03/24/four-geometries-of-time/ [Accessed: 27 Oct. 2014] &gt;&gt;&gt;&gt; Convert other one to 2014a
Hornung, E. (1999). The ancient Egyptian books of the afterlife. Translated by D. Lorton. Ithaca, N.Y.: Cornell University Press. p. 78.
Hutton, L. and Henderson, T. (2013). An architecture for ethical and privacy-sensitive social network experiments. SIGMETRICS Performance Evaluation Review, 40(4), pp.90–95.
Julius, M. (2014). [Blog] Multimedia Memories. Available at: http://multimedia-memories.tumblr.com/ [Accessed 2 Oct. 2014].
Julius, M. (no date). Remembrance Value of Topics in Social Media. [online] pp. 6, 12. Available at: https://dl.dropboxusercontent.com/u/24440204/remembrance_value_of_topics_in_social_media.pdf [Accessed 12 Oct 2014].
Kopytoff , V. (2013) 5 worst Internet acquisitions of all time. Fortune. [online] Available at: http://fortune.com/2013/05/21/5-worst-internet-acquisitions-of-all-time/ [Accessed 21st Oct. 2014]
Lewis, R. (2014). How Different Cultures Understand Time. Business Insider. [online] Available at: http://www.businessinsider.com/how-different-cultures-understand-time-2014-5 [Accessed 22 Dec. 2014].
Library of Congress (2010). How Tweet It Is!: Library Acquires Entire Twitter Archive. [Blog] Library of Congress blog. Available at: http://blogs.loc.gov/loc/2010/04/how-tweet-it-is-library-acquires-entire-twitter-archive/ [Accessed 21 Oct. 2014].
Lidwell, W., Holden, K. and Butler, J. (2010). Universal Principles of Design: 125 Ways to Enhance Usability, Influence Perception, Increase Appeal, Make Better Design Decisions, and Teach through Design. Berverly, MA: Rockport Publishers, p. 100. 
Lipton, D. (2005). Reviewed Work: Time and Process in Ancient Judaism by Sacha Stern. Bulletin of the School of Oriental and African Studies, University of London, [online] 68(1), pp. 103-104. Available at: http://www.jstor.org/stable/20181858 [Accessed 30 Dec. 2014].
Loux, V. (2014). Literature Review: Digital Preservation. [essay]. DJ32004 Research and Creative Practice Part 1, University of Dundee.
Martin, B. and Hanington, B. (2012). Universal Methods of Design: 100 Ways to Research Complex Problems, Develop Innovative Ideas, and Design Effective Solutions. Beverly, MA: Rockport Publishers, pp. 17, 32, 74, 156.
Materialising Memories (2014). [Blog]. Available at: http://www.materialisingmemories.com/updates/ [Accessed 2 Oct. 2014].
Moncur, W. &amp; Kirk, D., 2014. An emergent framework for digital memorials. In DIS '14: Proceedings of the 2014 conference on Designing interactive systems. New York, NY:  ACM, pp. 965–974.
Museum of Moving Image. (2012) Under Construction. [online] Available at: http://www.movingimage.us/exhibitions/2012/12/04/detail/under-construction/ [Accessed 21st Oct. 2014]
Odom, W., Banks, R., Kirk, D., Harper, R., Lindley, S. and Sellen, A. (2012a). Technology heirlooms?: considerations for passing down and inheriting digital materials. CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. New York, New York, USA:  ACM, pp. 337–346. Available at: {doi: 10.1145/2207676.2207723} [Accessed 17 Sep 2014]
Odom, W.,  Sellen, A., Harper, R. and Thereska, E. (2012b). Lost in translation: understanding the possession of digital things in the cloud. CHI '12: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. New York, New York, USA:  ACM, pp. 781-790. Available at: {doi: 10.1145/2207676.2207789} [Accessed 03 Jan 2015]
Petrelli, D., Whittaker, S. and Brockmeier, J. (2008). AutoTopography: what can physical mementos tell us about digital memories?. Proceeding of the twenty-sixth annual CHI conference on Human factors in computing systems - CHI '08. Available at: {doi:10.1145/1357054.1357065} [Accessed 12 Dec 2015]
Rendgen, S. et al., 2012. Information Graphics, Taschen America Llc.
Rosenberg, D. and Grafton, A., 2010. Cartographies of Time, Princeton Architectural Press.
Santiago, J., Lupáñez, J., Pérez, E. and Funes, M. (2007). Time (also) flies from left to right. Psychonomic Bulletin &amp; Review, [online] 14(3), pp.512-516. Available at: http://dx.doi.org/10.3758/bf03194099 [Accessed 22 Oct. 2014].
Scott, J. (2009) Datapocalypso!. ASCII by Jason Scott. [blog] Available at: http://ascii.textfiles.com/archives/1649 [Accessed 20th October 2014]
Scott, J. (2009). Geocities. [Blog] ASCII by Jason Scott. Available at: http://ascii.textfiles.com/archives/1956 [Accessed 21 Oct. 2014].
Scott, J. (2014). The House is on Fire, the Fire Trucks are on Fire, The Fire is on Fire. [presentation]. 19 June, CALI 2014. Cambridge, MA: Harvard Law School. Available at: https://www.youtube.com/watch?v=qh7EARxkxoU [Accessed: 28th October 2014].
Scott, J. (no date). A History of Jason Never Shutting Up. [videos] ASCII by Jason Scott. Available at: http://ascii.textfiles.com/speaking [Accessed 1 Nov. 2014].
Stereochron Island (2014). [Blog] Available at http://www.stereochron.org [Accessed: 24 Oct. 2014]
Stern, S. (2003). Time and Process in Ancient Judaism. Oxford and Portland, Oregon: The Littman Library of Jewish Civilization. p. 127.
Sterne, L. (1761).  The Life and Opinions of Tristram Shandy, Gentleman. [ebook]. Reprint, Salt Lake City: Project Gutenberg, 2012. Available from: http://www.gutenberg.org/ebooks/39270 [Accessed: 7th Dec. 2014]. pp. 347-348 (Book IV, chapter XL).
Strass, J. F. (1810). Descriptive Guide to “The Stream of Time,” or, General Outline of Universal History, Chronology, and Biography, at One View. 4th ed. Translated by W. Bell. London. Available at: http://access.bl.uk/item/viewer/ark:/81055/vdc_100023107350.0x000011 [Accessed 21 Dec. 2014]. pp. 8-10.
The Archive Team (2014). Why back up?. [online] http://archiveteam.org/index.php?title=Why_Back_Up%3F [Accessed 20th October 2014]
The Timekeeper Project (2013). [Blog] Available at http://www.astormisblowing.net [Accessed: 22 Oct. 2014]
Weger, U. and Pratt, J. (2008). Time flies like an arrow: Space-time compatibility effects suggest the use of a mental timeline. Psychonomic Bulletin &amp; Review, [online] 15(2), pp.426-430. Available at: http://dx.doi.org/10.3758/pbr.15.2.426 [Accessed 18 Oct. 2014].
Willard, C. (2012). The three worst-timed deals of the dot-com bust. Marketwatch. [online] http://blogs.marketwatch.com/cody/2012/04/17/the-three-worst-timed-deals-of-the-dot-com-bust/ [Accessed 21st Oct. 2014]
Wurman, R. S. (1989). Information Anxiety. New York, NY: Doubleday.
Whittaker, S. &amp; Sellen, A., (2010). Beyond total capture: a constructive critique of lifelogging. Communications of the ACM, 53(5).
</Text>
            <Comments>The page and ranking is updated monthly; a snapshot of the page at the date it was accessed is available at https://web.archive.org/web/20141007035034/http://www.ebizmba.com/articles/social-networking-websites</Comments>
        </Document>
        <Document ID="141">
            <Title>Untitled</Title>
        </Document>
        <Document ID="48">
            <Title>Backing up social networks</Title>
        </Document>
        <Document ID="133">
            <Title>A note about the draft</Title>
            <Text>This draft lacks important parts to it. Obviously, the outcomes of the interviews as they aren’t done yet, but parts of the context are also missing and possibly in the wrong order. Due to a heavy workload in the past weeks with deliverables with the honours project, I couldn’t finish it as much as I wanted to.
It is particularly worth saying that the literature review chapter is much longer than it will be in the final dissertation. It includes a lot of elements from the first draft of my literature review last semester that have been omitted in the final version, and new sections about individual backups. This puts this chapter at around 6,000 words, but it will be edited down to 2,000—2,500 words. As a result the chapters about context and methodology are much less developed, and for now it is mostly a structure with titles, synopses and notes for each section, which will be ultimately expanded to make up about 2,000 words each. Notes in redacted sections are generally marked [within square brackets].</Text>
        </Document>
        <Document ID="108">
            <Title>Reflection on experiments</Title>
        </Document>
        <Document ID="74">
            <Title>Introduction</Title>
        </Document>
        <Document ID="125">
            <Title>Growth of data</Title>
            <Text>The amount of data being produced digitally is growing  exponentially (SINTEF, 2013), and with this growth comes a greater volume of data worth archiving over the long term (Harvey, 2012, p. 33). However, the preservation of digital materials cause much more issues than traditional preservation paradigms; where we can consider that for paper and physical artefacts, “benign neglect may be the best treatment” (derived from Cloonan (1993, p.596), Harvey (1993, pp.14,140), and Bastian, Cloonan and Harvey (2011, pp.612–613)). </Text>
        </Document>
        <Document ID="150">
            <Title>Process-related</Title>
            <Text>Haynes (2014a) encourages us to stop trying to use units, and points out the works of Sasha Stern and Evans-Pritchard, who respectively analysed the ancient Jews’ and the Nuer’s ways of constructing time in their day-to-day thinking.
Stern believed that in ancient Judaism, for those speaking Hebrew and Aramaic, “the notion of time as an entity in itself, a human resource, a continuous flow, or a structure of dimension of the created world, [is] simply non-existent” (Stern, 2003, p. 127, cited in Lipton, 2005). While some considered that this belief was naïve (Lipton, 2005), it would be hard to argue that their perception of time was completely different from ours. Like the Nuer, they used events, processed and activities as points of reference for describing time, as opposed to units such as calendar dates, relative dates (two days ago)  and hours of the day. The “irregular, multiple, parallel phases are defined by the events they describe” (Haynes, 2014a), and not by these units. In the case of the Nuer, Evans-Pritchard writes that while names existed for months, they were seldom used and their day-to-day thinking was radically different.
“Nuer […] generally refer instead to some outstanding activity in process at the time of its occurrence, e.g. at the time of early camps, at the time of weeding, at the time of harvesting, &amp;c., and it is easily understandable that they do so, since time is to them a relation between activities. […] People indicate the occurrence of an event more than a day or two ago by reference to some other event which took place at the same time or by counting the number of intervening 'sleeps’.” (Evans-Pritchard, 1940, p. 100)
And as Haynes (2014a) reminds us, “vestiges of this are left in our language: the blink of an eye, the shake of a lamb’s tale, moons ago, the crack of dawn”.</Text>
            <Notes>“Though I have spoken of time and units of time the Nuer have no expression equivalent to 'time' in our language, and they cannot, therefore, as we can, speak of time as though it were something actual, which passes, can be wasted, can be saved, and so forth. I do not think that they ever experience the same feeling of fighting against time or having to coordinate activities with an abstract passage of time, because their points of reference are mainly the activities themselves. […]  Events follow a logical order, but they are not controlled by an abstract system, there being no autonomous points of reference to which activities have to conform with precision.”
(Evans Pritchard p 103)</Notes>
        </Document>
        <Document ID="49">
            <Title>Sustainable system</Title>
            <Text>One of the greatest challenges in designing such a system is to make an object that is sustainable, and that can last for several decades. It should be possible to upgrade and renew the item without any loss to the content; as recommended by Richard Banks to me, use strong technology (looking at embedded systems, and components with no moving parts such as solid state drives), and consider open sourced design and software, by openly releasing the plans and code for accessing the data externally, so that it can be used and maintained even if the manufacturing organisation disappears after several years or decades.</Text>
        </Document>
        <Document ID="117">
            <Title>Manual curation</Title>
            <Text>Another interesting selection process that has emerged is the one of specific archiving when certain events are happening. For instance, the UK Web Archive[ukwa] has, on top of their topical-based collections (Energy, Health and Social Care...), a few event-based collections (Queen Jubilee, Olympic and Paralympic Games, London 2005 terrorist attacks...) which reflect the state of the Web at that given moment in history. Masanès (2006, p.83) notes that this type of archiving must be manually curated and thoroughly preparated. He gives a methodology for this, using presidential elections as an example: a time frame for the collection must be defined (“3 months before the election + 1 month after”), what type of sites will be archived and when (“the political parties’ blogs and websites, every week; analysis, commentary and humourous/satire websites, every month; online newspaper articles, once”).</Text>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="75">
            <Title>Need for preservation</Title>
            <Synopsis>Growth of data produced
What is archive
Give ~opinion~ and analysis
</Synopsis>
        </Document>
        <Document ID="142">
            <Title>Acknowledgements</Title>
            <Text>I am indebted to the work and help of a few key people which have pointed me to extremely valuable sources, and that helped me in setting more precise objectives and gaining valuable outlooks for both my honours project and my dissertation. Kay Orzech and Miriam Julius here at Duncan of Jordanstone; the latter’s research blog  (Julius, 2014); the research blog of the Materialising Memories (2014) team, led by Elise van den Hoven; the research blogs of Cathy Haynes, artist (The Timekeeper Project, 2013 and Stereochron Island, 2014) and the talks of Jason Scott (n. d. and 2014), technology archivist.
Thanks to Katrina Gorkovenko, PhD student at Duncan of Jordanstone and alumni of the DIxD course, for recommending me the approach of generative research during Gurus’ Days, as she thought it would provide very valuable insights to encourage users to design their own for this particular issue.
+ Thanks to the participants of my workshop for their time.
+ R Banks during Show &amp; Tell</Text>
        </Document>
        <Document ID="134">
            <Title>J Evaluation: Results table</Title>
            <Text>[table of raw results]

Mention that to respect confidentiality, participants IDs were swapped between each sheets to avoid cross-tabulation of results.</Text>
        </Document>
        <Document ID="109">
            <Title>Evaluate them</Title>
        </Document>
        <Document ID="116">
            <Title>Automatic selection (Reputation model)</Title>
            <Synopsis>How to curate by popularity on SNS (likes, comments, shares)</Synopsis>
            <Text>In order to keep the most valuable content, algorithms could be used. Kawano (2008) proposes to use reputation models, that attempts to determine the relative value of a Web page by considering its “importance, fairness, trustiness, uniqueness and valuation”. This is done using a variety of ways; the algorithm suggested by Kawano relies on the consistency of a web page, that is the amount of time it existed, the number of links it contains and the number of external links to this page (Kawano, 2008, p. 291).</Text>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="76">
            <Title>Threats to digital continuity</Title>
        </Document>
        <Document ID="126">
            <Title>MUSE example</Title>
            <Text>An attempt has been made by the MUSE (Memories USing Email) project (Hangal et al., 2011), which aims to find patterns in our emails archives to help us make sense of this large data set. As the authors note in the introduction:
“Email has become a de facto medium of record; many people consciously deposit important information into email, knowing they can look it up later, and thereby use their email account as an informal backup device. Therefore, email archives contain or reflect memories that are extremely valuable for the purposes of reminiscence.” (Hangal et al., 2011)
Early users reported that they have been using it to: make a summary of their work progress over the year; extract and organise certain type of data (for instance, the personal out of the professional, or the important out of the more mundane); finding life milestones inside family emails; picking up work that’s been left unfinished and forgotten; renewing with old relationships; and serendipitous discovery. The authors note in the conclusion that the different uses of their program went beyond their original expectations of simply reminiscing: “the stories above include an example of each one of the ‘5R’s’ described by Sellen and Whittaker (2010): recollection, reminiscing, retrieving, reflecting, and remembering intentions. Further, it suggests that browsing and remembering the past can affect the future.”</Text>
        </Document>
        <Document ID="151">
            <Title>Untitled</Title>
        </Document>
        <Document ID="118">
            <Title>Selection by genre</Title>
            <Synopsis>Rewrite by social network</Synopsis>
            <Text>There are different genres of websites: institutional website, blogs, personal pages, forums. [[Genre have been studied in the context of the Web to see how they replicate or diverge from the genre in the print- ing world (see Crowston and Williams 1997) - in Masanès p88]]. An interesting point about this is that often, robots (crawlers, or later data analysis) can automatically identify their type [Rehm 2002 -&gt; check reference, Masanès:88] which permits the automatic generation of metadata, or simply to restrict a collection of web pages to certain Web genres.</Text>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="143">
            <Title>Style note</Title>
            <Text>The word data, in this dissertation, will generally refer to the computing term for information, as a singular mass entity. I have therefore deliberately used it in the singular, as recommended by the new Fowler’s modern English usage (1996).</Text>
        </Document>
        <Document ID="77">
            <Title>Who should preserve (?)</Title>
            <Synopsis>Explain why stakeholders should be the ones preserving and not rely on external services</Synopsis>
            <Notes>Parrallel between generic &amp; personal stuff, that is museums/archives vs personal storage
</Notes>
        </Document>
        <Document ID="135">
            <Title>Lecture</Title>
            <Text>
How do we even think about time, as people? That’s an odd question, but it’s also quite an interesting one for my project, because I need to visually represent time to represent the events happening in a life. And when you try to picture time, you transform time into space, which means it’s no longer time. So the most natural way, for us raised in a Western culture, is this…

# Timeline

A line. It’s a very simple, linear way of looking at time, it’s is logical order of when things happened, In terms of space, it’s a movement, that goes from the past, behind us, and the future, ahead of us. **[next slide]** The timeline on a single line is a very convenient thing because we can map units to it, all the same size, from years to minutes. And so, we’re very used to it. That’s how we’ve been taught history at school, that’s how we organise our CVs, that’s precisely, how social networks show content on a profile; your Twitter or Instagram timeline, or your own profile on Facebook is displayed, except it’s vertical instead of horizontal, the present at the top and the past below. It’s also used as another metaphor on computers…

# Progress bar

The progress bar. Same principle. Left: you’re at the start. Here: you’ve made some progress, you’re this close to the end. Right: there you are, you’re at the end. Simple. The very interesting thing about this is the name. **Progress** bar. We’re progressing from start to finish in terms of time. That notion of progress is very important for the timeline, keep that in mind, I’ll come back to it later. It’s actually what’s created it. The timeline as we know it, this one **[1 slide before]**, is only 250 years old. That model is very natural for us, but it’s actually a very cultural and somehow novel thing to have this single line, straight X axis with events on it that goes from left to right.

# A cultural thing

The origin of this direction, this movement, actually comes from reading. When we read, the upcoming information is on the right; in a sentence, or in a book, you make progress in the book. It’s an important thing to note because it’s very Western to think like that. Speakers of languages that are read from left to right, actually think of time in a left-to-right manner. There’s been studies *[Tversky, Kugelmass, and Winter 1991]* that asked Arabic and Hebrew speakers to order stickers, for example breakfast, lunch and dinner, or pictures from a person from younger to older, and they put it right-to-left, whereas English speakers did the reverse. And even in software, if you open software in Arabic, you’ll see that the progress bars are reversed.

On a side note, interestingly, there’s been other studies that have been done with some aboriginals from Australia, the Pormpuraaw community, and their languages do not have words for left or right. They tend to use absolute space directions like North, South, West, East for everything. So for example they would say “move your cup to the north-west a little bit”, or “the boy standing on the south of Mary is my brother”. They have amazing abilities to know which way they’re facing. And so researchers have been interested to know how they think about time, because they don’t have the same cultural idea of left or right to go further. When they’ve been asked to order things, instead of putting them right to left in front of them, they lay the stickers down and been ordering them from east to west, just like the sun, from morning to evening. 

# Cultural differences 2 (down arrow)

But it’s not just the writing direction. Mandarin speakers tend to think of time vertically, more often than we do, even though modern Chinese is read in rows not columns, but their conception of movement is also different — they see a moving timeline and a static observer, whereas we tend to visualise ourselves moving in the static timeline. Speakers of the Aymara language, in South America, think of time from left to right, like Arabic speakers, even though the language reads right-to-left; this is because they see the past as being in front of them, something that they can look at, whereas the future is in their back, it is the unknown, what you cannot see. [Lera Boroditsky, How Language constructs time]. 
+ link to how everyday language in English carry these notions of representing time as well (before, after, long and short times, intervals [spaces in between], move an appointment two hours *back*, the clock is 5 minutes *fast* (movement) or *ahead*, we have lunch in the middle of the day, implying that day is a line when it’s more accurately a circle) [source: Cartographies of Time 2010]

So. Even in the modern, current world, people tend to think of time in very different ways, different directions, different ideas of motion, for different reasons. 

# Ouroboros

Sometimes it’s not just a straight line. We can often find that famous Egyptian symbol, the Ouroboros, a snake or a dragon eating its tail, to represent the fact that time can be thought of as a recurring cycle, instead of something linear, with a start and with an end. Today we mostly use this representation for the dial of a clock, because days are easy to visualise as something that repeat themselves. And it’s perfectly natural; the Earth rotates continuously around the Earth, that representation actually comes from sundials. [It’s interesting because we don’t do the same thing when we pick up a calendar — personally when I think of the months, I have a straight line going from January to December but it’s not a circle even though it’s recurring.]

What’s interesting about this idea, it’s that Mayan and Pagan traditions visualised history and life as something like that. For life, they didn’t see birth as a new start and death as an end, just something that kept going. [If that helps with the concept, in the Balinese language, the word for grandparent and grandchildren is the same (kumpi). They see lives as continuations of someone else’s.]

Overall, from the research I’ve made, no matter which culture, our graphical representations of time are always a line, or a circle. The direction may change, the perception in terms of movement changes, but it’s still based around a line. What can change is the way we put events on it. There can be several dimensions to it. There can be several parallel lines. There can be streams of events merging and separating.

# The history of the timeline

18 - Genealogical tree, descendants of Noah’s son Japhet [Hartmann Schedel]
19 - record of English history from Alfred the Great (871–99) to Henry III (1216–72),
[Peter of Poitiers] (13th century)
20 - 1475 Epitome of chronicles and histories
21 - [twelfth-century] Joachim of Fiore - biblical past, Christian present, and a transformed future into a single, complex vision
22 - [16th century] Johann Funck’s - historical calendar, great events of Old and New Testament history
23 - paper chart with a pivoting central arm. Rings representing kingdoms and radial wedges representing centuries. The names of kingdoms are printed on the moveable arm. 
24 - [Johann Georg Hagelgans] 1718 - maintained the familiar historical matrix in the background, his enormous charts burst through everywhere with images, maps, and data.
25 - 1769 [Joseph Priestley] - A New Chart of History.  **Regularized the distribution of dates**.
26 -  Girolamo Andrea Martignoni - Historical map of Italy, 1721 - like a map, rivers and land masses turn out not to be landscape features but temporal metaphors —territories of history and rivers of time. [The streams at the top of the chart represent the nations conquered by the Roman Empire; those at the bottom, the nations that emerged from it; and the great lake at the center, the empire itself.]
27 -  Edward Quin’s An Historical Atlas, [1828]. Quin’s maps showed how the political world was divided up at different moments of history, and, through
the device of clouds rolling back, he indicated how much of the world was known to the West at each stage in history.
28 - Friedrich Strass [1804] Strom der Zeiten
29 - [Richard Cunningham Shimeall] - 1833 - radial columns represent centuries from the Creation to the Apocalypse.
30 - Wallis’ New Game of Universal History and Chronology [1840]. Such events as the first use of paper in England, the invention of engraving, and the discovery of longitude.
31 - Emma Willard’s Temple of Time from 1846 - standing columns represent centuries: those on the right are emblazoned with the names of important historical figures of the old world, those on the left, of the new. The floor shows a historical stream chart. The ceiling functions as a chart of biography.

So after all that you’re probably wondering…

# WHERE AM I GOING WITH ALL THIS 
also when’s the cake

My point is that there’s there’s several things happening at the same time, and more importantly that
# A life doesn’t look like this
But more like this **[next slide]**
The inventor of the timeline himself, Priestley, recognised that “historical narrative is not linear. It **moves backward and forward making comparisons and contrasts, and branches irregularly following plots and subplots**. […] The form of the timeline emphasises overarching patterns and the big story.” The timeline is a “great mechanical help to know history, but is not an image of history itself”. *[Cartographies of Time p.20]*

# Progression

Before the straight timeline, people didn’t see the future as being necessarily progressive. In the 1620s, Francis Bacon changed that and thought that the **technological and scientific revolutions would mean we would keep perfecting ourselves and the nature. Things always keep getting better as technology and democracy advances.** That’s the reasoning behind the timeline, and by extension, the progress bar that I’ve shown you before: the further we get on the line, the more progress we’ve made. 

**But that’s not necessarily true of our lives.** They’re not just advancing like that, they’re much more complex, like history. And if we try to visualise our life linearly, if we put too many measurements, it’s not a true picture of our life. We could do it, but I don’t think that’s ambitious, because memories link to each other and that’s how they make sense, that’s what makes them valuable. And I think overall, when we try to map out the complexity of everything that’s happened in our life, it’s more interesting to look back not at the big picture and think in terms of time units, years, months, but in terms of moments, what’s important and what’s not.
</Text>
        </Document>
        <Document ID="160">
            <Title>Results</Title>
        </Document>
        <Document ID="127">
            <Title>Copying/backup</Title>
            <Text>The second advantage, the ability to accurately and easily make copies and backups, is fairly obviously an advantage for personal preservation. However, Banks (2011) notes, the process of backing up is troublesome and storage media do not make our data immune. Additionally, the use of online services to store our data creates an abstraction between the storage material and us; about Flickr: “I have no idea what kind of hardware my files are now stored or even where they are geographically. I just expect to have access to them as long as I pay my bills” (Banks, 2011, p. 27).</Text>
        </Document>
        <Document ID="78">
            <Title>How to preserve</Title>
        </Document>
        <Document ID="152">
            <Title>Spatial model of timeline</Title>
            <Text>Time itself is not a concept that can be visualised. Whenever we think about time, we actually transform it into space in order to picture it in our minds. The most natural way, for us, is to visualise an arrow going like the one in [fig. 3.1].
[fig. 3.1]
It goes into the realm of space because it is a movement; the past is behind us and goes to the future, ahead of us. This idea of movement is repeated in our everyday language (Weger and Pratt, 2008, p. 426 and Boroditsky, 2010, p. 334); we use the words before, after, we have times that are short and long, we have intervals (literally, spaces in between) between two times; watches can be 5 minutes fast or ahead, and calendars and clocks make us think of time on segments with a start and an end (the beginning of the month, the middle of the day). Most social networks present our post history using a reverse timeline; newer posts at the top, older posts at the bottom.
However, languages vary and research has shown that different cultures and languages have a different mental representation of time, visually, and that this idea of a line going from left to right is in fact a cultural, nurtured interpretation of time that we have as Westerners, but is not innate.
</Text>
        </Document>
        <Document ID="119">
            <Title>Digital heritage</Title>
            <Text>A rare exception to this is Digital Heirlooms, a series of prototypes developed by Microsoft Research (Odom et al., 2012) to investigate how digital memories can be passed down and inherited. As the name implies, these conceptual objects were regarded as equivalents to photographic albums and diaries that can be passed down between generations. The three prototypes showed backups of Twitter,  locally-stored photographs, and Flickr [fig. 1.3].
[fig 1.3]
The testing of these prototypes with users revealed that while the experience was positive and led to engaging conversations in the families, doubts were raised on the recording of social networks:
“these instances highlighted tensions around integrating social networking content from members within the collective family archive. Participants made key distinctions between the thoughtful recording of one's life believed to be reflected in their ancestors' diaries, and their own practices of posting less mindful social networking content targeted at multiple audiences, often outside of the family.” (Odom et al., 2012a)
The question of privacy was also important. Users desired the have the ability to curate what was and wasn’t kept:
“Related concerns also emerged around how a device like BackupBox could cause family members to self-censor the social networking content they posted, or paralyse these practices completely. Some families proposed ways to work around these tensions, such as using a special hashtag or a specific application to send updates only to Backup Box.” (Odom et al., 2012a)
As Moncur (2014) also noted, Web 2.0 sites have largely changed the audience and publicity of memorials, and the ability to curate how one would like to be remembered is important. These insights encouraged me to focus first on designing for the users themselves, rather than exploring the much deeper question of digital heritage. While the idea behind these prototypes (particularly Backup Box, the Twitter archive) are close to my honours project idea, they did not fulfil the same goals. By being too conceptual and technologically fragile, they would not withstand decades of use; their representation of time was simplistic and linear, and not adapted to very large-scale archives; and the mindset going into designing and testing these was for heirlooms, in a family setting. The preliminary ethnographical research in this study, though, was very rich in insights for understanding how artefacts, sometimes valueless, become sentimentally important heirlooms (Odom et al, 2012a; see also Banks, 2010 and Petrelli et al., 2008).</Text>
        </Document>
        <Document ID="144">
            <Title>Table of Contents</Title>
        </Document>
        <Document ID="79">
            <Title>Methods for software preservation</Title>
        </Document>
        <Document ID="136">
            <Title>Questions asked</Title>
        </Document>
        <Document ID="161">
            <Title>Retrieval of memorable content</Title>
            <Text>In this task participants were to go on their Facebook account, using either their laptop, tablet or mobile phone, and retrieve 3 pictures that made them smile, or that stuck in their mind for any particular reason. The full methodology and motives for this activity are explained in [appendix D], and a table of the raw results can be read in [appendix E].
The results of this activity were divided. For two thirds of the pictures, people knew on which profile to look; they associated, in their memory, the picture with the person who posted it. In over half of these cases, they knew exactly in which photo album it was (as albums are generally unique per particular event or date, or they were in the special profile/cover pictures album); in the remaining cases, they had to browse through a few albums to find the photo they were thinking about. Only one photo was sent in private message.
For six photographs, the participants did not know in which album it was, and instead scrolled down the users’ timeline until they found the picture. One other browsed the timeline but used the links to access a specific time period, knowing when the photo was posted. Two photos could not be found at all; either by not remembering where it was located, or by remembering where it was located but could not find it there.
Of the 27 (9⨉3) times a photo has been searched, 12 times it was considered a laborious process, and 11 times participants have had no trouble finding it. Two times it was considered really hard to find it, and in the last two cases the photo wasn’t found at all. The most interesting insights we can get from this activity are by comparing the experience of retrieval with the process used. In the 14 times the retrieval was considered either “laborious” or troublesome, none of them was for “I went to the profile and knew which [album] it was in”; this happened only when the exact location of the item was not known precisely, and some research through the albums, timeline or message history had to be done first. This isn’t exactly surprising (having to spend longer on finding a picture means it is more laborious than finding it straight away) but the amount of times this happened demonstrates that our ability to find data is limited to the amount of “metadata” that we have stored with it: most people knew which friend this memory was linked with, but less than half could remember in which “box” it was stored on the social network. This indicates that more levels of classification and sorting must be available when browsing a large archive; for example, being able to know which other friends were tagged with it, at which period it happened, and possibly where it happened, if the content is geotagged.</Text>
        </Document>
        <Document ID="128">
            <Title>Indexing &amp; cataloguing</Title>
            <Text>The first one, ease of organisation, can be significantly helpful in tackling the abundance of digital data. Banks (2011) suggests that the technologies lying behind the ranking in the result of Web search engines could, eventually, help us in understanding and finding what is our most important data.</Text>
        </Document>
        <Document ID="153">
            <Title>Conclusion</Title>
        </Document>
        <Document ID="170">
            <Title>Workshop results</Title>
            <Text>￼￼￼￼￼￼￼Retrieval process
￼p1
￼p2
￼p3
￼p4
￼p5
￼p6
￼p7
￼p8
p9
AVERAGE
I went to the profile and...
￼￼x
￼x
x
3
I went to the profile and kept scrolling down until I found it in the feed
￼x
x
x
3
I went to the profile and used the Timeline links on the right to access a time period
x
1
I went to the profile and knew it was in their profile/cover pictures, so I clicked there directly
x
￼x
2
I went to the profile and directly browsed the albums
x
1
... I knew which one it was in
x
x
x
￼x
x
x
￼x
x
8
... I had to go through a few albums to find it
x
x
￼x
￼x
x
x
6
I used Facebook’s search engine to find the album or post
0
I searched in my browser history
0
I searched in my messages history
0
... it was a shared link
0
... the photo was sent privately (in the messages)
x
￼1
I searched my inbox for the relevant Facebook notification emails
0
I asked someone to send me a link to it
0
I had a picture in mind but I can’t remember where it was
x
1
I had a picture in mind and knew where it was, but I couldn’t find it/it’s been deleted
x
1
Experience
Works fine
x
x
x
x
x
x
x
x
x
x
x
11
Laborious
x
x
x
x
x
x
x
x
x
x
x
x
12
Had trouble finding it
x
x
￼2
Couldn't find it at all
￼0
Wasn't where I thought it was
x
x
￼2
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼
￼￼￼￼￼￼￼￼What do you use social media for?
(grades range from 1 to 10)
p1
p2
p3
p4
p5
p6
p7
p8
p9
Total
Keep friends up to date
1
7
9
5
9
5
6
7
9
￼6.44
Preserve things that affect me emotionally
1
6
1
1
5
1
2
1
5
2.56
Stimulate friends to think about certain topics
5
4
5
6
1
1
1
7
5
3.89
Satisfy a spontaneous need for communication
1
5
9
5
1
5
5
7
9
5.22
Get attention for my projects
1
5
9
1
5
5
9
6
5
5.11
Define my reputation
1
2
9
8
1
5
5
7
1
4.33
Chat with friends
5
9
9
6
9
9
8
9
9
8.11
Follow news of friends
5
9
9
1
9
9
9
8
9
7.56
General attention
1
3
9
8
1
1
4
7
5
￼4.33
Keep in touch with friends far away
5
9
9
8
9
5
5
9
9
7.56
Use groups for school/work/activities
9
9
9
1
9
9
10
8
9
8.11
Follow celebrities or brands
1
2
5
1
4
5
1
5
5
￼3.22
Follow networks about general news and current affairs
5
3
5
5
5
9
6
7
1
5.11
Follow content about my domain (blogs, magazines, communities)
1
2
9
6
5
9
9
5
1
5.22
Leisure activities
5
2
5
1
5
5
8
3
1
￼3.89
Be part of the community
9
6
5
1
5
5
5
4
9
5.44
No specific goal
9
5
1
3
5
1
7
5
5
4.56
How long do you think Facebook will stay popular before being replaced by something else?
10
10
5
?
5
10
10
5
2
7.125
Would you be willing to manually curate the archive of your social networks to organise it?
- Yes, every few weeks, so that I can keep a fresh eye on what’s important
x
￼1
- Yes, every year or so, that’d allow me to look back
x
x
x
x
x
x
x
￼7
- Yes, less often, when I think of it
￼0
- No, I’d prefer the curation to be done automatically, even if that means it is less accurate
x*
x
￼2
- No, I think a standard timeline is better than these alternative representations
0
- No, I would not be interested in your product anyway
0
* although if sth was missing, they would like to be able to manually fix this.
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼Cartography p1 p2 p3 p4 p5 p6 p7 p8 p9 AVERAGE CREBCREBCREBCREBCREBCREBCREBCREBCREBC R E B
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼1 2 3 4 5 6 7 8 9 10 11 12 13
513 ￼ ￼ 5 5 1 5 5 3 4 3 2 4 3 3 4 3 4 3 5 5 5 5 5 2 4 4 4 2 2 2 4 2 3 1 5 3.44 3.00 3.22 4.33 432 ￼ ￼ 4 3 4 2 3 4 4 3 5 4 3 3 3 2 4 4 5 3 3 5 5 4 4 4 4 3 4 4 5 4 4 4 2 3.44 3.67 3.44 4.00 232 ￼ ￼ 3 1 3 1 5 3 2 2 4 1 2 1 4 1 1 1 3 1 3 3 5 1 2 2 1 4 4 4 5 2 2 1 3 1.78 2.44 1.89 3.67 432 ￼ ￼ 3 5 5 5 5 4 1 3 4 5 4 2 3 5 2 4 5 5 5 5 5 1 1 1 3 5 5 5 5 1 3 2 4 3.89 3.22 3.22 4.11 443 ￼ ￼ 4 3 3 1 1 5 4 5 5 5 5 1 4 5 5 4 3 5 5 5 3 5 5 5 3 5 5 5 5 5 4 3 5 4.67 4.44 3.56 3.67 232 ￼ ￼ 3121345333412131315334433555513212.443.782.332.89 231 ￼ ￼ 1 4 4 1 5 3 3 3 4 3 5 3 1 1 2 1 5 3 3 3 3 2 1 2 4 2 4 5 5 1 2 3 1 2.33 3.00 2.44 3.22 313 ￼ ￼ 2213154511111244113312121555111412.442.333.331.11 112 ￼ ￼ 5333522443335123353532131344542442.672.333.443.89 533 ￼ ￼ 2554533325434444511353333555554554.003.563.674.00 322 ￼ ￼ 3444334134221335311132224354443253.002.892.563.22 121 ￼ ￼ 3253512141211333553552122445512312.222.672.673.44 333 ￼ ￼ 2555545435545535533335544444452554.333.894.114.00
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼C Clarity
R Relevance E Efficiency B Beauty
Grades range from 1 to 5.
</Text>
        </Document>
        <Document ID="145">
            <Title>Front matter</Title>
        </Document>
        <Document ID="137">
            <Title>Drawings</Title>
        </Document>
        <Document ID="162">
            <Title>Procedure followed</Title>
            <Text>The workshop started with a short introduction to my project, so that participants understood what are my motivations and what I wanted to get from them. I have presented the topic of my dissertation and honours project, explained the challenges in visually mapping a life, and did a short lecture on time visualisation, summarising what I have discussed in the previous chapter — the cultural differences in time representations, the normalisation of timelines, and the issues with linear timelines for time representation. The slides and notes from the lecture are available in [appendix A].
The participants were then asked to perform four tasks: draw their life in a non-linear way, retrieve old photographs on Facebook, answer a survey and evaluate different cartographies of time. Methodologies for each activity can be found in [appendices B, D, F and H] respectively.</Text>
        </Document>
        <Document ID="129">
            <Title>Collecting a culture</Title>
            <Text>To combat this issue, following the quick shutdown of hosting sites like Geocities, AOL Hometown and Podango, technology historian and web archivist Jason Scott started the Archive Team in 2009 (Scott, 2009). Described as a  “loose collective of rogue archivists, programmers, writers and loudmouths dedicated to saving our digital heritage” (The Archive Team, 2014), The Archive Team aggressively downloads whole websites that risk to close down soon, and then mirrors them. Their mission statement helps us understand why we cannot trust online services to be the only holders of our data:
“Corporations do not contemplate their own inevitable end. At least, they don't do it in public, unless they are in really bad shape. When times are good, those thoughts are pushed away, and end users are encouraged to do the same. When times are bad, they tend to go very bad, very quickly - if you're lucky, you'll have an announcement. Your data is never totally safe. Backing up your data is always necessary, even if it's stored elsewhere. […] Businesses can be extremely helpful, but they are also self-interested. As benevolent as Web services present themselves to be, your data is valuable to them - they aren't running this for your benefit. And it should be valuable to you, too.” (The Archive Team, 2014)

The Archive Team has notably rescued pages on GeoCities, a hosting site that was very popular in the mid- to late 90s. It was acquired by Yahoo! in 1999 (in what is now often referred to as one of the worst deals of the dot-com bubble (Willard, 2012 and Kopytoff, 2013)) and suffered a great decline since, ultimately leading Yahoo! to close down Geocities in 2009.
Although often considered of little value by the modern Internet community (Scott, 2009) due to the tacky and amateur design of the websites (animated GIFs, excessive animations, auto-playing MIDI music… [fig. 1.1]), archivists have decided to back it up and place mirrors of it online for cultural reasons:
But please recall, if you will, that for hundreds of thousands of people, this was their first website. This was where you went to get the chance to publish your ideas to the largest audience you might ever have dreamed of having. Your pet subject or conspiracy theory or collection of writings left the safe confines of your Windows 3.1 box and became something you could walk up to any internet-connected user, hand them the URL, and know they would be able to see your stuff. In full color. […] Already, little gems have shown up in the roughly 8000+ sites I’ve archived. Guitar tab archives. MP3s that surely took the owners hours to rip and generate. GIF files, untouched for 13 years. Fan fiction. Photographs and websites of people long dead. All stuff that, I think, down the line, will have meaning. It’s not for me to judge. It’s for me to collect. (Scott, 2009)
There is certainly a cultural aspect to the whole archive; the visual style of 90s websites, although generally considered of poor taste, has a cultural meaning and brings a certain form of nostalgia and reminiscence when we see it. The Museum of the Moving Image (2012), in New York, set up an installation of “Under Construction” GIFs [fig. 1.2] found in the GeoCities archive, small animated symbols that were so commonplace on personal websites that they became a symbol of this era in computing history, a meaning obviously acquired with time. But more importantly, there are indeed memories, photographs, stories, works shared by people 15 to 20 years ago that would otherwise be lost forever without this initiative.</Text>
            <Comments>Using “crawling”, a technique used by search engines to easily find all the pages of a website by copying a page and recursively going through all of its links.
Mirroring means putting up a static copy of the website on another website, so that its contents remain accessible</Comments>
        </Document>
        <Document ID="154">
            <Title>Intro</Title>
        </Document>
        <Document ID="146">
            <Title>Back matter</Title>
        </Document>
        <Document ID="171">
            <Title>Workshop results</Title>
            <Text>￼￼￼￼￼Retrieval method￼￼p1￼p2￼p3￼p4￼p5￼p6￼p7￼p8p9TotalI went to the profile and......kept scrolling down until I found it in the feedXXXXXX￼6...used the Timeline links on the right to access a time periodX1...knew it was in their profile/cover pictures, so I clicked there directlyXX2...directly browsed the albums... I knew which one it was inXXXXXXXX8... I had to go through a few albums to find itXXXXXXX7I used Facebook’s search engine to find the album or post0I searched in my browser history0I searched in my messages history... it was a shared link￼0... the photo was sent privately (in the messages)X￼1I searched my inbox for the relevant Facebook notification emails0I asked someone to send me a link to it0I had a picture in mind but I can’t remember where it wasX1I had a picture in mind and knew where it was, but I couldn’t find it/it’s been deletedX1ExperienceWorks fineXXXXXXXXXXX11LaboriousXXXXXXXXXXXX12Had trouble finding itXX￼2Couldn't find it at all￼0Wasn't where I thought it wasXX￼2￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼
￼￼￼￼￼￼￼(grades range from 1 to 10)￼What do you use social media for?p1p2p3p4p5p6p7p8p9AverageKeep friends up to date179595679￼6.44Preserve things that affect me emotionally1611512152.56Stimulate friends to think about certain topics5456111753.89Satisfy a spontaneous need for communication1595155795.22Get attention for my projects1591559655.11Define my reputation1298155714.33Chat with friends5996998998.11Follow news of friends5991999897.56General attention139811475￼4.33Keep in touch with friends far away5998955997.56Use groups for school/work/activities99919910898.11Follow celebrities or brands125145155￼3.22Follow networks about general news and current affairs5355596715.11Follow content about my domain (blogs, magazines, communities)1296599515.22Leisure activities525155831￼3.89Be part of the community9651555495.44No specific goal9513517554.56How long do you think Facebook will stay popular before being replaced by something else?10105?51010527.125￼Would you be willing to manually curate the archive of your social networks to organise it?TotalYes, every few weeks, so that I can keep a fresh eye on what’s importantX￼1Yes, every year or so, that’d allow me to look backXXXXXXX￼7Yes, less often, when I think of it￼0No, I’d prefer the curation to be done automatically, even if that means it is less accurateX*X￼2No, I think a standard timeline is better than these alternative representations0No, I would not be interested in your product anyway0* although if something was missing, they would like to be able to manually fix this.￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼Cartography p1 p2 p3 p4 p5 p6 p7 p8 p9 AVERAGE CREBCREBCREBCREBCREBCREBCREBCREBCREBC R E B￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼1 2 3 4 5 6 7 8 9 10 11 12 13513 ￼ ￼ 5 5 1 5 5 3 4 3 2 4 3 3 4 3 4 3 5 5 5 5 5 2 4 4 4 2 2 2 4 2 3 1 5 3.44 3.00 3.22 4.33 432 ￼ ￼ 4 3 4 2 3 4 4 3 5 4 3 3 3 2 4 4 5 3 3 5 5 4 4 4 4 3 4 4 5 4 4 4 2 3.44 3.67 3.44 4.00 232 ￼ ￼ 3 1 3 1 5 3 2 2 4 1 2 1 4 1 1 1 3 1 3 3 5 1 2 2 1 4 4 4 5 2 2 1 3 1.78 2.44 1.89 3.67 432 ￼ ￼ 3 5 5 5 5 4 1 3 4 5 4 2 3 5 2 4 5 5 5 5 5 1 1 1 3 5 5 5 5 1 3 2 4 3.89 3.22 3.22 4.11 443 ￼ ￼ 4 3 3 1 1 5 4 5 5 5 5 1 4 5 5 4 3 5 5 5 3 5 5 5 3 5 5 5 5 5 4 3 5 4.67 4.44 3.56 3.67 232 ￼ ￼ 3121345333412131315334433555513212.443.782.332.89 231 ￼ ￼ 1 4 4 1 5 3 3 3 4 3 5 3 1 1 2 1 5 3 3 3 3 2 1 2 4 2 4 5 5 1 2 3 1 2.33 3.00 2.44 3.22 313 ￼ ￼ 2213154511111244113312121555111412.442.333.331.11 112 ￼ ￼ 5333522443335123353532131344542442.672.333.443.89 533 ￼ ￼ 2554533325434444511353333555554554.003.563.674.00 322 ￼ ￼ 3444334134221335311132224354443253.002.892.563.22 121 ￼ ￼ 3253512141211333553552122445512312.222.672.673.44 333 ￼ ￼ 2555545435545535533335544444452554.333.894.114.00￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼C ClarityR Relevance E Efficiency B BeautyGrades range from 1 to 5.</Text>
        </Document>
        <Document ID="138">
            <Title>Recording</Title>
        </Document>
        <Document ID="163">
            <Title>Life mapping</Title>
            <Text>In the first activity, participants of the workshop were invited to map their life visually. The full methodology is described in [appendix B], and the description of results are in [appendix C]
Overall, we can notice that the line remains a mode of representation chosen by most people, even when asked to attempt to go away from it. A lot of people attempted to classify the events in their lives by emotional value, whether positive or negative; those used a single line. Of the people who used multiple lines, forking and merging again, there was a variety of contexts used. Most people considered schools as the main periods in their life, each change of school generally meaning a change in location and social circle; only Map 1 prefers to focus on a periodical change of goals and values. For all participants, events and ‘periods’ themselves were points of reference, and time units were not important at all; periods were not normalised and not proportional to each other compared to the amount of years they lasted.
When looking at the highlighted sections of the maps, i. e. the life events that appear on social media, there was a large variation in the proportion of the life map that existed online; this emphasised the content that participants put on their map, a lot of them putting a large focus in their most recent years, whereas some others had a more global view, from earlier on. Given the age of participants (early twenties), it coincides with the emergence of social networks that most of them started sharing their life during high school, some of them only at the beginning of university. Most maps seem to say that there was a “before” and “after” social networks, where everything was suddenly logged online after they registered and started being active on social networks. But a look at maps 2 and 5, which provide a greater degree of precision about events, shows that obviously only some aspects of the life are shared socially; generally these were positive events.</Text>
        </Document>
        <Document ID="155">
            <Title>Five orders of magnitude</Title>
            <Text>When organising any type of information, there are generally five ways to do so, known as the five hat racks: by category, by time, by location, alphabetically, and by continuum/magnitude (for example, lowest to highest price, or best to worst result) (Wurman, 1989 cited in Lidwell et al., 2010, p. 100; see also Rendgen et al., 2012). In the context of my project, I chose to investigate time exclusively. An alphabetical ordering would be irrelevant since there is a lot of non-textual items on a social network, and it would regardless not be helpful on textual updates; location would be impractical as well, as a lot of the content would be concentrated in a single area; and categories and magnitude cannot be established computationally from raw data in a manner that would be precise enough to be meaningful to users. The following chapter is therefore looking at what is time, how it can be represented, and why it is relevant to look for alternative ways of representing time.</Text>
        </Document>
        <Document ID="147">
            <Title>Cultural differences</Title>
            <Text>For example, Tversky et al. (1991) demonstrated that the origin of the direction can stem in the reading direction. When we read, the upcoming (future) information is on the right; we make progress by going right in a sentence or book. Speakers of languages that are read from right to left actually think of time going from right to left, the opposite direction of how Western European cultures see it, as demonstrated in Tversky et al.’s experiment. In every day life, it is possible to see this difference, for example, in computer software; progress bars are “reversed” in these languages, showing that progress is thought of going from the right to the left (see [fig. 3.2 and 3.3]). 
[Fig. 3.2]
[Fig. 3.3]
But as Boroditsky (2010) explains, it is not simply the reading direction that influences our perception of time; the Pormpuraaw community of Australian aboriginals exclusively use absolute directions and do not have words for left or right. This influences their perception of time, which is linked to the sun’s (East to West). Mandarin speakers tend to think of time vertically, more often than we do, even though modern Chinese is read horizontally. Their conception of movement is also different — they see a moving timeline and a static observer, whereas we tend to visualise ourselves moving in the static timeline (Santiago et al., 2007, p. 512).</Text>
        </Document>
        <Document ID="172">
            <Title>Tech review</Title>
        </Document>
        <Document ID="139">
            <Title>A Lecture slides/transcript and questionnaire</Title>
            <Text>Notes available at: http://socialdigital.dundee.ac.uk/~vloux/blog/archives/411
Slides at: http://www.slideshare.net/victorloux/preserving-digital-memories-workshop
+ include questionnaire PDF</Text>
        </Document>
        <Document ID="164">
            <Title>H Evaluation:Methodology</Title>
            <Text>In the last activity, I have asked participants to look at 13 historical representations of time, selected and extracted from Cartographies of Time (Rosenberg and Grafton, 2010), and rate each of them on four criteria: clarity (how self-explanatory the map is), relevance (how pertinent would that be to map a life), efficiency (how quickly could we find information on it) and beauty (the visual aesthetics of it). The objective of this activity was to find what are positive and negative patterns in the given designs, in order to inform a new design. Ratings were to be made freely on a line segment, from “not at all” to “absolutely”, which were lated translated into notes from 1 to 5 for comparison. All the cartographies of time shown have been presented orally during the introductory presentation before the evaluation exercise.</Text>
        </Document>
        <Document ID="156">
            <Title>Historical timelines</Title>
            <Synopsis>Timelines over history, quick history and particularly go over fact that they are new and they have been normalised on units in mid-18th century</Synopsis>
            <Text>Although our general representation of time is this arrow with convenient units, the timeline as we know [fig. 3.5] it hasn’t always been there, particularly in terms of normalisation of units; events were independent of markers, used to have multiple dimensions, be organised into streams of other events separating and merging, showing multiple events in parallel.
[fig. 3.5]
The book Cartographies of Time by Rosenberg and Grafton (2010) is an excellent resource to understand the history and politics of time representations, from the earliest calendars to the modern timelines. Many examples are given, and we can see that a variety of techniques and designs were used, and I have actually used some of these examples for my workshop (see next chapter). One of my favourite cartographies presented in the book is Strom der Zeiten [fig. Cartographies/11-StromDerZeiten], a novel design by Johannes Strass using the metaphor of streams. The full description that accompanied its release is particularly pertinent:
 “The expressions of gliding, and rolling on; or of the rapid current, applied to time, are equally familiar to us with those of long and short. Neither does it require any great discernment to trace as a farther exemplification of this assertion, in the rise and fall of empire, an allusion to the source of a river, and to the increasing rapidity of its current, in proportion with the declivity of their channels towards the engulfing ocean. […] Its diversified power likewise of separating the various currents into subordinate branches, or of uniting them into one vast ocean of power of dispersing them a second time, but still in such a manner that they are always ready under the guidance of some great conqueror to converge again into one point, tends to render the idea by its beauty more attractive, by its simplicity more perspicuous, and by its resemblance more consistent.” (Strass, 1810, pp. 8-10; cited in Rosenberg and Grafton, 2010)
It is only in the mid-18th century that Joseph Priestley designed the influential New Chart of History [fig. 3.6], using normalised units and linear blocks, that is the foundation of what we are used to today. </Text>
        </Document>
        <Document ID="148">
            <Title>Circular representation</Title>
            <Text>This linear timeline, however, is not the only way of representing time; it can also be seen as a recurring cycle. On our day-to-day life, we mostly use this representation for analog clock dials; this is borrowed from sundials, and makes sense when we think of the rotation of the Earth. It really is a continuous cycle, which doesn’t really start nor end happening, but that we can still quantify — a day has passed when a full rotation has been done, and we can map time units to it, from midnight to 11:59pm. This representation, however, is rarely used nowadays when talking about months or years, even though the same astronomical principles apply. Would it however be relevant for representing history, or individual lives?
[fig. 3.4]
In many traditions (Mayan and Pagan, for example), lives were seen as the continuation of someone else’s life; birth wasn’t seen as a starting point, and death not as an end point, but it was rather a recurring cycle. Graphically, these lives could be represented as an ouroboros [fig. 3.4].</Text>
            <Comments>Again, languages and expressions reflect these ways of visualising time spans or lives; traditionally, in Bali, the word for grandparent and grandchildren is the same (kumpi), as they would be the same person ultimately. (Haynes, 2014b)</Comments>
        </Document>
        <Document ID="173">
            <Title>Conclusion</Title>
        </Document>
        <Document ID="165">
            <Title>Results</Title>
        </Document>
        <Document ID="157">
            <Title>D Retrieval:Methodology</Title>
            <Text>In this task participants to go on their Facebook account, using either their laptop, tablet or mobile phone, and retrieve 3 pictures that made them smile, or that stuck in their mind for any particular reason. The main rule was that this picture had to be at least one year old (by the time of the workshop, this meant posted before December 2013). It did not matter whether the picture was on their own profile, on a friend’s profile, on a community page, or on a group. They did not have to be photos on which the participants or their friends were; funny pictures or memes that particularly stuck in their mind would have been fine too. 
The objective of this exercise was to get an understanding of the mental process they go through and how they proceed to find what they want, when they are looking to retrieve old content on Facebook. For each of the three photographs they were asked to describe which method they used to fetch it, how easy for them it was to find it, and if they found it at all (in cases where the picture was not where the user originally thought it was, or if the picture was deleted, or if the account holder deactivated his account).</Text>
        </Document>
        <Document ID="20">
            <Title>Intro</Title>
            <Notes>Find exact ref in Rendgen et al, possibly quote from it</Notes>
        </Document>
        <Document ID="149">
            <Title>Streams</Title>
            <Text>Using streams to represent time differently (see fig. Cartographies/11-StromDerZeiten):

 “However natural it may be to assist the perceptive faculty in its assumption of abstract time by the idea of a line and however inseparable the sensible and mental objects may have become by the figurative method of speech it is astonishing that upon this near advance and with similar assistance from the delicate preciseness of language the image of a Stream should not have presented itself to any one whose consideration had been attracted to this object. The expressions of gliding, and rolling on; or of the rapid current, applied to time, are equally familiar to us with those of long and short. Neither does it require any great discernment to trace as a farther exemplification of this assertion, in the rise and fall of empire, an allusion to the source of a river, and to the increasing rapidity of its current, in proportion with the declivity of their channels towards the engulfing ocean. This metaphor, by presenting something more congenial to a common object of sense, and at the same time more agreeable in its variations to the nature of the abstract notion, gives greater liveliness to the ideas, and impresses events more forcibly upon the mind, than the stiff regularity of the straight line. Its diversified power likewise of separating the various currents into subordinate branches, or of uniting them into one vast ocean of power of dispersing them a second time, but still in such a manner that they are always ready under the guidance of some great conqueror to converge again into one point, tends to render the idea by its beauty more attractive, by its simplicity more perspicuous, and by its resemblance more consistent.” (Strass, 1810, pp. 8-10)</Text>
        </Document>
        <Document ID="174">
            <Title>E Retrieval: Results table</Title>
            <Text>[table of results for Retrieval activity]</Text>
        </Document>
        <Document ID="166">
            <Title>B Maps:Methodology</Title>
            <Text>The method used is known as projective generative research: an ambiguous, open-ended instruction was given to participants (“draw your life, without using a one-axis/linear timeline”), to give them the opportunity to think about their life in a non-conventional way and inform my concept developments with different perspectives. This type of generative research is called projective as it is “focusing on expressive exercises enabling participants to articulate thoughts, feelings, and desires that are difficult to communicate through more conventional verbal means.” (Martin and Hanington, 2012, p. 94); this is in opposition to constructive generative research, which is more constrained and less expressive, and more appropriate for later stages of designing (Martin and Hanington, 2012). 
This activity has already been done at a conference by Haynes (2012), and a slide of examples was shown during the activity [fig. Cartographies/CathyHaynesHowtoMapaLife2012]. However, once the participants of my workshop were finished drawing their map, they were also asked to highlight the parts of their map which were visible or published on social networks, allowing me to grasp the extent of a life that we could display using these alternative life cartographies.</Text>
        </Document>
        <Document ID="21">
            <Title>Applying it to a personal life</Title>
            <Text>Should we think using events more than with units? Timelines and mechanical clocks are devices that have appeared relatively recently, over the course of the 18th century (Haynes, 2013a); yet they have shaped our vision of time to be incredibly linear and normalised. But Joseph Priestley, the inventor of the modern history timeline as we know it, admitted this drawback:
“Historical narrative is not linear. It moves backward and forward making comparisons and contrasts, and branches irregularly following plots and subplots. Part of the advantage of the matrix form was that it facilitated the scholar’s understanding of the many intersecting trajectories of history. The form of the timeline, by contrast, emphasised overarching patterns and the big story. This proved a great advantage in some respects, but not all. And Priestley readily admitted this. For him, the timeline was a “most excellent mechanical help to the knowledge of history,” not an image of history itself.” (Rosenberg and Grafton, 2010, p. 20)
The concept of progress is key to the timeline: the further we get on the line, the more progress we have made. But just like history, reducing our lives to lines reduces their complexity, and does not picture them accurately.  Lives are knotty and elusive, and would maybe better be represented like these representations of Tristram Shandy’s life [fig. 3.7 and 3.8]:
[fig 3.7]
[fig. 3.8]
Sadly, the linear timelines offered by social networks offer none of this complexity. I think however that for my project, it is relevant to explore these different options and go away from the classical, linear representation of time. It would not be ambitious and meaningful to keep this model, because the memories, people and places we know link to each other and that is how they make sense, that is what makes them valuable to our eyes. Cathy Haynes did question it for her Timekeeper residency:
“So what if we tried an experiment and mapped our life as we really experience it to be: a map without measurements? One that gives space to events according to their significance rather than their length in clock-time?
What if we made that map just for our self and included what we would leave out of a job application – a map that includes the mazes and trapdoors along with the parades of glory and the leaps of progress? Might we value the failures and the ‘time wasted’ more then? And when we accept and value our past experience in all its fullness, how does that change our view of the future?” (Haynes, 2013b)
Of all the different models that I have shown here, the critical question is now to figure out which one is more relevant, and works best, for representing a life based on the data available on social networks and, hopefully, change our view of the future. </Text>
            <Comments>According to Haynes (2014b), the future wasn’t always seen as being progressive; the Apocalypse was awaiting for us, and the wars and diseases never seemed to stop. It is only in the 1620s that Francis Bacon challenged this idea, advancing that technological and scientific revolutions would mean we would keep perfecting our world.</Comments>
            <Notes>“And it surely is faulty. A measurement is only a shadow of the thing. If we mistake the map for the land, the score for the performance, the timeline for the life, then we reduce existence to its shadows. As the philosopher Henri Bergson warned, lived time in all its fullness can’t be measured. Doing so risks reducing a life to a machine or commodity.”

(Haynes, 2013b)</Notes>
        </Document>
        <Document ID="158">
            <Title>F Questions:Methodology</Title>
            <Text>The questionnaire was structured, with limited response options, for quantitative results; although self-reporting may lead to uncontrolled and inaccurate results (Martin and Hanington, 2012, p. 127), it was the most appropriate choice for these questions. A comprehensive ethnographic analysis of  behaviours on social networks would be more accurate but would raise privacy concerns, and the development of an ethical framework for such a study (see Hutton and Henderson, 2013) was not an option given the timeframe and relatively low importance of the results.
 The first question, “What do you use social media for?”, asked users to rate, for 15 statements (based on Julius, n. d., p. 6), how strongly they used social media for. For examples, to the statements “Keep friends up to date”,  “Define my reputation” or “Follow celebrities or brands”, they could, on a scale, define how much if it wasn’t their use at all, not primarily, or if it was mostly what they used it for. The 15 statements can be found in [appendix A] and the raw results can be found in [appendix G].
The second question simply asked them to estimate, in their opinion, how many years would Facebook stay popular before being replaced by another social network, if they thought that it would be replaced at all. The third and last question, centred on the honours project, asked participants whether they would be willing to periodically curate their ‘archive’ manually— and if so, how frequently would they be willing to do it. Full questions are in [appendix A].</Text>
        </Document>
        <Document ID="22">
            <Title>Screen based interaction patterns</Title>
            <Notes>possibly physical? (see PeDeTe boxes exemple)</Notes>
        </Document>
        <Document ID="175">
            <Title>G Questions:Results table</Title>
            <Text>[table of raw results for questions]</Text>
        </Document>
        <Document ID="167">
            <Title>C Maps:Description of results</Title>
            <Text>Note that to preserve the confidentiality of participants, identifying information such as names, birth years or places names have been blurred.
[scans of all results]
All but one of the cartographies keep a line going from left to right, the last one being a web going from the centre to the outside. The first half of these eight linear cartographies only had one line, but chose, through different visual cues, to indicate different feelings during their lives. Maps 3 and 6 only took for analogy “up and downs”, and their line looked like an oscillogram’s wave, with positive moments going up and negative moments going down. Maps 2 and 5 combined this technique with squiggles and abstract shapes on the timeline to indicate chaotic moments, in contrast with the straighter, calmer parts of the line; this was highly reminiscent of Tristram Shandy’s life map [see fig. 3.7 and 3.8], which was shown during my presentation and could have influenced them. 
The other half of the maps used other systems, or multiple timelines. Map 1 split different life sections into “scopes”, each one with the life goal the participant had at that age, and enclosing the previous scope; as we grow older, it reflects on the fact we are still what we used to be, but have richer thoughts and ambitions. Map 4 uses bubbles of different sizes to represent events by their importance, each one getting more or less into the others (like a Venn diagram, but not enclosing them like in Map 1) to indicate how events are linking with each other. Here, it shows how college was a “stepping stone” linking high school and university; sadly it is limited in depth, but it is an interesting idea. Map 7 intends to be something much more graphical, starting from a central point (birth) and branching out into different directions, much like a tree, with each ‘branch’ being drawn differently (oscillogram, tree, river, leaves) and representing different aspects of life (education, connections, friends, personality). However, besides primary and secondary school, no events or periods were placed on it, making it rather unclear on time mapping.
Map 8 presented three major events on a timeline. After each event a series of different branches was presented, most going in unknown directions and only one going to the next event. This map clearly emphasises life choices that have to be made, and unknown possibilities coming out of the choices that have been settled or that will have to be made (post-university). Finally, the ninth map showed two parallel timelines, separating different aspects of the participant’s life that happened over the same period of time (here, the progression in different schools and the changes in their family/household, until they came to university and merged them as they were now living alone). </Text>
        </Document>
        <Document ID="23">
            <Title>Reflection on experiments</Title>
        </Document>
        <Document ID="159">
            <Title>Evaluation of time cartographies</Title>
            <Text>In the last activity participants were asked to evaluate different representations of time. Methodology is described in [appendix H]; the evaluated images, along with individual comments, are in [appendix I]. A summary of the averages for each result is presented in the table below [fig. 4.1]; full results lie in [appendix J].

[fig. 4.1]

Looking at the individual reviews, it appears clear that simplicity is key. The charts that were considered most relevant for being used as life maps were linear, with little to no branching and separation [fig. I.2, I.5, I.6, I.13], contradicting the intuitions that I have had when discussing streams and the knottiness and elusiveness of lives in the previous chapters. Those which fared well for clarity [fig. I.4, I.5, I.10, I.13] are not necessarily the least complex, indicating that richness of information is not necessarily a bad thing although it should be very carefully designed to avoid overcrowding the chart and confusing the user. 
Regarding efficiency, we can see overall that the averages are low or intermediate for all the charts, only one of them exceeding 3.67. The criteria of efficiency and clarity almost always received similar results. We can however get a new insight from this: it is those which are complex but extremely crowded, where it is hard to distinguish information and what belongs to which group of data, that received the worst results [fig. I.3, I.6, I.7, I.11, I.12]. This confirms the previous statement in regards to smart design for associating readability with complexity.
The criterion of beauty, or aesthetic quality, inversely received the most positive reviews, with only two exceptions going below an average of 3.00. In terms of patterns, we can see that the use of colour is not very incidental on the result, as both the best [fig. I.1 and I.2] and worst [fig. I.6 and I.8] charts were monochromatic or bicolour; Strom der Zeiten [fig. I.12], with its liberal use of colour to separate streams, was rated highly for beauty but poorly for clarity, so it should not necessarily be a deciding factor. Ornamentation did not seem to be influential either, charts who were “plain” and not highly decorated getting both honourable grades ([fig. I.2, I.5, I.9, I.11]) and terrible ones ([fig. I.8]); likewise richly illustrated ones had both great ([fig. I.1, I.3, I.4]) and lower ([fig. I.6 and I.7]) reviews. Looking at the individual reviews chart in [appendix I], we can see that while the grades for beauty were generally consistent, in a few cases this aspect was controversial (some charts getting both “5”s and “1”s), and reminded us that beauty is always subjective.</Text>
            <Comments>Considering the evaluation was not made with full-size charts asking the user to look for particular information, but only as a rapid rating of images, the metric of efficiency is not going to be accurate; and so we can expect participants to judge hastily based on their perception of clarity</Comments>
        </Document>
        <Document ID="24">
            <Title>Issues of the project</Title>
        </Document>
        <Document ID="168">
            <Title>Analysis</Title>
        </Document>
        <Document ID="25">
            <Title>Evaluate them</Title>
        </Document>
        <Document ID="50">
            <Title>Maintaining context</Title>
            <Text>It is important to add or maintain context with the data (transforming data into information), and not just copy the raw data. Kirk and Sellen (2010) found that ultimately, stories and narrative are more important than the preservation of the artefacts themselves; this is particularly important in the situation of heirlooms, where transmitting the emotional value and stories is more important than a meaningless photograph.</Text>
        </Document>
        <Document ID="26">
            <Title>Tech Heirlooms - considerations</Title>
            <Text>Technology Heirlooms? Considerations for Passing Down and Inheriting Digital Materials
William Odom1, Richard Banks2, Richard Harper2, David Kirk3, Siân Lindley2, Abigail Sellen2
Carnegie Mellon University1 Human-Computer Interaction Institute PA 15213 Pittsburgh, USA wodom@cs.cmu.edu
ABSTRACT
Material artifacts are passed down as a way of sustaining relationships and family history. However, new issues are emerging as families are increasingly left with the digital remains of their loved ones. We designed three devices to investigate how digital materials might be passed down, lived with and inherited in the future. We conducted in- home interviews with 8 families using the devices to pro- voke discussion about how technology might support (or complicate) their existing practices. Sessions revealed fami- lies desired to treat their archives in ways not fully sup- ported by technology as well as potential tensions that could emerge. Findings are interpreted to detail design considerations for future work in this emerging space.
Author Keywords
Technology Heirlooms, Memories, Digital Inheritance
ACM Classification Keywords
H5.m. Information interfaces and presentation (e.g., HCI): Miscellaneous.
INTRODUCTION
Material artifacts are passed down across generations of family members as a way of sustaining social relationships and bolstering ideas of shared heritage, history and values. These heirloom objects often offer connections to the past that extend before and potentially beyond the current owner’s life. As we live more of our lives “online”, it is interesting to ask how digital content will find its place among these physical collections of things that connect us to the past. After all, digital technology makes it possible for people to accumulate vast and diverse digital archives. In the future will children look back over their grand- mother’s digital photos or Facebook content to explore what her life was like? Will these digital things be passed down the same way as physical things are?
Microsoft Research Cambridge2 Cambridge CB3 0FB, UK {rbanks r.harper, sianl, asellen}@microsoft.com
Newcastle University3 Culture Lab Newcastle, UK, NE1 7RU david.kirk@ncl.ac.uk
￼Figure 1. The three ‘technology heirloom’ devices: the Timecard (left), BackupBox (center), and the Digital Slide Viewer (right).
Research in the HCI community has illustrated a diverse range of ways people are drawing on digital objects to re- flect on and reminisce about the past [e.g., 14]. Very recent work has described new complications that are emerging as loved ones pass away and leave complex assortments of digital remains for the living to come to terms with [e.g., 16, 19]. Many of these issues point to the fact that we are seeing a proliferation of personally meaningful digital arti- facts. However, little work to date has progressed beyond explorations of current practice to explore how these sensi- tive materials might persist over time, across owners and across generations in the future.
With this in mind, we designed three devices (see Figure 1) as a way of encouraging people to think more concretely about how digital materials might be inherited in the future. The aim was to use these design artifacts to explore how the processes of passing down digital materials among family members might be better supported as well as to reveal po- tential unintended consequences that could emerge. They are: the Digital Slide Viewer, which packages treasured family photo albums in the form factor of a traditional slide viewer; Timecard, a device that enables people to assemble, present and hide away digital content of multiple family members along a chronological timeline; and Backup Box, which locally stores a person’s Twitter archive on a daily basis in a form that can be handed down. We conducted in- home interviews with 8 families, using the devices to pro- voke discussions about how technology might fit within (or complicate) their practices of inheriting and passing down digital collections in the future. These sessions opened up discussions that provided insights into how families desired to treat their archives in ways not fully supported by tech- nology. They also revealed emergent tensions as members critically considered futures embodied by (and beyond) the devices and reflected on consequences that could emerge. With these findings in mind, this paper concludes with a
￼Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.
CHI’12, May 5–10, 2012, Austin, Texas, USA. Copyright 2012 ACM 978-1-4503-1015-4/12/05...$10.00.
discussion of four design considerations aimed at sensitiz- ing the design space toward better supporting the work of inheriting, living with and passing down significant digital materials: designing technologies to be put away; support- ing the moral work of safeguarding; enabling multiple roles; and enabling multiple representations in the archive.
BACKGROUND AND RELATED WORK
Artifacts play important roles as triggers for personal and shared memories. Over time these things signify our rela- tionships with each other and can mediate how people re- member their loved ones. The roles material artifacts play in supporting personal and familial memory [2] as well as ideas of family history and heritage [10] have been central concerns across several disciplines in the social sciences and humanities. Currently, there is a growing literature ex- ploring the process of passing down objects as not merely reflecting our relationships with loved ones, but in essence constituting them over time [6]. A special emphasis has been given to how objects signify human relationships with the living as well as stand in as proxy for the departed [17].
With the increasing presence of digital artifacts and systems in everyday life, the nature of human interactions is shift- ing—people now commonly mediate between material things and digital technologies. It is not surprising then that research related to the effects of digital artifacts being left behind by departed loved ones is starting to emerge in quite a vital way. Based on an empirical study of bereaved fami- lies, Massimi and Baecker [16] speculate on future chal- lenges related to digital inheritance, including: the claiming problem—digital materials lack clear affordances for inher- iting, and the afterlifelog problem—reimagining the role of digital materials representing the lives of departed family members could provide opportunities for family members to remember loved ones. In a related study, Odom et al. [19] describe how relationships with the departed loved one continues to evolve, often mediated by inherited objects. It suggests concerns such as supporting the endurance of a cohesive archive and developing richer tools for contextual- izing inherited digital content.
More generally, there exists a history of research in the HCI community exploring the recording and archiving personal or family memories. Kaye et al. [13] describe how digital archives could better support the work of self-reflection and understanding. Kirk &amp; Sellen [14] present a values-oriented approach to support the archiving of families’ cherished digital materials. Importantly, they highlight how the movement and storage of artifacts around the home plays central roles in preserving them for future generations.
Additionally, several projects [e.g., 8, 24] have designed and studied devices in laboratory environments that, in varying ways, enable families to attribute audio annotations to physical objects and digital photos. These studies specu- lated that shifting interaction away from the PC and toward dedicated devices may be more appropriate for supporting
social practices of storytelling. Outside of the lab environ- ment, Petrelli et al. [21] present a rare example of how reminiscence could be triggered by encasing audio record- ings of family events in the form of a vintage FM radio.
Collectively, these strands of research have made important contributions to understanding how interactive technologies could better support digitally capturing family memories and revisiting them. They also reveal how new problems are emerging as members attempt to make sense out of in- herited digital content, and consider how they themselves will pass down their digital legacy. Our work attempts to bring these strands of research together. We want to inves- tigate how digital technology might fit within (or compli- cate) families’ existing practices, and how the design space could be critically developed through and sensitized by these understandings. Beyond work that has gone before, we do this by grounding discussion around a set of working prototype devices that aim to make concrete new ideas for dealing with families’ growing legacies of data.
METHODOLOGY
We designed three working devices to critically explore potential future interactions, experiences and practices sur- rounding the inheritance of digital content. Although these objects offer some diversity in design we synthesized a methodological approach that united them. Specifically, we used them to provoke reflection on the materials themselves and encourage a dialogue about (and beyond) the stances and potential futures they embody. Our methodology drew from a number of approaches, including speculative design [9], critical design [3], reflective design [23], technology probes [12], and design-oriented HCI [5].
The process leading to the development of these devices consisted of the following. We conducted review sessions of theoretical literature and empirical studies (many are noted previously). We then ideated many design concepts and progressively refined and clustered several conceptu- ally related sets to construct an understanding of the overall design space. Comparable to Schön’s notion of design as a reflective conversation with materials [22], we engaged in a reflective dialogue with theoretical and empirical materials, and iterative development and critique of the design con- cepts themselves, to arrive at our final devices.
We intended the form and presentation of each respective device to be resolved to the extent that, at first glance, they might appear relatively familiar in comparison to other do- mestic artifacts. We wanted the devices’ material aesthetics to, on the surface, evoke a sense of the warm qualities asso- ciated with antique or heirloom objects (e.g., veneered oak composing an old chest compared to plastics encasing many contemporary appliances). The three devices are designed as a visual family, each encased in a European Oak veneer with a single surface of color. Further, the digital technol- ogy of each artifact is integrated into a form characterized by affordances that enable them to be fluidly opened up and
put away. These design choices were influenced in part by prior work illustrating how the qualities of certain materi- als, such as wood, can inspire a perceived sense of durabil- ity [20]; and how the invocation, experience and putting away of inherited objects—digital and physical—appears central in supporting meaningful, self-determined interac- tions with them [19].
Nonetheless, it is important to point out that the notion of ‘designing an heirloom’ can seem contradictory. The ways in which an object achieves heirloom status is highly idio- syncratic and heterogeneous; what one family may regard as an heirloom will likely not retain the same meaning for another. Additionally, heirlooms often directly owe to the people that possessed them previously and the material his- tories inscribed through their use over time.
Thus, it must be stressed quite crucially that we did not aim to evaluate our design concepts per se. Indeed, a more tradi- tional ‘evaluation’ would require a deployment for many years—if not decades—to understand how the devices shaped people’s practices and experiences as they accumu- lated digital content and were (or were not) passed down to another generation. Rather, we used the devices to provoke discussion around—and beyond—the potential futures they might embody and inspire; and to explore issues and in- sights that emerge through these discussions. Additionally, we populated the devices with digital content from a re- search team member’s personal collection, as opposed to each family’s specific content. This team member’s digital content captured years of personal and family experiences, as well as materials left behind after the loss of a close elder family member. Nonetheless, this clearly has limitations. The digital materials left behind by, for example, a teenager or middle-aged person would be different. However, this approach did appear effective in providing families with enough context to understand and relate the devices to their own lives, while remaining open enough to encourage them to envision new ideas or uses. In what immediately follows, we describe each of the concepts in turn, and then provide details on our participants and study.
The Digital Slide Viewer is a device for the local archiving of different collections of a family’s digital photographs (see Figure 2). The device is an augmented vintage analog slide viewer popular in the United Kingdom in the 1970s. Physical slide tokens, laser cut from acrylic, symbolically correspond to photo albums previously stored online or locally by a family. The slides and viewer are stored and organized in an oak case. Each slide has a unique strip of color on its back, which is recognized by a color sensor to determine which album should be made viewable from in- ternal memory. When a slide is inserted, the photos in the corresponding album become viewable, which may be se- quentially explored by tilting the device left, to move backward, or right, to move forward, in the set. The digital slide viewer is driven by a Gadgeteer [18] microprocessor board, which several sensors and devices are plugged into,
including: a 100x100 pixel display; an SD card (in an inter- nal SD reader) for image storage; an RGB reader for detect- ing a unique color present on each slide token (to invoke different photo collections); and a breakout board with two tilt sensors for supporting navigation. A mini USB connec- tor powers the device. Content for the photo albums was supplied by a research team member and models their exact organization. These 20 albums cover a diverse range of events over several years, including family trips and mo- ments in a young child’s life as well as mundane experi- ences (e.g., a family informally creating artwork together).
Figure 2. From left to right: The viewer in case with the slides; View of a photo; Families often desired to store the slide viewer in spaces where other significant artifacts were kept.
Issues framing the rationale for this concept included: How would the form and presentation of this device be perceived to support or complicate participants’ existing practices of viewing family photos, against the backdrop of their own physical and digital albums? How would integrating digital photo albums into an artifact that may already be familiar to some members shape perceptions of these digital materials?
Timecard enables family members to construct and present a timeline representing the life of a loved one, which is stored and displayed on a dedicated device (see Figure 3). Timelines can be created for a departed family member as a form of memorial, or simply to map the lives of several family members as a matter of preserving family history. Family members can add digital content (e.g. text, images) to the system via a web interface and backend online serv- ice, which is used to transfer content locally to the device. During the upload phase, people are able to attribute spe- cific dates to the content, which dictate where items appear on the timeline. The Timecard case includes doors that en- able it to easily be opened up or put away; the touch screen sits behind the doors. It is stand-alone and can sit of a shelf or on display elsewhere in the home. A fanless mini-PC runs the Timecard application displayed on the screen.
Figure 3. From left to right: Children from F4 interact with his- torical metadata; The timeline UI view; Several families placed Timecard (closed up) on display with other things in the home.
Photos can randomly cycle in full screen mode. Touching a photo brings up a timeline view of all the images of a per- son chronologically; the timeline (and collated content) can
￼￼
then be explored via the touchscreen. In addition to per- sonal annotations, family members can attribute metadata of historical events (scraped from Wikipedia) to the time- line to help better contextualize the life and times of an an- cestor. We speculated this design choice might make the life stages of different ancestors more meaningful for future generations. A research team member that had recently ex- perienced the loss of an elder close family member pro- vided the content Timecard presented in this study. This included physical objects and photos that he had been be- queathed (which were later scanned), as well as photos over the years that depicted the member in different life stages.
Issues framing the rationale for this concept included: How might technologies fit within, extend or complicate fami- lies’ practices of remembering and commemorating the lives of loved ones? How could these narratives be passed down and how could chronology affect these practices? We were also interested in where families perceived they would keep an artifact like this in their home and how it would be treated considering its potentially sensitive nature. For ex- ample, would enabling content to be made public shape perceptions of its placement in storytelling practices?
BackupBox is a digital store of a lifetime of Tweets posted to the micro-blogging website Twitter.com (see figure 4). Through a WIFI connection, it copies messages from the internet to a self-contained hard drive. There they are pre- served for a future time when they might be drawn on as a resource to revisit the mundane and extraordinary moments of a family member’s life captured by their Twitter account. We selected Twitter in contrast to other social media ac- counts (e.g., Facebook) as we speculated the 140 character limit for each entry would produce more concise and easily accessible entries. However, during the study participants speculated on how their own digital materials (e.g., Face- book content) might relate to—and extend beyond—the BackupBox concept, which we will discuss in detail later.
Figure 4. From left to right: The removable lid; Mom2 presses a icon to open a Tweet; UI design for an opened Tweet.
The physical form consists of a box with a removable lid, intended to conceal the growing archive of digital materials so as to not attract attention, while still inviting exploration if a family member chooses to open it up. The user interface presents Tweets in chronological order along the X axis; the Y axis indicates the time of day each Tweet was posted. The interface is navigated via a touch screen and each Tweet item in the timeline is symbolically represented as a non-descript flower; touching a specific element will pre- sent the contents of the message. A fanless mini-PC runs
the BackupBox application displayed on the screen. Con- sidering the potentially sensitive nature of some messages, we speculated this design choice could provide an addi- tional layer of comfort by requiring people to physically invoke the content beyond just removing the lid. The Twit- ter content on BackupBox at the time of the study was ar- chived from nine months of the device routinely backing up one of our research team members’ Twitter account.
Issues framing the rationale for this concept included: Would the BackupBox surface tensions around the proc- esses of passing down personal digital content that is cre- ated and stored online? Would family members perceive a physical instantiation of a digital service to be valuable? Would family members perceive social media content, such as Twitter data, to be similar or different to existing percep- tions of materials to be passed down in a family archive?
Participants and Data Analysis
We recruited 8 families (F1-F8) from the southeastern re- gion of the United Kingdom to participate in our study. This approach clearly has limitations; for example, it makes the results hard to generalize to another population of users. However, we wanted to focus on a specific group to gain a richer descriptive understanding of the space as a whole to inform what might be salient issues for future research. Two parents from each family participated (with the excep- tion of (F5); only the mother participated). All families had at least 1 child; F2, F4, F5, F6 and F8 all had young or teenage children, all of whom participated in the study. F1, F3 and F7 had children in their early to mid-twenties which all lived outside of the parents’ home; 4 out of 5 of these young adults participated. Three families (F1, F6, F7) had members representing two generations that participated (i.e. children and parents); the remainder had members repre- senting three generations that took part in the study (i.e. children, parents and grandparents). 5 of the 8 families had experienced the loss of at least one grandparent in the past 5 years; all inherited objects from these experiences. In total 36 people participated in the study—15 children (ages rang- ing from 9-25), 15 parents (mid 30s-early 50s), and 6 grandparents (late 60s-late 70s). The occupations of parents ranged from schoolteacher to IT consultant to plumber; occupations of non-student children included sales atten- dant, law clerk, and barista; all grandparents were retired. We recruited this participant pool as they could offer a range of experiences with physical and digital objects.
All interviews were conducted at the parents’ home, where family members collectively convened prior to the inter- view. The choice of the parents’ home appeared most ap- propriate as they typically housed an assortment of artifacts ranging from heirlooms that had been passed down over at least one generation, to objects that were anticipated to be passed down to their children. One home visit was con- ducted per family and lasted between 2 to 3 hours. Visits began with parents (at times together with grandparents
￼
and/or children) giving us a tour of their home, with em- phasis on where they kept heirlooms or objects that might become heirlooms. They were asked to describe stories associated with these artifacts, how they were received, who is responsible for them, and reasons for keeping them in particular spaces. We also explored if members pos- sessed digital collections they desired to hold onto (and potentially pass down), and where they were kept. We then asked members to gather a selection of artifacts emerging in the tour and to arrange them in a central room in the home. This was to provide a rich backdrop of participants’ posses- sions that could serve as a basis for comparison when ex- ploring the devices.
All participating members then reconvened in the central room (often living room or kitchen). We conducted a brief discussion to clarify experiences surrounding the artifacts arranged in the room. We then began sessions using the devices. We were careful to make clear that all the devices are concepts to be used as starting points for discussion about and beyond them; family members were encouraged to envision what they would (or would not) want them to be. One device was introduced at a time, and each had a specific semi-structured session conducted with it. How- ever, members were free to go between devices if desired. For each device, researchers offered a short narrative pro- viding background context, illustrating how it could be in- teracted with in the process. These introductions were kept brief. Emphasis was placed on family members exploring the device and coming to their own interpretations of it; they were encouraged to imagine what kind of future each device projects and consider what that would be like.
At appropriate moments during sessions of exploration and discussion, we posed open-ended questions. Questions were designed to critically elicit reflections on topics including: how narratives persist with personal artifacts as they are passed down; how and when cherished objects are used; what kind of family ‘image’ they construct; how physical and digital archives are maintained and how the social roles of members surrounding their care may change; and where they will go when they are passed down. Members were asked to contrast their descriptions with how the device might or might not fit within their practices. We altered the order devices were introduced to families across the study. After all devices had been discussed, we asked members to take us on another tour of their home, this time considering where they would keep them in their home and why.
All interviews were audio recorded, which resulted in nearly 20 hours of recordings; photographs were addition- ally taken to document objects and spaces discussed during the interview. We listened to recordings and transcribed segments relevant to heirlooms and interview questions (as opposed to general chat), which were organized into themes. Meetings were held with the research team to dis- cuss and corroborate emergent themes; we coded the textual
documents using these themes. In addition, we created af- finity diagrams using sticky notes to order findings across families and reveal unexpected connections.
FINDINGS
In what follows, we present several examples taken from field observations with families, which we feel capture the core themes emerging across our interviews. We refer to participants by their role — GF (Grandfather), GM (Grandmother) Mom, Dad, S (Son), D (Daughter) — fol- lowed by a number indicating the family. In the case of children, the reference includes a second number indicating the child’s age. For example D4-13 would stand for a 13- years-old daughter from family 4.
Figure 5. Family members interacting with the Technology Heirlooms during in home interview sessions.
The storage and safekeeping of family heirlooms
Interviews in families’ homes revealed a diverse range of material and digital artifacts members kept and desired to pass down. In what follows, we first describe families’ per- ceptions of their material heirlooms and their digital collec- tions. We then detail how families drew on the devices to envision alternatives to better support their practices.
Despite representing some of their most valued possessions, families commonly described ‘using’ their heirlooms infre- quently, at times several years lapsing in between these instances. It was also common for families to clearly differ- entiate heirlooms from other domestic objects: “We don’t use them like you’d use a [television] remote. ...Their pur- pose is something bigger.” (Mom3). Instead, practices sur- rounding heirlooms were bound up with having them pre- sent and ensuring their safekeeping. Dad1 describes an al- bum containing photos and memorabilia of his family’s ancestors: “we rarely go back to them. ...it’s having that peace of mind that they’re there [motioning to bookshelf] and we’ll see to it that they’re there until it’s time for my kids to take them.”
Safekeeping was understood as occurring across genera- tions and was bound up with the passing on of items. In
￼
some cases, older members preemptively passed down heir- looms to ensure their transfer to the next generation: “...making sure [they] make it through time, that feels as important as the things themselves. ...telling my daughter what they mean, the people they represent, while she has them, that’s going to help them last” (GM5). Similar to their material heirlooms, families sought to safeguard treas- ured digital collections for future generations. These in- cluded things such as: digital photos, videos, documents, and to some extent, artworks and music.
Various tensions were bound up with the notion of safe- guarding digital collections, however, especially relating to practices surrounding their backing up. For example, it was a common strategy for families to use external hard drives to back up their digital collections. However, in some cases the extra task (and hassle) of updating a secondary storage location led to the external hard drive being routinely ne- glected. In others, families described a general distrust over the longevity of their personal computers, which led them to create extensive backups on physical media (e.g., CDs or DVDs). Tensions also emerged with this approach, namely due to doubts over how long these media would last and the physical space their storage required. Other concerns in- cluded the potential to lose the physical media: “the prob- lem with CDs is if we lose one ... we’d lose a whole a chap- ter of the kids growing up” (Dad8); as well as concerns that the aesthetics of physical media failed to convey the pre- ciousness of the content. As Mom7 put it: “they deserve better than that.”
The use of online services to store digital family collections is an alternative to creating local backups, and members from all families reported using photo sharing services (e.g. Facebook, Flickr) or email to share select family photos with specific people to varying extents. However, these services were viewed as supporting sharing rather than the safekeeping of sentimental content: “We put things online to share them, not to preserve them. ...all our intimate [digi- tal] memories, we want to know where they are, keep them in order. ...the thought of them being where someone could get at them. That makes us uneasy” (Dad6). Parents in two families (F4, F7) maintained accounts through the cloud storage service dropbox.com, and similar concerns also emerged: “I’ll put things for my work or my music in drop- box, but I wouldn’t put anything too valuable to us there. What if our account was hacked or deleted? ...it feels too risky” (Dad7). When possible, we probed teenagers’ per- ceptions of storing content online. They typically reported fewer immediate reservations about hosting personal con- tent online, but tended to react strongly against integrating their own digital content into family collections.
Unexpectedly, some families drew on the physical forms of Timecard and, especially, BackupBox to propose alterna- tives that might help alleviate some of tensions mentioned above. While these ideas varied, they were united insofar as they proposed that a storage system distributed among peo-
ple was an appropriate way to preserve familial content. Consider Dad4’s reflection: “my brother, my wife’s brother. ...they would be the guardian of our kids if we passed away. We’d do the same for them. ...it makes sense that they could guard our [digital] things and we could do the same. ...So if one of our homes burned down or our thing [i.e. device] died, there’d still be one or two copies out there, like at my brother’s or at Mum’s place. Same would go for them.”
Dad4’s reflection captures how some families drew on the devices to propose potential uses of technology that might better support their desires to safely preserve precious digi- tal archives over time.
Embodied digital forms: settling in and setting the tone
The embodiment of digital content in physical forms con- veyed through our devices provoked discussions across home visits. Below we detail how families saw ways in which physical properties might enable them to treat, relate to and live with sentimental digital content.
A primary theme across interviews centered on how captur- ing digital family archives in forms distinct from the com- puter might both project and engender a deeper sense of care for these materials: “Putting our family photos and videos and all in a different folder [on our computer] doesn’t do them justice. There is so much on [our computer] that we won’t give a toss about in a year. ...our photos, videos, that’s the bit that matters. ......[The devices] get away from all the clutter. ...they show you care and makes you want to care for them, tend to them” (Mom3). GM5 similarly noted, “there’s something about being able to say ‘what’s important, it’s all in here’ and pick it up, give it to someone or keep it in a special place that suits it.” Other families speculated on potential benefits of storing digital content in domestic spaces populated by their treasured material things. For example, when considering where the Digital Slide Viewer would be stored in their home, F1 se- lected a small living room cupboard that housed several sentimental items: “...having it packed up next to the Chi- nese boards and albums and medals. ... seeing it age with them, the things we’ll always have. It feels right. ...we want to hold onto our [digital] family photos like those things I suppose. Putting it there makes it feel like it’s findings its place. ..with our things, in our home” (Mom1).
Four of the eight families (F3, F5, F6, F8) we interviewed possessed only a single computer, all of which were desk- tops set up in home office or kitchen locations. These fami- lies in particular reflected on how moving their sentimental digital archives to other domestic places could better prime interactions with them: “we have this chest. ...It has little trinkets and bits and bobs that we’ve saved over the years, some old stuff from me Mum. ...this is where it [Digital Slide Viewer] should go. Opening [the chest], seeing those things and bringing out the [digital] slide box, that’d be a more natural way of coming to them [photos] than booting up the computer” (Dad6). Mom6 then continued: “We’ve
got this habit about the chest. When we get into it, it sets a tone. It’s time to take a moment and look through them. ...having it [Digital Slide Viewer] in the chest, it’d blend right in. ...with what we’re already doing and the things that’ve always been there.” Mom8 contrasts Timecard’s location in her living room with the home office-based computer: “I don’t walk by our computer in the office and think of the memories that’re on it. ...This feels somewhere in between. ...it’d remind me of the memories in there, but if it’s closed up, we could walk past it and leave it at that. ...That makes it feel like a more complete part of our life.”
Additionally, the vintage form factor of the Digital Slide Viewer itself appeared to help set the tone for reminiscing about the past. Members of several families recognized its form, which led to discussions about their lives when they last used one. After one such discussion with her son and granddaughter, GM2 noted: “seeing something familiar from the past, it triggers all these memories and associa- tions I haven’t thought about in a while. ...it feels like a real way of starting to get back to the past and remember it, with the photos and all.” Often younger members were ac- tively included in these discussions as the device was passed around; in some cases, they initiated discussions themselves: “D4-13: Mummy you had one of these. Is this what you used to look at pictures? M4: Yes I did. It was [grandmother’s], she can tell you where she got it from.”
Collectively, this sample of reflections helps illustrate how giving digital collections physical properties might better support the dynamics of living with them over time, from intentional engagement to simply letting them persist among other significant domestic possessions and spaces.
Curating, Integrating and Changing Roles
Families adopted several practices to construct a meaning- ful whole out of collections of heterogeneous artifacts they desired to pass down. In what follows, we provide an over- view of these practices, before detailing how Timecard in particular provoked discussions about potential benefits and complications technology might present in this context.
A common practice we observed across families was the use of notes and other materials to explicitly detail the his- tory of family artifacts to preserve their meanings. These instances ranged from Dad2’s collection of his great grand- father’s medals and other artifacts from World War One, to Mom6’s scrapbook owing to her own life as well as to several departed ancestors. Across these examples, family members included short notes and, at times, materials de- tailing local and historical events occurring when specific artifacts were in use to help communicate their significance to future generations.
It was also common for families to consciously prune col- lections of important physical materials to avoid creating an archive of undesirable size and scale, and to underpin a sense of coherence. We found both parents and grandpar- ents engaged in this practice and while at times difficult, it
was considered an essential part of ensuring cherished familial artifacts made it to the next generation.
However, the constraints families imposed on their material archives did not always translate to their digital collections. Mom5 contrasts her family’s physical photo albums with their digital collections: “With the [physical] albums we have to decide what to put in there and what’s not quite worth it. ...On our computer they pile up. We have so many photos on there now and we keep taking more. ...It starts to feel endless, really.” In two cases (F5, F6), families elected to print out physical copies of digital photos and integrate them into physical albums, to make them easier to manage and pass down. However, when posed with the question of how (or if) families would wish to cull their digital collections for the future, most members were ambivalent.
While archives of material things supported heterogeneity in a way that digital archives did not, they were typically associated with one branch of a family. Discussions of Timecard highlighted that having a place to collate content from multiple sources would also be desirable: “...thinking about when my Dad passed away. I have some digital pho- tos of him and my sister does, and we both have some of his things. ...If we were able to put some of them [digital things] together, when we’re feeling up to it, that would be meaningful. ...We could have something celebrating his life, and us with him” (Dad7). Mom1 speculated on the potential benefits of distributed curation of sensitive digital materials over time: “having a place where my brother could add an event in one of our parent’s lives and I could leave it for a while, and then add something. ...let things come out slowly over time, that would be valuable. ...it would create a new record of our family.”
Digital archives were also noted for supporting collabora- tion within nuclear families. However, this also raised con- cerns. Some families perceived that this could complicate meaning: “If everyone is putting in things like moments in history or notes about a person, it’s going to make things confusing. There has to be some kind of quality control” (Dad1). Timecard triggered other families to consider how social roles of members would be supported: “We [parents] take most of the responsibility for preserving things about our parents’ lives and our lives with the kids. ...I like how we could all see it and add to it. That is useful for everyone. But we [parents] need to be able to make sure it doesn’t become a mess” (Mom6).
In some cases Timecard triggered intergenerational discus- sions among living family members in the room about past experiences and family history. For example, after interact- ing with a metadata tag relating to the date of India’s inde- pendence (15 August 1947), D4-13 felt prompted to ask her Grandmother about her life during this time period. After describing what her life was like as a young girl then, GM4 reflected on what she remembered of her father immedi- ately following World War II. At the conclusion of GM4’s story, Dad4 remarked: “well, that’s a bit of our family his-
tory I haven’t heard. I wish we could’ve recorded [it] in this box [Timecard], right then and there.” Dad4 highlights the potential value of capturing emergent conversations about family members’ own lives; this opens a space to consider how such records could make interactions with the device richer in the future.
However, some discussion emerged about how perceptions of past experiences can shift over time and how technology could pose challenges: “Even if we remember things from the past the same, the way we feel about them can change. ...like if a photo or summit later reminds us of a falling out we had with a relative. We chuck it in the bin to be done with it. ...So if I put something in there [motioning to Time- card], I should also be able to take it out” (S3-25). His re- marks represent discussions that emerged with the Time- card and the Digital Slide Viewer: the need to take things out of digital archives as fluidly as they are put in.
Tensions over new digital materials in the family archive
Our aim with Backup Box was to provoke family members to consider the potential role of social networking data, such as Twitter updates, within family archives. Backup Box was highly contentious across families. Several related kinds of criticism emerged, as we describe.
Several families possessed diaries written by ancestors now considered important parts of the family archive. These diaries tended to contain mundane information (e.g., a list of household chores completed on any given day) with a sprinkling of extraordinary events (e.g., marriage of family member, birth of child). When asked to speculate on simi- larities and differences among the diaries and Backup Box, family members drew strong distinctions. Dad7’s percep- tion of the difference between his father’s diaries and social media content is exemplary of members of several families’ sentiments: “when I open one of his diaries and see what he wrote, I know he sat down and thought for a moment, and that feels significant. ...with stuff like Twitter, people rattle things off, sometimes without thinking ...the intention is different and I suppose that makes a huge difference.”
Backup Box also raised issues over the potentially vast amounts of social networking content other family mem- bers would have to reconcile with. D3-22 prospectively considered what it would be like to receive her brother’s social networking archive: “He posts stuff to Twitter and Facebook literally all of the time. I can’t imagine how many updates there would be for one or two years, let alone a decade. How would we deal with that?” Other participants speculated on how years worth of Twitter data could trap a small amount of meaningful insights from a person’s life within a sea of trivial entries, potentially making it difficult to explore or let go of: “If I got, say, Mum’s Twitter. I’m sure there’d be some stuff I’d enjoy seeing, but I’d have no idea how to find it. ...I’d probably keep it, but not know what to do” (D1-21).
When D3-22 concluded reflecting on her brother’s social media content (mentioned above), she noted: “And it’s so much about him, but not all that much about us. ...or our family.” This statement captures deeper concerns echoed by members of several families: that social media content is often targeted at different audiences, which could make its place in the family archive controversial. Mom2 describes how this quality could lead to undesirable experiences: “on- line it’s easy to act [in] very different ways to different peo- ple. Even I confess to that, and I wouldn’t exactly want other people to know about this. ...it feels a little scary that we could learn something about someone that maybe we weren’t supposed to know, or didn’t want to.” Teenagers in the families we interviewed typically were frequent users of social networking services, and also reacted against the inclusion of their content in the family archive. D6-17 re- flects on her personal social media content: “I could see looking back on it myself, but it would be weird if other people in my family used it to think about me. I’d rather make myself something that would go in it. ...something that’d show my family something special about me.”
Related concerns also emerged around how a device like BackupBox could cause family members to self-censor the social networking content they posted, or paralyze these practices completely. Some families proposed ways to work around these tensions, such as using a special hash tag or a specific application to send updates only to Backup Box.
DISCUSSION AND DESIGN CONSIDERATIONS
It is clear physical and digital objects hold significant places in families’ lives, and that these are envisaged as retaining this significance over time and across generations. A key contribution of our study is to surface insights on how technology might open up new opportunities for pass- ing down and inheriting digital materials, as well as new complications that they could introduce. Our findings reveal a range of ways families desired to treat and live with their significant digital materials. Several of these cases were characterized by their desires to treat these archives differ- ently, integrate them into more appropriate places in the home, and tend to their care and safety. Other instances suggested how technology might better support social prac- tices of creating more cohesive sets of materials to be passed down, creating archives from multiple branches of the family, and documenting conversations that emerge around them. The devices also raise a range of potential consequences that could emerge if careful consideration is not given to new technological interventions. In what fol- lows we present several research and design considerations for the HCI community that emerged from the study.
Designing technologies to be put away— Similar to mate- rial heirlooms, participants perceived value in supporting the dynamics of living with treasured digital collections, from knowing their location, to tending to their well being, to actively interacting with them. That the physical forms, material qualities and affordances of our devices enabled
them to be packaged away, discretely displayed, or actively explored seemed to resonate with families and some of their existing rituals, practices and values. Reforming digital materials in this way allows them to fit into the wider ecol- ogy of archived materials in the home and situates them within a familiar context of artifact-mediated reflecting, remembering and learning about the past. Beyond designing explicitly for ‘use’, this consideration emphasizes the aes- thetics of integrating treasured digital materials into envi- ronments as a whole over time, a notion parallel to ‘slow technology’ [11]. Collectively, these findings suggest that to support more sensitive and nuanced engagement with cherished digital familial content requires the artful design of technologies that can be put away, drawn on alongside others, and which evoke rich experiences when interacted with. This is more complex than it sounds; comments about the fractious intrusions of waiting for machines to ‘boot up’ are indicative of this.
Supporting the moral work of safeguarding—Notions of the value of ‘deep storage’ [14], redolent in our interviews, highlight clear unresolved tensions between digital and physical materials. For example, the encasing of our de- vices may last 100 years (or longer), while their technologi- cal components may last for only 5 years. This highlights the need to design new storage systems that are extremely robust and can handle sporadic use. There are opportunities to explore combined advances in solid-state storage and low power consumption. Although even with hardware innova- tion it is hard to imagine end users not having to engage with some degree of archive maintenance, as such advances will not resolve significant issues of evolving file format standards and ensuing compatibility issues. We suggest the ritual work of preservation may accommodate issues of safeguarding. Several instances from our findings suggest that tending to material heirlooms is itself a significant act: rituals of care could therefore be appropriated as opportuni- ties for the physical maintenance and updating of these technologies.
While the Cloud offers a technical solution to problems of storage, our findings reveal that knowing where one’s sen- sitive digital materials are located is bound to the sense that one is keeping them safe. ‘Storing’ these kinds of sensitive materials in online places raised concerns, especially in terms of ceding the higher-level social and moral work of safekeeping to a third party service. An approach to safe- guarding raised by participants themselves, which lends particularly well to digital technologies (as opposed to physical possessions), is the distribution of storage devices and the (redundant) copying of familial archives across multiple homes and branched families. This would leverage the value of existing social-familial networks and could help alleviate immediate concerns over the loss of cherished content, while supporting the higher-level work of safe- keeping content in morally and socially appropriate ways.
Enabling multiple roles in the archive—The solution pointed to above would need to be nuanced, however. One of the largest issues our devices provoked families to con- sider was the various roles members play in maintaining family archives, and how they would be supported in these roles by future technologies. From contributing new materi- als, to curating collections (organizing and editing etc.), family members play important roles in sustaining the fam- ily archive [15]. So while technologies might open up op- portunities for mirroring archives across homes, richer combinations would need to be carefully considered.
Families suggested Timecard’s indirect, distributed nature could create an opportunity for mapping family history "slowly over time". In other cases it seemed to open the opportunity to support storytelling and the recording of family history. Both of these opportunities potentially illus- trate how a digital artifact from the past might accrue value through repeated interaction, and resonate with prior re- search [8, 24] suggesting the prospect of integrating multi- ple family perspectives as beneficial.
However, it was clear that family members’ approaches to archiving were expected to differ, and this raised concerns over how 'quality control' could be upheld. These issues raise significant questions for future research. How does the architecture of new technology reinforce the moral ac- countability of access to the content? Who has the right to delete or edit entries? How is this accountability repre- sented in the system? What is the communicative structure that envelops the archive and provision of material within it, and how is this negotiated through technology? Better understanding these concerns seems a crucial part of de- signing new systems to support the persistence of a family’s digital legacy across generations. Research proposing im- plications for ‘forgetting’ as a feature in system design [e.g., 1] could be leveraged in future explorations, as could emerging research on multi-lifespan design [7].
Enabling multiple representations in the archive—While previous research suggested people desired to pass down their social networking content to other family members [19], families across our study reacted strongly against hav- ing a technology like the BackupBox. In particular, these instances highlighted tensions around integrating social networking content from members within the collective family archive. Participants made key distinctions between the thoughtful recording of one's life believed to be re- flected in their ancestors' diaries, and their own practices of posting less mindful social networking content targeted at multiple audiences, often outside of the family. These reac- tions surfaced clear boundaries members had for how they wanted to author their presentation of self within the family archive. Prior work has explored how technology could productively support members in presenting different repre- sentations of their selves to each other through novel tools for curating family photo collections [4]. While there are clear differences between curated photos and social net-
working data, this work could be leveraged to further ex- plore how different aspects of unique social bonds between family members could be preserved, while also leaving space for authorship of one’s self image in the family ar- chive as a whole.
CONCLUSION
We designed three devices aimed at provoking families to consider how technology might fit within their practices of inheriting, living with and passing down digital collections in the future. Families’ reactions revealed several ways digital materials fall short of supporting the values and practices they associated with physical heirlooms, and high- lighted new opportunities for design. While researching in this space is inherently challenging, our methodology pro- vided a way to engage family members in confronting po- tential benefits and tensions projected by our devices and draw on their own experiences to make sense of possible futures—and envision ideas beyond them. These reactions provided salient points to consider as people increasingly acquire cherished digital collections that they may desire to pass down alongside material heirlooms. Based on these findings we proposed designing technologies to be put away, supporting the moral work of safeguarding, enabling multiple roles, and enabling multiple representations in the archive as considerations for future HCI research and prac- tice. Importantly, our devices did not explicitly explore how to address the challenges that the sheer size and scale of meaningful digital content pose as families increasingly amass larger archives. Designing new forms and ways of interacting with massive archives of sentimental materials marks a clear area for future research. Ultimately, we hope this study will inspire future research into how technologies can better support the range of experiences that come with inheriting, living with and passing down treasured digital possessions over time and across generations.
ACKNOWLEDGMENTS
We thank Alex Taylor and Mike Massimi for their thoughts on this paper, as well as Phil Gosset, Tim Regan, and Mark Selby for their help on this project.
REFERENCES
1. Bannon, L. 2006. Forgetting as a feature, not a bug: the duality of memory and implications for ubiquitous comput- ing. CoDesign, V ol. 2, 1, 3-15.
2. Belk, R. 1990. The Role of Possessions in Constructing and Maintaining a Sense of Past. Advances in Consumer Re- search, 17, 669-676.
3. Dunne, T., Raby, F. 2001. Design Noir: The Secret Life of Electronic Objects. Birkhauser.
4. Durrant, A., Taylor, A., Frohlich, D., Sellen, A., Uzzell, D. 2009. Photo Displays and Intergenerational Relationships in the Family Home. Proc. of BCS HCI ’09, 10-19.
5. Fallman, D. 2003. Design-oriented human-computer inter- action. In Proc. Of CHI '03, 225-232.
6. Finch, J., Mason, J. 2000. Passing On: Kinship &amp; Inheri- tance in England. Routledge.
7. Friedman, B., Nathan, L. 2010. Multi-lifespan Information System Design: A Research Initiative for the HCI Commu- nity. Proc. of CHI ’10, 2243-2246
8. Frohlich, D., Murphy, R. 2000. The Memory Box. Per- sonal Ubiquitous Comput. 4, 4, 238-240.
9. Gaver, B., Martin, H. Alternatives: Exploring Information Appliances through Conceptual Design Proposals. In Proc.of CHI ’00, 2000, 209-216.
10. Hallam, E., Hockey, J. 2001. Death, Memory and Material Culture. Oxford: Berg.
11. Hallnas, L., Redstrom, J. 2001. Slow Technology: Design- ing for Reflection. Personal Ubiquit. Comput. 5, 201-212.
12.Hutchinson, H. et al. 2003. Technology probes: inspiring design for and with families. Proc. of CHI ’03, 17-24.
13.Kaye, J. et al. 2006. To have and to hold: exploring the personal archive. Proc. of CHI '06, 275-284.
14.Kirk, D., Sellen, A. 2010. On human remains: Value and practice in the home archiving of cherished objects. In ACM Trans. Comput. –Hum. Interact. 17, 3, 10.
15. Kirk, D. Izadi, S., Sellen, A., et al. 2010. Opening up the family archive. Proc. of CSCW ’10, 261-270.
16.Massimi, M., Baecker, R. 2010. A Death in the Family: Opportunities for Designing Technologies for the Be- reaved. Proc. of CHI ’10, 1821-1830.
17.Miller, D., Parrot, F. 2009. Loss and Material Culture in South London. J. of R. Anthro. Inst., Vol. 15, 3, 502-519.
18. .Net Gadgeteer. http://research.microsoft.com/en- us/projects/gadgeteer/
19.Odom, W., Harper, R., Sellen, A., Kirk, D., Banks, R. 2010. Passing on and putting to rest: Understanding be- reavement in the context of interactive technologies. Proc. of CHI ’10, 1831-1840.
20. Odom, W., Pierce, J., Stolterman, E., Blevis, E. 2009. Un- derstanding why we preserve some things and discard oth- ers in the context of interaction design. Proc. of CHI ’09, 1053-1062.
21.Petrelli, D., Villar, N., Kalnikaite, V., Dib, L., Whittaker, S. 2010. FM radio: family interplay with sonic mementos. Proc. Of CHI '10, 2371-2380.
22. Schön, D., Bennet, J. 1996. Reflective Conversation with Materials. Bringing Design to Software, 171-189.
23. Sengers, P., Boehner, K., David, S., Kaye, J. 2005. Reflec- tive design. Proc. of CC '05, 49-58.
24.Stevens, M, Abowd, G., Truong, K., Vollmer, F. 2003. Getting into the Living Memory Box: Family archives and holistic design. Personal Ubiquitous Comput, 7, 210-216.
</Text>
        </Document>
        <Document ID="51">
            <Title>Remembrance values</Title>
            <Synopsis>Existing research by Miriam Julius {Jung:2013ua} on remembrance values
• What they are posting &amp; on which SNS
• Defining what memory means for them
• Retrieval methods to go back to data 
   ⁃ Laborious methods are currently used to retrieve old posts</Synopsis>
            <Text>[Cite &amp; analyse results of existing interview/survey by Miriam Julius {Julius:2013ua} on remembrance values
	•	What people are posting on social networks
	•	Which SNSs are they mostly using
	•	Defining what memory means for them
	•	Retrieval methods used to find old data
	⁃	Laborious methods are currently used to retrieve old posts]</Text>
        </Document>
        <Document ID="169">
            <Title>I Evaluation:Images</Title>
            <Text>[fig. Cartographies/1]

The idea of genealogical tree in [fig. Cartographies/1] was rated positively, with the best score overall for aesthetic beauty (a 4.33 average out of 5), generally clear  and efficient, and moderately relevant (3.5).

[fig. Cartographies/2]

This less graphical tree representing English history [fig. Cartographies/2] received similar results, although judged less beautiful overall it was considered more relevant, and almost equally clear and efficient.

[fig Cartographies/3]

The cartography in [fig. Cartographies/3] was deemed unclear (1.78) and inefficient (1.89), receiving the worst results of all the maps for these two criteria. It was also generally considered inefficient (2.44), and moderately attractive (3.67).

[fig.4]

The historical atlas of [fig. 4], with its clouds gradually disappearing, received moderately positive results; the concept is clear (3.89 average, receiving 4 or 5 from all people except two who gave it a 1), it is moderately relevant and efficient, and generally beautiful (4.11 average, the second best result of the set). 

[fig. 5]

The New Chart of History of Priestley [fig. 5], considered one of the first timelines in the modern sense of the term, was evaluated very positively, showing that a linear rendition remains a good way to display information over time. It received the best averages for clarity (4.67) and relevance (4.44), and good ones for efficiency (3.56) and beauty (3.67).

[fig. 6]

However, linear renditions must be carefully crafted and not too dense with information, as the chronology of the Atlas Historicus [fig. 6], which predates that of Priestley [fig. 5], goes to show. It received poor grades for clarity (2.44), efficiency (2.33) and beauty (2.89), and fared well only with its relevance for life mapping (3.78), with its tabular format.

[fig. 7]

The Discus Chronologicus [fig. 7] did not seem to convince participants either, despite its original circular representation. It was rated as unclear (2.33) and inefficient (2.44), though moderately relevant (3.00) and aesthetically pleasant (3.22).

[fig. 8]

The tabular calendar of [fig. 8] received negative evaluations as well, considered unclear (2.44), irrelevant for a life representation (2.33), only moderately efficient (3.33), and, unsurprisingly, received the worst average of the whole set in terms of beauty, with 1.11.

[fig. 9]

The codex genealogy in [fig .9], using chains as a visual metaphor, was not considered a clear (2.67) or relevant (2.33) option, but was seen as efficient (3.44) and more appealing (3.89).

[fig. 10]

The three-dimensional piece of Emma Willard [fig. 10] got positive evaluations, showing that such a system could work well despite being very densely packed with information. It was considered particularly clear (4.00 average), moderately relevant (3.56) and efficient (3.67), and visually pleasing (4.00).

[fig. 11]

It is interesting to look at the differences between [fig. 11] and the Discus Chronologicus [fig. 7], as they are both radial but work radically differently; this one is read from the center to the outside, as opposed to a revolution around the circle. Overall, the chart of [fig. 11] received neutral reviews, not showing more interest in radial charts: it fared slightly better than [fig. 7] in terms of clarity (3.00), but worse in terms of relevance (2.89), and almost the same in efficiency (2.56) and beauty (3.22).

[fig. 12]

The great Strom der Zeiten [fig. 12], using the metaphors of streams, as seen in the previous chapter, did not convince participants. It was judged positively for its visual and colourful design (3.44), but its complexity earned it terrible grades for clarity, relevance and efficiency (2.22, 2.67 and 2.67 respectively).

[fig. 13]

Last but not least, the game of history presented in [fig. 13] received the best average overall, and obtained very positive evaluations in average — 4.33 for clarity, 3.89 for relevance, 4.11 for efficiency and 4.00 for beauty. This is indicative that a very visual (one main image per event) and simple (linear, no parallel axes, guided towards the centre) chart works well overall.</Text>
            <Notes>C Clarity
R Relevance
E Efficient
B Beauty</Notes>
        </Document>
        <Document ID="27">
            <Title>dissertation</Title>
        </Document>
        <Document ID="52">
            <Title>Questions</Title>
            <Text>What is the end goal
What is the project space (literally or the area / keywords)
What do I know
Need to find out
Who has already done it
What is the [visual?] language used

	•	How could I design something to preserve &amp; organise memories created digitally to give them the same value as physical objects who are sentimentally important?
	•	How could I design a technologically sustainable object that is meant to exist for decades without becoming obsolete?
	•	How do I represent a lifetime graphically and in a hierarchically relevant way?

Different types of questions (see slides Fraser presentation)/
Research question: are our memories safe on the internet? 
Safe -&gt; preserved, cherished, archived, kept on the long term; safe = privacy in the mind of most people, not ‘technically’ safe in their integrity</Text>
        </Document>
    </Documents>
</SearchIndexes>